Title1,Text,,,,,
Big California donors want to fill Kamala Harris’s Senate seat with a woman of color,"Some of California’s biggest political donors are urging Gov. Gavin Newsom to choose a woman of color to fill the seat of Vice President-elect Kamala Harris.
Given how rare it has been for a Senate seat in the country’s largest state to become vacant, California leaders have been hard at work trying to lobby Newsom ever since Harris was chosen for the Democratic ticket this summer. And now the lobbying is becoming more public.
On Monday, about 150 of the state’s biggest women donors will ratchet up the pressure with a public letter to Newsom saying that he should not replace Harris with a white woman, never mind a man.
“We urge you to continue this Californian tradition by appointing a woman of color to Vice President-elect Harris’s US Senate seat,” the donors write in the letter, which will appear as a full-page ad in the state’s two largest newspapers, the Los Angeles Times and the San Francisco Chronicle, and was shared early with Recode. “Women of color are the core drivers of electoral progress in our country, and their voices should be heard in the nation’s highest governing body. California is fortunate to have a strong pipeline of women of color in elected office who are prepared to serve; as Californians and political supporters, we look forward to you selecting one of them.”
Signatories of the letter — which is officially authored by two donor groups, Electing Women Bay Area and the Los Angeles Women’s Collective — include Silicon Valley psychiatrist Karla Jurvetson, one of the country’s biggest Democratic donors; Gretchen Sisson, a sociologist and on-the-rise Democratic fundraiser; Susan Pritzker, a scion of the famous hotel family that has bankrolled Newsom’s ambitions for years; and Dagmar Dolby, the billionaire philanthropist.
The decision before Newsom could be one of the politically diciest of his governorship. Newsom is also under pressure from Latino groups to name California’s first Hispanic senator, and Alex Padilla, California’s secretary of state, who is Hispanic, is considered a top contender, in part because he is personally close with Newsom. Another possible Latino choice is California Attorney General Xavier Becerra.
There are several woman of color who are believed to be competitors with Padilla, including Karen Bass, a Los Angeles congresswoman who is Black and was a finalist to be Joe Biden’s vice-presidential selection; and Barbara Lee, a Black congresswoman from Oakland known for her anti-war stance.
Senate seats in California don’t come up that often. Harris’s counterpart in the Senate, Dianne Feinstein, has held her seat for almost 30 years. Harris’s predecessor, Barbara Boxer, sat in hers for 25. So Newsom is likely staring down a decision that will well outlast him.
Last month, Newsom lamented about “the stress of having to choose between a lot of friends, to choose between quality candidates — and the fact that whoever you pick, there are going to be a lot of people who are going to be upset.”
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
"One of the few Black C-suite execs in tech is starting a firm to invest in Black, Latinx, and women entrepreneurs ","Mike Smith is a versatile and well-respected executive in the e-commerce industry. He also happens to one of the few Black C-level leaders in tech. 
Now he wants to play a bigger role in changing that. 
Smith has served as president, COO, and interim CFO over eight-plus years at Stitch Fix, the online apparel retailer and personal styling service. But he told Recode on Thursday that he plans to leave his executive role at the $4 billion publicly traded company in the coming months to start a venture capital firm. His goal is to get more money into the hands of tech entrepreneurs from underrepresented backgrounds, namely Black, Latinx, and women founders. 
“I’ve been fortunate that I’ve done well being out in this ecosystem, and I want [there to be] more people like me,” Smith told Recode. “When I look around and I’m the only one or one of the few, it just shouldn’t be the case.”
As a racial reckoning swept the US this year in the wake of George Floyd’s murder, some of the Silicon Valley elite who decide how to invest billions into startups have confronted their own role in the systemic issues of economic inequality prevalent in the US. Only 1 percent of VC-backed entrepreneurs are Black, and less than 2 percent are Latinx. Meanwhile, the percentage of VC dollars invested in female founders has barely increased since 2012. According to a Morgan Stanley report published this week, 61 percent of venture capitalists say that the Black Lives Matter movement has impacted their investment strategy, and 43 percent of these investors say that funding “multicultural-founded” companies is now one of their top priorities, up from 33 percent in 2019.
Smith said he was happy to field calls this summer from startup investors and other business leaders who wanted his advice on how to help solve issues of racial injustice and economic inequality. “The dialogue needs to happen and there needs to be vulnerability where people can admit, ‘I don’t know what to do,’” Smith said.
At the same time, this summer’s events and conversations made Smith want to do more.
“I considered either being CEO of a company or joining a venture firm, and then George Floyd happened and the racial unrest, and I really took stock of, ‘What do I want my impact to look like over the next 10 to 15 years of my career?” Smith said. “And it was super meaningful to process all that was going on this summer and realize, I do think the broadest impact that I can have is doing venture capital and starting my own firm, with diversity being a really important pillar of the firm.”
While Smith said his firm won’t ignore founders who aren’t from underrepresented backgrounds, there will be a “big focus” on evaluating ideas from those entrepreneurs who are. 
“That pipeline has been underrepresented, that pipeline hasn’t had access. And we think we’ll find great founders,” he said. 
Smith has for years served as both a formal and informal adviser to a growing network of Black and women founders, and believes that will put him in a position to get in front of the next great wave of entrepreneurs. The investment firm, which Smith will run with a partner he’s not ready to announce, will favor investments in consumer companies based on his experiences over the last two decades working at Stitch Fix and Walmart.com before that.
“Dollars spent in this country and the world are spent by more people who are non-white, and there’s a lot of Black influence on culture in this country,” Smith said. “But I don’t think we’ve seen as much participation in wealth creation, specifically in technology, in the Black community.”
Though Smith will leave his full-time role as interim chief financial officer when Stitch Fix hires a permanent replacement soon, the company is naming him to its board of directors — a rare offer to a departing executive. Smith also serves on the boards of publicly traded companies Ulta Beauty and Herman Miller, as well as startups Mayvenn and Imperfect Foods.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Silicon Valley elbows for a seat at the table in Joe Biden’s White House,"When it comes to Silicon Valley, Joe Biden is something of a blank slate. And for Silicon Valley, that means Joe Biden is something of an opportunity.
So Big Tech reformers and Big Tech allies are gearing up for a spirited fight in the coming months over the types of people who will staff the Biden administration. Those personnel decisions will offer some of the first revelations into how exactly the president-elect will regulate the tech industry and its titans, a high-stakes question about the American economy that he mostly avoided answering during his campaign. 
That ambiguity is making the transition period all the more important, a dozen people with ties to the Biden team tell Recode. Reformers want to make sure they at least have a seat at the table and that they aren’t boxed out by well-paid industry interests. Forces aligned with the industry, meanwhile, want to make sure that a Biden administration isn’t too captive to the online left, even though they know it won’t resemble the halcyon days of Barack Obama.
Back then, Silicon Valley was a celebrated part of America’s innovation economy. Since Obama left office, though, the tech industry has become radioactive to parts of both the left and the right, part of a “techlash” that has culminated in calls to break up Big Tech companies like Amazon, Apple, Facebook, and Google. Tech critics worry that these companies and their leaders have amassed too much control over Americans’ lives when it comes to privacy, the economy, and politics. Now Obama’s former No. 2 will have to answer these important questions on dicier terrain: Will he pursue this breakup? Will he inflame the tensions or cool them? Will he side more with the reformers or the industry? 
The next few months will test the influence and muscle of both sides. Tech insiders have been among Biden’s biggest donors and are well-organized. But Biden has to be sensitive to a far left that is deeply skeptical of any corporate incursions — and is often louder.
“They’re in a difficult political situation,” said Rob Atkinson, the head of the Information Technology and Innovation Foundation think tank, who helped lead a tech advisory committee for Biden during the campaign. “It’s almost like a draft lottery for what team you want. You want to pick somebody on your team from the progressive wing and then somebody more from the tech or moderate wing. He’s going to have to do both.”
The draft has already begun: Phones are ringing across the tech industry as people close to the Biden campaign gauge some leaders’ interest in joining the administration and other Silicon Valley veterans hunt for inroads. Lobbyists and activists alike are researching names who they might want to push on Capitol Hill or disparage in the press. People in the Bay Area who raised money for Biden are being overwhelmed with requests to pass along resumes to his inner circle.	And Biden’s team is encouraging experts who served on Biden’s tech advisory committee to apply for positions in the administration.
Flashpoints, too, have already emerged that speak to these new battle lines. Activists have grown concerned about a report that Eric Schmidt, the former CEO of Google and a vocal defender of technology giants, was “being talked about” to lead a new tech task force out of the White House. (The report did not say who was doing this talking.)
On Monday, a dozen progressive groups wrote to the Biden transition effort to plead that Schmidt not be appointed to this task force. The letter — shared first with Recode — amounted to a warning shot not just about one particular tech billionaire but about the influence of the tech industry on politics more broadly. 
“The appointment of Schmidt risks fracturing a Democratic coalition that your campaign and so many others worked so hard to build over the past several months,” said the letter-writers, which included activist groups like Demand Progress, the Revolving Door Project, and the Progressive Change Campaign Committee, a group allied with leading Big Tech critic Elizabeth Warren. “While the appointment of Schmidt may attract praise from certain elites in both Washington and Silicon Valley, it risks alienating an overwhelming majority of the electorate, including within the Democratic base, who want to see the economic power of major corporations reined in.”	
Silicon Valley sources close to the Biden team tell Recode that they are unaware of any planned formal role for Schmidt and that they find one hard to believe given the optics of Big Tech. A source familiar with the matter said there have been no discussions between the Biden transition team and Schmidt about a role.
Sources do, however, expect Schmidt, a bipartisan veteran of the Washington scene who had wide influence during the Obama years but also has had complimentary things to say about Jared Kushner, to at least have considerable access to the Biden White House. There’s also the possibility that some aides at Schmidt’s philanthropic foundation, which is stacked with former Obama hands, will decamp for the new administration.
Schmidt and the Biden transition team declined to comment.
The battle over Schmidt is just one of several personnel fights that will likely play out in the first year of the new administration. Other key positions that tech voices will surely try to influence include the chairs of the Federal Trade Commission and the Federal Communications Commission, and the head of the Department of Justice’s antitrust division — all roles that police tech giants’ behavior.
People allied with Big Tech say they aren’t concerned with developing blacklists of reformers who must be repelled. But they are concerned about the converse — that the progressives are organizing themselves to torpedo any and all people who worked in the industry, even if they have relevant policy expertise about complicated topics that would prove valuable to the country.
“You would really want to have an administration that doesn’t have industry voices as a part of it? That to me sounds like a really problematic outcome,” said Matt Perault, a former Facebook policy executive who now leads Duke’s Center on Science and Technology Policy and has offered policy advice to the Biden team. “So I hope there aren’t those kinds of litmus tests.”
It’s still too early to know how this will work out. Few heavyweights are ultimately expected to take staff jobs. But some names are beginning to be privately bandied about by people with ties to the transition effort.
Laurene Powell Jobs, the philanthropist and wife of the late Steve Jobs, stirred some DC speculation that she might be interested in a role with her statement about her hopes for the new administration, a source told Recode. Meg Whitman, the longtime tech executive who most recently served as the CEO of Quibi, is earning a look as a potential secretary of commerce. (Whitman, a Republican, often appeared on calls for Biden’s national finance committee.) Former presidential candidate and tech dystopian Andrew Yang has also attracted buzz and confirmed interest in serving as the country’s chief technology officer, a position that some Silicon Valley supporters hope will be at the Cabinet level.
But what casts a shadow over all of this jockeying is that Biden and his aides were, and will continue to be, reluctant to seem too cozy with high-profile tech insiders, according to people who have spoken with these aides.
The reason these names matter so much is that Biden has largely kept Silicon Valley guessing about where exactly he falls when it comes to tech policy. Over the course of the race, he and his aides made plain their disdain for Facebook and Mark Zuckerberg, who Biden said was “a real problem.” But they had less to say about other tech giants. Biden has promised to repeal Section 230 of the Communications Decency Act, a law that shields social media companies from lawsuits, but he’s released few details about that plan. And he has sounded the alarm about corporate consolidation, but stopped short of calling for a breakup of Big Tech.
That lack of clarity has also been reflected in his personnel decisions thus far. The 700 names on Biden’s “Innovation Policy Committee,” a working group of volunteers meant to help the campaign surface policy ideas, feature both industry insiders and prominent activists calling for a breakup. Biden’s hiring of tech executives for his transition, such as Apple’s top lobbyist, Cynthia Hogan, could be seen as a capitulation to Big Tech — but it could also be read as Biden merely rehiring his former aides, including his former counsel, Hogan, who just happened to have spent a few years at the tech giants.
That all has given both sides reason for optimism. So, too, has the presence of two senior Biden advisers, Bruce Reed and new chief of staff Ron Klain, who each have ties to tech leaders. Both reformers and industry allies see them as reasonable brokers.
Jim Steyer, the head of Common Sense Media and a prominent privacy critic of Big Tech, said he has passed along names and ideas to people like Reed, a close friend of his. He is not naive and expects the tech industry to still have access to Biden, but not exclusive access like under Obama.
“Do I think that the Biden administration is going to turn over his tech agenda to the industry? No, I do not,” Steyer said. “They’re not going to be bought and sold by the tech industry.”
But if the old adage that “personnel is policy” is true, the next few weeks will reveal whether any of this optimism is misplaced. But even before any compromises, there are already signs of just how much the Overton window has shifted when it comes to Silicon Valley over the last four years.
Before Election Day in 2016, for example, Facebook’s No. 2, Sheryl Sandberg, was seen as a leading contender to be secretary of the treasury in a Clinton administration. 
Now, four years later in an incoming Democratic administration, the possibility of a Treasury Secretary Sandberg seems unthinkable — if not downright ludicrous.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Support Vox’s explanatory journalism,,,,,,
"Twitter announces Fleets and audio spaces, two new things Twitter didn’t really invent","Twitter is finally letting users post ephemeral content, starting today. 
The new feature — which has been tested in various markets this year — is called Fleets, and it looks an awful lot like Snapchat Stories. Twitter is also testing out a new audio feature called audio spaces that largely resembles the embattled, invitation-based startup audio app Clubhouse which launched earlier this year. Together, these new efforts show how Twitter, a famously public-facing platform, is attempting to expand how people interact on its platform.
Twitter, of course, is doing what Facebook has done many times: imitating aspects of its competitors’ successful products in an attempt to stay on the same footing. These new features also indicate that Twitter, like Facebook, is increasingly interested in private and group-based interactions. Both new tools show that Twitter wants to appeal to users who might be more reluctant to share publicly and permanently on the platform. In terms of active users, Twitter is still quite a bit smaller than Facebook, Instagram, or TikTok.
“It’s no surprise that the typical conversation on Twitter is a short burst of high-brevity exchanges back and forth between multiple people,” said Twitter product lead Kayvon Beykpour. “That’s very powerful. But if we want to allow for a wider range of conversations to unfold, we need to support other formats. We need to support other use cases that help people have more thoughtful debate, more thoughtful exchanges, that you can’t pack into 280 characters.” 
  
  
    
    
      
        

<img alt="""" src=""https://cdn.vox-cdn.com/uploads/chorus_asset/file/22046938/Fleets.gif"">

      
    
    
  
  



The new Fleets feature, for example, allows users to post to their followers content that disappears after 24 hours. It really does look a lot like Stories on Facebook and Instagram — and Snapchat. Just as they are on Facebook and Instagram Stories, links to Fleets appear in the top portion of the Twitter app, and they’re also accessible by clicking through someone’s account profile picture. 
Like Instagram and Snapchat Stories, people will be able to share reactions to other tweets, videos, and photos. Eventually, users will be able to incorporate stickers and live broadcasts, the company said. Notably, Twitter has not built a way to prevent someone from taking a screenshot of a Fleet or a way to provide a notification when someone takes a screenshot of your tweet. 
Importantly, Fleets can’t be retweeted or shared. Replies to Fleets will be private and will function as part of Twitter’s existing direct message system. The goal, in part, is to beckon users reluctant to post publicly on the app to engage in this way. Again, Fleets launches today worldwide, so every Twitter user, including President Trump, will have access to the new feature.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        Fleets are disappearing message that look almost identical to Instagram Stories.
      
      
        Twitter
      
    
  


Then there’s audio spaces, an audio-based conversation tool. Spaces builds on the audio tweets feature Twitter launched earlier this year that allowed people to post recordings of their voice up to 140 seconds long. That tool has continued to roll out through this fall, and the company is also incorporating transcription features in 2021, following criticisms that the tool isn’t accessible to people who are deaf or hard of hearing. 
The idea behind audio spaces is to make Twitter’s audio feature more conversational. With the new feature, a user will be able to start a conversation and then allow others to participate or listen in. The company likens the feature to a “well-hosted dinner party” and anticipates that the tool will be used for debate. Yes, it looks a lot like Clubhouse.
Audio spaces won’t be available to the general public yet. Twitter still plans to do some experimenting and — also like Clubhouse — plans to start rolling out the feature through a limited number of invitations. 
“We are going to launch this first experiment of spaces to a very small group of people, a group of people who are disproportionately impacted by abuse and harm on the platform, women and those from marginalized backgrounds,” said Maya Gold Patterson, a staff designer at the platform. 
The company reiterated that all content on Twitter, including Fleets and audio spaces, is subject to Twitter’s rules. Just like regular tweets, Fleets are also subject to Twitter’s various labels, including those for false or misleading content.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        Audio spaces are a new way to have live conversations on Twitter.
      
      
        Twitter
      
    
  


While these new and upcoming features are an attempt to get users doing new things on its platform, they will also invite new challenges in content moderation. With audio spaces, for example, Twitter must tackle the tricky, technical question of moderating live audio content. Clubhouse has faced an uphill battle in creating and enforcing rules for its platform and recently came under scrutiny after a 300-person conversation devolved into anti-Semitic commentary. At the same time, the Fleets feature provides a new avenue for misinformation to spread, and the push toward more direct messages means non-public content is less accessible to other users and moderators.
Still, we shouldn’t expect Twitter to stop experimenting anytime soon. The company says it’s still studying how well its election season product modifications worked, and has hinted that it may continue to tinker with those features. Twitter is also exploring ways of facilitating private apologies and promoting forgiveness in an effort to encourage more empathy on the platform. Just last month, company CEO Jack Dorsey hinted that he’s interested in letting users choose their own algorithms, a move that could dramatically alter Twitter as we know it. 
All these moves are signs that the platform isn’t interested in limiting itself to what it’s done before — and a reminder that social media companies still feel perfectly comfortable ripping off each other’s products.  
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.


  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
"Amazon starts selling prescription drugs, with two-day delivery for Prime members","When Amazon spent $750 million to acquire the online pharmacy PillPack in 2018, it was clear the tech giant had interest in the prescription drug market. Now we know how serious it was.
Amazon will start selling prescription medications on its main Amazon website and app on Tuesday, and will offer two-day delivery of these medications to Prime members for no extra fee. Prime members without prescription drug coverage, or with coverage that isn’t great, can also save up to 80 percent on generic and 40 percent on brand-name drugs when paying out of pocket without insurance. Prices with and without insurance can be compared at checkout.
“Our goal is to make accessing prescription medications as simple as any other purchase: saving customers time, giving them more control over their purchases, and helping them stay healthy,” Amazon spokesperson Jacqui Miller said in an email.
Prescription drugs are a $500 billion market in the US, with patients spending $67 billion out of pocket at US retail pharmacies in 2019, according to IQVIA, a health data provider. Amazon’s brick-and-mortar retail competitors like Walmart, Target, and Costco all have significant pharmacy presences across their chains of stores, and Amazon wants a piece of that, too. When Amazon executives talk about the desire to sell every genuine product in the world through Amazon.com, it’s now clear that medications aren’t excluded.
Amazon’s acquisition of PillPack in 2018 gave the company entry into the growing online segment of the pharmacy industry, with a focus on Americans who have chronic illnesses and take multiple medications every day. PillPack presorts medications for its customers, before shipping them to their door. An Amazon spokesperson said customers with those prescription medication needs should still order directly through PillPack, which operates five pharmacies in the US and is licensed nationwide, but does not ship to Hawaii.
By offering the option to purchase prescription drugs through the main Amazon website, the tech giant is attempting to appeal to a broader base of consumers who don’t take multiple medications daily but might need a prescription drug in the house — perhaps blood pressure medication, an Epipen for a food allergy, or prescription pills for anxiety. However, Amazon’s online pharmacy offering isn’t a fit — at least not yet — for customers who need a prescription filled the same day for an illness that needs immediate treatment.
Patients who want to use Amazon to purchase medications can instruct their doctor to send prescriptions to Amazon Pharmacy just like any other retail pharmacy. The company said it accepts “most” insurance plans.
The discounts Prime customers get when paying for medication without insurance are administered by a separate company called Inside Rx. Inside Rx has relationships with more than 50,000 pharmacy locations, meaning Prime members can also use these discounts at pharmacy competitors like Walmart, Costco, CVS, and Walgreens, with the latter two offering free home delivery of prescription medication. 
Over its 25-year history, Amazon has convinced online shoppers to trust buying an ever-expanding assortment of product types from the company: from books and DVDs in its early days, to clothing, jewelry and packaged foods, to vitamins, supplements, and fresh groceries more recently. But perhaps no new product launch will test the trust that people have in Amazon more than whether they trust the company with prescription medication. After all, Amazon does have some counterfeit issues, and last year notified customers that a merchant had sold knockoff supplements through Amazon.com.
Launching the new service in the midst of the pandemic, however, may help the adoption curve, with the potential that more people will want to avoid waiting in line at brick-and-mortar pharmacies as Covid-19 infections soar nationwide. Amazon has already seen an enormous increase in its online grocery business during the pandemic. 
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Join the Vox Book Club!,"Join the Vox Book Club!

      Our pick for November 2020 is Trust Exercise, by Susan Choi.

    
  
  
  
    
      
        Contributors:
        
          
            Constance Grady and Matthew Yglesias",,,,,
The future of commercial space travel is almost here with the latest SpaceX launch,"Elon Musk’s SpaceX just launched the first operational crewed flight into orbital space, following up on its successful test flight several months ago and bringing us one step closer to private commercial space travel.
SpaceX’s Crew Dragon Crew-1 capsule, seated on top of the company’s Falcon 9 rocket, took off on Sunday night with four astronauts on board — three from NASA and one from Japan’s JAXA — for a return flight to the International Space Station (ISS). The launch follows its crewed test flight last May, for which two astronauts successfully launched, docked at ISS for two months, then safely returned to Earth with its crew. 
Sunday’s flight was the first operational one — that is, the first flight since NASA certified the capsule for spaceflight, following its successful crewed test — in SpaceX’s contract with NASA to send astronauts to and from ISS, which both the company and the government agency hope will be a lasting and mutually beneficial relationship.


Falcon 9 launches Crew Dragon on its first operational flight with astronauts on board, beginning regular crew flights to the @space_station from the U.S. pic.twitter.com/C8oBqMcAuj— SpaceX (@SpaceX) November 16, 2020





""It is not over. This was a beautiful launch... but remember, this is a six-month mission, and it's the first of many.""Administrator @JimBridenstine looking toward the future of the Crew-1 mission and the @Commercial_Crew program. #LaunchAmerica pic.twitter.com/7cKcu5mM1J— NASA (@NASA) November 16, 2020



But it’s also a relationship born out of necessity. The United States retired its own Space Shuttle program in 2011, and has had to rely on Russian rockets to travel to the ISS ever since. Rather than building its own spacecraft, NASA decided to invest billions in private companies like SpaceX to develop vehicles that would escort its supplies and crews instead.
SpaceX’s rise
Using $100 million of his PayPal payout, Musk founded SpaceX in 2002, predating his Tesla car company by more than a year. As the story goes, Musk wanted to put plants on Mars, but it was too expensive to acquire the rockets to do so. So he started his own company, SpaceX, to see if he couldn’t get those costs down. In early years, the venture seemed destined for failure: Between 2006 and 2008, the first three launches of its Falcon 1 rocket failed. But the fourth rocket succeeded later in 2008, and the fifth carried a satellite into orbit in 2009. 
After this, and with some funding from NASA, SpaceX accelerated development of the Falcon 9 rocket, which first took flight in 2010. This two-stage rocket powered by nine Merlin engines has now launched nearly 100 times, carrying satellites into orbit and supplies to ISS; now, it’s brought people to ISS as well. It’s failed just twice: once in flight in 2015 and once on the launch pad in 2016. It’s also the first and only orbital rocket that’s partially reusable — the booster section lands itself back on Earth after launch — which significantly cuts down on operating costs.
There’s also the Falcon Heavy, a heavy-lift launch vehicle that looks like a Falcon 9 rocket with two Falcon 9 boosters strapped to the sides. On its 2018 maiden voyage, it sent a Tesla into space, complete with a dummy driver clad in a spacesuit. It’s still up there somewhere. On the second Falcon Heavy launch, all three rockets returned safely to Earth. After the third and most recent launch, the Falcon Heavy earned certification from the National Security Space Launch (NSSL) program, which is part of the United States Space Force.
SpaceX then became the first private company to send a crew into orbital space with the Crew Dragon Demo-2 test flight, which was operated by NASA astronauts Robert Behnken and Douglas Hurley. 


With the successful test flight under its belt, SpaceX and NASA had the green light to begin operational flights to and from ISS. The first of those was Sunday’s launch, with a crew of NASA astronauts Victor Glover, Michael S. Hopkins, and Shannon Walker, and JAXA’s Soichi Noguchi. SpaceX astronauts in both the test and operational missions have been escorted to their launches in Tesla cars, both giving Musk’s electric car company some nice cross-promotion and demonstrating just how commercial our new era of space travel has become.
Impressive as the success of SpaceX has been, Elon Musk still has his sights set on greater things. The company’s most ambitious project yet, the SpaceX Starship, is underway. Intended to be a fully reusable, stainless steel, heavy-lift launch vehicle that would tower over the iconic Saturn V rocket developed for the NASA Apollo missions, the Starship is supposed to go to the moon, Mars, “and beyond.” In fact, NASA has already included the Starship on its list of commercial launch systems for the Artemis missions, which are scheduled to land a man and a woman on the moon by 2024.
The successful crewed flights set up SpaceX for an even brighter future. The company has become NASA’s preferred launch partner and now handles about two-thirds of the agency’s launches under government contracts worth billions. SpaceX also offers a “rideshare” option that will carry smaller payloads to orbit for as little as $1 million. The company also just raised more than $1.9 billion in fresh funding to keep developing its Crew Dragon capsule, Starship program, and Starlink satellite business. A second operational crewed flight to ISS is already planned for spring 2021. SpaceX also hopes to sell seats to (presumably wealthy) space tourists someday.
NASA’s fall
SpaceX, now valued at about $46 billion, rose to prominence after NASA fell from grace. The federal space agency has to rely on private companies to send its astronauts into space  after NASA ended the Space Shuttle program in 2011. At that time, NASA shifted its attention to Mars and Earth science and away from space shuttles and a return trip to the moon. Under President Trump, however, NASA has turned back again to putting astronauts back on the moon with the launch of its Artemis program in 2017. The incoming Biden administration may change things up once again.
Suffice it to say, there’s been some shifting of priorities at NASA. In the years since the Space Shuttle program ended, American astronauts have had to hitch rides on Russian rockets to get to and from the ISS at a cost of $86 million each and an unquantifiable amount of national pride. (SpaceX, by contrast, is estimated to charge $55 million per astronaut for these round-trip flights.) This arrangement with Russia is not supposed to last forever.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        The Crew Dragon capsule, shown here atop the Falcon 9 rocket, is equipped with touchscreens and a streamlined interior.
      
      
        SpaceX
      
    
  


Over the past decade, NASA’s Commercial Crew Program has awarded billions to a handful of private companies to develop crewed space vehicles to carry NASA astronauts to and from the ISS. Rather than use private companies as contractors that fulfill government orders, as it did in the past, NASA gave private companies funding to develop their own commercial efforts, which NASA could then use for its own ends.
That means space exploration is now a business, and many of its biggest innovations are coming from the private sector, which is partially subsidized by public money. Through these arrangements, Boeing has developed its Starliner capsule, which has no launch date yet and has been beset with difficulties, and SpaceX built the Crew Dragon capsule. And NASA is just fine with this, as the new partnerships shifts some of the cost of developing and constructing spacecraft onto private industry. And it’s not just companies that make spaceships; NASA recently awarded Nokia the right to build a 4G mobile network on the moon as part of its effort to establish a more permanent presence there.
We need to talk about Elon
No discussion of SpaceX would be complete with some hand-wringing over its controversial founder and CEO — Musk himself has made sure of that. 
His biographer Ashlee Vance interviewed Musk for Bloomberg as the Demo-2 launch approached. Vance highlighted how Musk has recently made himself a lightning rod of criticism for suggesting that Covid-19 is fake and generally being awful on Twitter.
Vance writes:
Even the most fervent Musk hater, of whom there are plenty in the US, has to feel some twinge of pride. At a moment when the American Empire can seem to be in decline, here’s a clear sign that great things remain possible and that humans have much left to achieve. “America is still the land of opportunity more than any other place, for sure,” Musk says, waxing patriotic. “There is definitely no other country where I could have done this—immigrant or not.” That it’s a multibillionaire, Covid-19-truthing, entrepreneurial huckster/hero delivering this message is pretty much perfect for America in 2020.
Vance added that Musk’s “business tactics and behavior can oscillate between infuriating and appalling.” 
Indeed. Musk’s Twitter account has 40 million followers, and the tone of his tweets tends to alternate between that of a self-promotional businessman and an angsty teenager. Musk’s tweets alone have gotten him sued by a cave diver and the Securities and Exchange Commission. (He won the first case and settled the second, with an agreement that personally cost him $20 million and his chairmanship of Tesla’s board.)
Just this year, Musk has vowed in a tweet to sell his possessions, after which he tweeted, “My gf … is mad at me.” He also said the price of his own company’s stock was “too high,” named his new child X Æ A-Xii, repeatedly downplayed the coronavirus pandemic, and forced his Tesla employees to work through it — even defying government orders to reopen a factory early. SpaceX, which is considered critical infrastructure, never stopped. 
When Musk did seem to take the pandemic seriously, it was to offer his companies’ assistance in manufacturing ventilators. But that help never really came — although in fairness, neither did the feared nationwide ventilator shortage that prompted those tweets. Musk’s May tweet urging followers to “take the red pill,” a term that has well-known far-right and men’s rights activist connections, got a response from Ivanka Trump, who simply said, “Taken!” 
Most recently, Musk appears to have contracted the coronavirus himself, tweeting that he “most likely” had the virus. He complained of “symptoms of a minor cold,” which were apparently treated with DayQuil. But after taking four rapid Covid antigen tests, two of which were positive and two of which were negative, Musk said “something extremely bogus is going on.” He was forced to miss Sunday’s launch and a Twitter user dubbed him “Space Karen” for his multiple complaints about the accuracy of coronavirus tests. “#SpaceKaren” and “Space Karen” trended on the platform afterward. (“Karen” has become a term for entitled white people who become outraged when they don’t get their way in various aspects of life.)
Yet while Musk’s bizarre, attention-seeking behavior may be a turnoff for many, his businesses make enough money and are cool enough to investors that SpaceX and Tesla seem to be succeeding in spite of Musk’s increasingly controversial public image. The US government, however, is not a business, and it has not taken well to Musk’s antics. Along with the SEC’s $20 million fine, NASA investigated and scolded him after he smoked pot while appearing on a podcast in 2018.
Still, SpaceX is undeniably an accomplishment, and its successful crewed launches will be an essential step toward Musk’s plans for the moon or Mars or wherever he ultimately decides to go. At this point, it’s hard to imagine the future of space travel without SpaceX and without Musk. 
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Obama: The internet is “the single biggest threat to our democracy”,"Back in 2008, Barack Obama famously harnessed the internet and social media to help win the White House. He kept up the embrace once he got there.
Now he worries that the internet and social media have helped create “the single biggest threat to our democracy.”
Obama has been saying a version of this for four years — since he left the White House — but his words are getting steadily more pointed. He’s clearly sounding an alarm, but it’s not exactly clear what he thinks we should do about it.
His latest critique comes in a new interview between Obama and Atlantic editor Jeffrey Goldberg, and before we go any further we should put it in full context: Obama was discussing a media landscape dominated not just by Facebook but by Fox News that allows Americans to choose their own distorted reality. Which means, he says, we no longer have a shared set of facts.
That assessment is now conventional wisdom among many critics of the TV and internet ecosystem. There’s almost no practical, constructive argument about how we should respond to that problem. Obama doesn’t offer one in his interview, either.
And again, it’s incorrect to say that Obama is laying the problems of our broken information landscape solely at the feet of Facebook or any other particular tech company. But he is certainly lacing into them now in a way he didn’t do prior to leaving the White House.

Obama: Now you have a situation in which large swaths of the country genuinely believe that the Democratic Party is a front for a pedophile ring...I was talking to a volunteer who was going door-to-door in Philadelphia in low-income African American communities, and was getting questions about QAnon conspiracy theories. 
Goldberg: Is this new malevolent information architecture bending the moral arc away from justice?
Obama: I think it is the single biggest threat to our democracy.

Later in the interview, Obama makes it quite clear that much of his concern is specifically about the internet — which he is also quite clear isn’t “going away” — and the big platforms that sort and distribute most of the internet for most people: 

Obama: I don’t hold the tech companies entirely responsible, because this predates social media. It was already there. But social media has turbocharged it. I know most of these folks. I’ve talked to them about it. The degree to which these companies are insisting that they are more like a phone company than they are like The Atlantic, I do not think is tenable. They are making editorial choices, whether they’ve buried them in algorithms or not. The First Amendment doesn’t require private companies to provide a platform for any view that is out there. At the end of the day, we’re going to have to find a combination of government regulations and corporate practices that address this, because it’s going to get worse. If you can perpetrate crazy lies and conspiracy theories just with texts, imagine what you can do when you can make it look like you or me saying anything on video. We’re pretty close to that now...
Goldberg: It’s that famous Steve Bannon strategy: flood the zone with shit.
Obama: If we do not have the capacity to distinguish what’s true from what’s false, then by definition the marketplace of ideas doesn’t work. And by definition our democracy doesn’t work. We are entering into an epistemological crisis.

Obama’s criticisms of Fox News and the Rupert Murdoch empire predate his time in the White House. It continued once he was there. 
During his eight-year tenure, though, Obama was quite welcoming to the tech industry, and vice versa: Obama stocked the White House with Silicon Valley veterans, and White House veterans later landed important jobs in Silicon Valley. 
And Google executives in particular, starting with former Google CEO Eric Schmidt, had frequent meetings with White House staff. Near the end of Obama’s presidency, the Wall Street Journal reported that career regulators wanted to pursue antitrust charges against Google but were overruled by political appointees. 
Obama certainly understood the power of social media, which helped him get into office. In the last days of the 2016 presidential campaign, Obama was reportedly obsessed with a BuzzFeed story about Macedonian teens flooding Facebook with fake news. 
But it wasn’t until after the election that Obama sounded off in public about “active misinformation” on Facebook and TV. Days later, he pulled Facebook CEO Mark Zuckerberg aside for a private plea “to take the threat of fake news and political disinformation seriously.”
And while Obama made a point of keeping a low profile during most of the Trump era, when he did surface, he would often take pains to spell out his criticisms of social media:
“I do think the large platforms — Google and Facebook being the most obvious, Twitter and others as well, are part of that ecosystem — have to have a conversation about their business model that recognizes they are a public good as well as a commercial enterprise,” he said at an MIT event in 2018. “We have to have a serious conversation about, what are the business models, the algorithms, the mechanisms, whereby we can create more of a common conversation. And that can not just be a commercially driven conversation.”
Obama was calling for a “serious conversation” about our information dystopia two years ago. Now he’s calling for “a combination of government regulations and corporate practices” to deal with it. 
It is difficult to be optimistic that we’ll get there. It’s hard to see the federal government regulating big tech in a serious way, because Democrats and Republicans don’t have shared facts about the problem; Republicans, in fact, have elected a QAnon promoter to Congress. And Big Tech isn’t remotely comfortable regulating itself — it would rather have government regulate big tech. And it would be surprising if Joe Biden — who had little to say about tech during his presidential campaign — and Kamala Harris — a longtime ally of Silicon Valley — make it a focus in a pandemic presidency. 
A modest suggestion: Barack Obama is still working on the second volume of his memoirs. This seems like a problem worth focusing on after that.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Listen to our new podcast with never-before-told stories about Amazon’s ascent,,,,,,
Jeff Bezos plays it safe on his $10 billion climate giveaway,"Amazon founder Jeff Bezos on Monday announced nearly $800 million in grants to some of the country’s most prominent environmental organizations, spelling out the first details on his massive climate change push since he unveiled it in February.
The $10 billion program, called the Bezos Earth Fund, is one of the biggest charitable commitments ever and the largest to date by Bezos, the world’s richest person. 
The lion’s share of the money from Bezos is funding nonprofits that are prominent even outside of environmental circles. If you were hoping for the tech billionaire to make moonshot investments in unheard-of but highly effective charities, Bezos’s gifts will disappoint you. But if you were hoping for massive cash injections into well-financed, uncontroversial, and long-established organizations, Bezos fulfills your expectations.
“These first grants make it clear Bezos is entering the mainstream of US climate philanthropy. It’s hard to write an eight-figure check to any but the biggest, most established grantees,” said Daniel Firger, who oversaw Mike Bloomberg’s climate philanthropy.
Bezos is awarding $100 million each to the Environmental Defense Fund, the Natural Resources Defense Council, the Nature Conservancy, the World Resources Institute, and the World Wildlife Fund. Those five groups are among the largest environmental nonprofits in the country. The Nature Conservancy had almost $1 billion in revenue in the most recent fiscal year on file, and the other four had over $100 million each.
To be sure, some of the $791 million is going to less recognizable groups. But in his first major contributions, Bezos is largely playing it safe.
“I’ve spent the past several months learning from a group of incredibly smart people who’ve made it their life’s work to fight climate change and its impact on communities around the world,” Bezos wrote on his personal Instagram page. “We can all protect Earth’s future by taking bold action now.”
The announcement on Monday included the first concrete details on the program that Bezos had shared since launching it in February. Bezos has shared surprisingly few details about the initiative for months — and continues to offer little.
A Bezos Earth Fund representative on Monday declined to comment when asked about the structure of the fund and its ties to a new Bezos-started company that Recode reported on this summer. Bezos said he initially planned to start making contributions this summer, but is only unveiling his first grants now. The Earth Fund representative said that missed deadline was due in part to the Covid-19 pandemic, which is demanding more and more of Bezos’s attention.
The representative also said the fund did not yet have a leader — an unusual state-of-play for a charity already giving away hundreds of millions of dollars — but was in the process of hiring one.
The reason all that matters so much is that the $10 billion Bezos has promised is one of the largest charitable gifts ever and will reshape climate philanthropy. How Bezos sets up his charity, the speed with which he gives the money away, and the types of people that he hires will help determine how successful America’s billionaire philanthropists will be at solving the climate threat.
Bezos’s own company, Amazon, has been criticized by environmental activists for not doing enough to combat climate change in its corporate practices. Some of those criticisms have even come from some of the groups taking home money on Monday. That’s a reminder that billionaire philanthropy can potentially grant something to the giver, too.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
TikTok’s US ban has been delayed another two weeks — or maybe forever,"Remember when the Trump administration thought TikTok was a grave threat to America?
No?
Well, fair enough. The Trump administration also seems to have forgotten that it had planned on banning the Chinese video app, which is wildly popular with American kids.
That ban was supposed to go into effect yesterday, based on an August executive order that has already been amended once. In the original order, Donald Trump argued that there was “credible evidence” that ByteDance, TikTok’s China-based owner, “might take action that threatens to impair the national security of the United States.” 
ByteDance’s only option, supposedly, was to sell TikTok to an American owner. But a convoluted, complicated deal to sell some of TikTok to Walmart and Oracle has yet to be completed.
And as TikTok’s tens of millions of US users have noticed, TikTok is still working in the US, even though it didn’t meet yesterday’s deadline.
Last night, Trump’s Commerce Department said it was holding off on its would-be ban. Today, TikTok told a federal court that the Trump administration has given it and ByteDance another 15 days to work out its Walmart/Oracle deal. 
The extension comes days after TikTok complained that the Trump administration hadn’t said a word about TikTok’s proposed plan. TikTok’s new deadline to figure something out is November 27. 
But feel free to be skeptical about that deadline, too. Trump’s approach to TikTok, as well as WeChat, a Chinese-based messaging app he has also tried to ban, has been wildly erratic, even by Trump standards. At various times, Trump has announced that he would ban the app; or that he would force TikTok to sell itself to a US company; or that any deal would force TikTok to give a portion of the sales proceeds to the US; or that TikTok was going to contribute $5 billion to a fund “so we can educate people as to the real history of our country.”
It’s much more likely, in fact, that Trump hasn’t spent a lot of time thinking about TikTok and was instead hoping that his stance against a Chinese-owned tech company might help him rile up voters and/or donations for this month’s election, which he lost. 
But even that seemed like a half-hearted attempt: Aside from a couple weeks in August and September, Trump rarely mentioned TikTok, WeChat, his proposed bans, or the so-far-successful court challenges to those bans.
It probably would be good for US lawmakers to take TikTok seriously: There’s never been a Chinese-made consumer app with widespread appeal in the US, and there’s a legitimate debate about whether or not the app poses real security risks, and whether it is censoring content on its massive platform.
Ben Thompson, the American-born tech commentator who lives in Taiwan, for instance, argues that the US should ban TikTok because it’s a potentially powerful tool for Chinese propaganda and censorship. Tens of millions of Americans, meanwhile like using the app to create and watch memes and likely have no idea who owns the app.
But there’s a good chance this issue will keep getting kicked down the road, right into the lap of the Biden administration.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Vox Crossword,"What’s a four-letter word for a berry often found in a bowl?
Welcome to Vox crosswords. New puzzles, designed to test your knowledge and relieve a little stress, come out Monday through Saturday. Make sure to bookmark this page to find new ones each day. 
Puzzles are constructed by these great people, and edited by Vox staff.
This is a new feature for us: Are the puzzles too easy, or too hard? Have an idea for a theme? Spot a bug? Or if you just love our crosswords and want to make sure they stick around, email your feedback to crosswords@vox.com.
(Oh, and it’s acai.) Now, go play!






var puzzlecontainer = document.getElementById('xword-wrapper');
var puzzle = document.getElementById('voxpuzzle').contentWindow;


function receiveMessage(event) {
if (event.origin !== ""https://cdn3.amuselabs.com"") return;
if (!event.data) return;
if (typeof event.data !== 'string') return;
var data = JSON.parse(event.data);
  if (data.src === ""crossword"" || data.src === ""picker""){
  puzzlecontainer.style.height = data.frameHeight + 'px';
}
}
window.addEventListener(""message"", receiveMessage, false);



  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Why Fox and Trump can’t quit each other,"President Trump is acting badly. He is being supported by enablers in his government and by allies who fear him and/or want to take advantage of him. And he’s being supported by Rupert Murdoch’s Fox News.
So what else is new?
The stakes. There’s a very small chance that Trump could actually disrupt a peaceful transfer of power with his baseless claims of election fraud. He will, more likely, permanently damage America’s ability to hold elections by undermining much of the country’s faith in them.
It’s time for Fox to dispense with the bad-faith, bifurcated approach to the truth it has used for years, which allows its most popular stars to peddle lies to its audience under the guise that they’re merely offering their opinions.
That won’t happen, of course.
That’s in part because of Fox’s well-documented symbiosis with Trump, where its top talent — Sean Hannity, Tucker Carlson, Laura Ingraham, the Fox & Friends crew — act as Trump’s on- and off-air advisers and cheering squad. (Even this week, as Trump floats a trial balloon that he’ll ditch Fox and take his audience to a much smaller media operation, like Newsmax, or start his own “rival” network, his complaints on Twitter are about Fox’s news operation, not his TV pals.)
And it’s in part because Murdoch, who enjoys conservative politics but truly loves power, has an endgame in mind: By mid-January, Joe Biden will be president, and Fox News will be the disloyal opposition, a position where it thrives. 
What we’re seeing now is a warmup act. In one part of the Fox universe, Trump and his team are making as-yet-unfounded allegations of election fraud — or Trump and his team are fighting election fraud but everyone else is against them and it may not work out. 
Either way, we’ll get to the same point next year, where Fox News is very comfortable attacking the Democratic president — who some viewers will believe doesn’t have the right to be in office. 
As NPR media correspondent David Folkenflik reminded me in our chat this week on Recode Media, that’s a trope Fox News has used since its founding in 1996. It pushed the message that Barack Obama was (supposedly) an illegitimate president because he (supposedly) wasn’t born in the United States (not coincidentally, the main proponent behind this theory was ... Donald Trump). 
But in Foxland, Bill Clinton was also an illegitimate president — because he won his election with the help of Ross Perot, who ran as a third-party candidate and drew away votes that should have gone to George H.W. Bush.
So maybe Trump really will stop showing up on Fox and praising its talent on Twitter. Maybe he really will head to a would-be-rival TV network with minuscule ratings, or try to launch his own online service. Most likely, I think, he’ll end up as a recurring guest on Fox News, where he can keep doing what he does best — rant daily, without having to do anything else — and Murdoch can keep Trump’s fans on his network. Either way, when Trump leaves the White House, Fox News will spend the next four years laying into his successor.
But in the meantime, Murdoch is once again trying to have it both ways: His news operation — the one Trump tweets angrily about — has told its viewers that Trump lost the election and that his complaints about voter fraud are made up. But in the morning, and at night, it’s a different story.

Last Friday, for instance, Hannity brought on Republican National Committee Chair Ronna McDaniel for a segment in which they both suggested that voter fraud was quite plausible. That was not a coincidence: According to a GOP memo Folkenflik viewed, the two sides worked out with “great specificity the intended flow of the show’s lengthy opening segment — including its guests, articles and subjects — and the primary points Hannity would make.”
On Tuesday night, Ingraham hosted someone who said they were a poll worker in Nevada (her guest’s face and voice were disguised) who claimed to have seen some kind of Biden-Harris ballot chicanery.



This is where we're at right now.Laura Ingraham brings on an unidentified ""whistleblower"" -- with hidden face and altered voice -- to claim that folks literally from a Biden-Harris bus were altering ballots in Nevada. pic.twitter.com/b8xGe8KXSb— Justin Baragona (@justinbaragona) November 11, 2020



And on Wednesday night, Carlson explained that the mainstream media is refusing to look into plausible vote fraud allegations (Trump’s campaign tweeted this one out; Trump retweeted it):


The liberal media says voter fraud doesn't happen. They're lying.Someone used the identities of dead people to vote in the presidential election. Here's the proof. pic.twitter.com/iFLWvfUvIE— Trump War Room - Text TRUMP to 88022 (@TrumpWarRoom) November 12, 2020



Hannity, Carlson, and Ingraham do their own version of the Fox News two-step: They don’t come out and say outright that Trump is a victim of massive voter fraud that cost him the election while simultaneously defeating Democratic House and Senate candidates. But they argue that it’s plausible. They feed the fire with oxygen.
Fox isn’t the only one playing this game. Much of the Republican Party, from Senate Majority Leader Mitch McConnell on down, engages in a similar version: either flat-out suggesting that Trump’s claims are legitimate or at least arguing that he should be able to make those claims and then see what happens. 
It’s easy for anyone who wants to look to see what’s really happening. There’s the objective truth — hammered away at by the likes of the New York Times, which ran “Election Officials Nationwide Find No Fraud” as its banner print headline on Wednesday. 
Republicans are eager to tell reporters the same thing but won’t attach their names to their statements. On background, they announce that they’re simply humoring Trump, or treating him, toddler-like, as someone who needs to be gently prodded into accepting his loss. Some Republicans are telling CNN’s Jake Tapper that this is “all part of walking President Trump through this process emotionally.” Or they say that Trump is in on the joke: A “top White House aide” tells NBC’s Peter Alexander that Trump realizes his claims are “theater.”
This is all par for the course for the past four years, and beyond: If you consume a steady diet of Fox News and nothing but, you see the world very differently than the rest of America, even when it comes to life-and-death issues like the Covid-19 pandemic. (It may also matter which Fox host you like more: A study this spring concluded that Fox viewers who watched more of Hannity, who consistently downplayed the coronavirus in the spring, were more likely to contract Covid-19 than Fox viewers who watched more of Carlson, who was the rare Fox opinion host who warned viewers about the pandemic early on.)
And maybe this is the time we’ll get lucky, and the viewers of the country’s most popular news channel will eventually come around to the idea that Joe Biden is a legitimate president. As of this week, at least 80 percent of the country — and 60 percent of Republicans — say Biden won, per a Reuters/Ipsos poll.
On the other hand: Four years ago, just weeks after the presidential election, a 28-year-old man with a semiautomatic assault rifle walked into a pizza place and fired his gun because he was trying to “shine some light” on claims that Democrats ran a pedophile ring. At the time, “Pizzagate” was a dark conspiracy that lived mostly online; Tucker Carlson wasn’t doing segments on Hillary Clinton’s link to sex traffickers. (It hasn’t gone away, either: Pizzagate has now merged with QAnon, an all-encompassing conspiracy theory that is just as extreme but has become mainstream enough that it is sending adherents to Congress.)
Now Fox News is dancing with a conspiracy theory that could be equally upsetting to an angry, suggestible audience. The best-case scenario is that Fox merely convinces its audience that voting is rigged against them. And its viewers are content to just watch Fox, seething.
But that’s a terrible range of outcomes. We shouldn’t expect better from Fox’s leaders. But we should definitely ask them to do better.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Facebook’s election woes are headed to Georgia,"Less than a week after Joe Biden secured a victory in the 2020 presidential election, it looks like Facebook’s post-election plan is already backfiring.
On Wednesday, the company announced it would extend its ban on political ads for at least another month, and possibly longer, in an attempt to quell confusion over an election that President Donald Trump lost but still hasn’t conceded. Google similarly told advertisers it was unlikely to lift its political ad ban in November or December, according to the Wall Street Journal. 
Since the 2016 election, Facebook has sought to avoid intense and continued criticism over its policies on political ads. Now, as the latest presidential election season is drawn out by an extra couple of months due to the dual runoff in Georgia that will decide control of the Senate, some claim the political ad ban’s extension constitutes voter suppression.
The frustration with Facebook’s handling of the election extends well beyond its political ad policy. Democrats and others have condemned the social media platform for enabling viral misinformation. The Biden campaign, in particular, has criticized Facebook’s approach, which often involves applying mealy-mouthed labels to content rather than removing posts that push conspiracy theories about voter fraud and sow doubt in the election. At the same time, Republicans complain that Facebook is systematically biased against conservatives and that tech companies unfairly censor right-wing voices. (These complaints usually lack evidence.)
The week after the election, Facebook seemed to respond to the litany of criticism in a blog post. The company wrote that, despite conservatives frequently dominating the lists of the most-engaged content on its platform, most of what people see on Facebook is not hyperpartisan political content.
Both sides are upset about how the platform treats organic content, but they’re also anxious about maintaining their ability to advertise on Facebook — a way to more directly spread their messaging on the site. So as the presidential election begins to appear in our rearview mirror and the Georgia runoff approaches, the problem of Facebook being bad for democracy — one that Facebook itself has admitted to — isn’t going away.
The Georgia runoff has both parties mad at Facebook — again
In Georgia, Democrats Jon Ossoff and Raphael Warnock are challenging Republican incumbents Sens. David Perdue and Kelly Loeffler, respectively, in separate races in January.
Because Facebook and Google are not allowing any political ads to run on their platforms, which is an extension of previous policies, the candidates haven’t been able to use the two highly valued digital platforms to reach voters with advertisements or supply them with information about Georgia’s somewhat unusual runoff-election process. This, of course, is happening in the midst of a pandemic, when in-person campaign activities are limited.
While Google has not revealed much about its plan to extend the political ad ban, Facebook’s director of product management, Rob Leathern, took to Twitter on Wednesday to offer more details about his company’s decision, explaining that the company’s systems don’t have a way to enable an exemption to the political ad pause for individual advertisers.




Critics quickly pointed out that Facebook, which is worth hundreds of billions of dollars, has had years and a seemingly endless supply of resources to build this feature.
Neither Facebook nor Google responded to a request for comment.
The extension of the ad ban has left the Georgia Senate candidates to question how Facebook — and, to a lesser extent, Google — will continue to impact the election. The Democratic Georgia Senate campaigns have accused Facebook of allowing its algorithms to boost misinformation and hyperpartisan, right-wing accounts.
Miryam Lipper, communications director for the Ossoff campaign, told Recode in a statement that the companies “are putting their fingers on the scale for millionaire Republican candidates” and “ignoring the rampant disinformation on their platforms.” Terrence Clark, a spokesperson for Warnock’s campaign, said that by “preventing campaigns from sharing crucial information about how to register to vote, sign up for an absentee ballot, and how to ensure their vote counts,” the platforms were engaging in voter suppression.
Meanwhile, Republicans have resorted to accusing the social network of anti-conservative bias, which has become the party’s signature talking point on tech companies. In a tweet Thursday, Loeffler accused the companies of “silencing conservatives” and “suppressing free speech.” Perdue’s campaign spokesperson told Recode the bans constituted “an infringement of basic First Amendment rights.”
Republicans and Democrats have dueling complaints about Facebook
While their particular grievances may be different, politicians from both parties have been increasingly vocal about their frustrations with Facebook since the 2016 election. Things especially heated up in the weeks before November 3.
For example, conservatives fumed after the platform limited the distribution of a New York Post story about Hunter Biden. The outrage ultimately spurred a Senate hearing in which Republicans pushed their claim that Facebook, among other social media companies, was tampering with the election. Members of both parties were also angered when Facebook inadvertently blocked a slew of campaign advertisements from going up days before the election.
The frustration over Facebook’s ad policies reflects both sides’ broader frustrations with its handling of organic content. Democrats seem like they’re only growing more upset about rampant misinformation on the platform in the days after the election. Bill Russo, a Biden spokesperson, recently accused the company of “shredding the fabric of our democracy” in a series of tweets lambasting Facebook’s failure to clamp down on content that promoted Trump’s false accusations of widespread voter fraud and claims of victory.


We knew this would happen. We pleaded with Facebook for over a year to be serious about these problems. They have not. Our democracy is on the line. We need answers.— Bill Russo (@BillR) November 10, 2020



At the same time, conservatives, including the Georgia Republican Senate candidates, have continued to argue that Facebook is censoring them. 
Other Republican frustrations with Facebook concern its voter registration efforts. Trump’s digital director once argued, without evidence, that Facebook’s attempt to register voters was a ploy to register more Biden voters than Trump voters. Some Republican secretaries of state even wrote to the company objecting to its Voter Information Center, an online platform for helping people register to vote, discouraging the effort and arguing it was redundant.
With what’s happening with Georgia, it seems clear that neither side will let up in their criticism of Facebook. At the same time, this latest episode is a reminder that companies like Facebook and Google have by no means perfected their policies toward US elections, and that political content, from misinformation to candidate advertisements to hyperpartisan Facebook pages, do not exist in a vacuum.
In this most recent case, the move to extend a ban on political ads might have a technical explanation. But for the candidates in Georgia, it has a real impact on their campaign plans.
Facebook’s policies leading up to one state’s runoff elections could influence which party controls the Senate — and whether Biden can push through a ledger of Democratic policies without hurdles from Republicans. It’s a reminder that the company’s influence over politics seems to only be growing.
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
How Biden’s FCC could fix America’s internet,"When Joe Biden is inaugurated as president on January 20, he stands to oversee a Federal Communications Commission (FCC) that could do remarkable things. Among other things, the new FCC could bridge the digital divide, ensuring all Americans have access to the internet. But even though Biden’s victory is assured, the future of the FCC hangs in the balance. 
The Trump administration’s FCC has had a particular agenda. Under the leadership of Chairman Ajit Pai, the agency has pushed to deregulate the industries under its purview and, in turn, to create a business-friendly environment with few rules, little accountability, and minimal oversight for some of the biggest and most powerful companies in the world. In the months and years to come, the FCC is likely to reverse some of those policies, especially Pai’s most controversial decision: repealing net neutrality, a policy that required internet service providers to treat all types of internet traffic the same. But getting broadband internet in as many homes as possible during the pandemic is many Democrats’ most urgent goal, and one they feel the Trump administration failed to accomplish.
“Because the Trump FCC failed to meaningfully address the digital divide, tens of millions of Americans still lack high-speed internet,” Rep. Anna Eshoo (D-CA) told Recode. “This worsens the impacts of the pandemic, and the Biden administration has to take this head-on.”
She added: “Every person in our country must have high-speed internet. Period. We’ve failed for too long to expand access to rural and tribal areas, and too many urban communities can’t afford broadband.”
The Biden administration’s FCC can and likely will aid this effort by making the internet more affordable and accessible. This could involve providing more subsidies to lower-income people, continuing its work increasing broadband access, and opening up more radio frequency bands for high-speed 5G networks in order to bring the United States to the level of its peers. The agency is also poised to restore net neutrality and reclassify broadband internet as a Title II service, which would give the FCC more authority over carriers. Under the Biden administration, the agency will also probably let Trump’s anti-social media Section 230 rulemaking mission die. 
With these goals in mind, Biden will get to pick a new FCC chair, who will do much to set the agency’s agenda. Beyond that, we don’t yet know who that chair will be, how many of the five commissioner seats will be available to be filled, or which party will have control of the Senate. A Republican-majority Senate may well make it much more difficult to confirm new commissioner appointments or refuse to vote on laws that could provide funding needed for Democrat-chaired FCC initiatives.
Experts and FCC insiders told Recode they foresee a Biden FCC that goes back to trying to govern and reclaims some of the authority it ceded under Trump. And the FCC’s glass ceiling may finally break with the first chairwoman in its 86-year history.
Where the FCC is now
The legacy of Pai’s FCC will be a “light-touch” approach and mass scale deregulation. Proponents say this encourages investment and innovation, and opponents argue that it favors businesses at the expense of consumers. While Pai’s FCC has made an effort to bring broadband internet to rural and tribal communities — which overwhelmingly benefits red states — it hasn’t done much to make those services affordable to lower-income people.
“We still don’t really know what the results of [Pai’s] multi-billions of dollars to rural internet service providers will be,” Gigi Sohn, a distinguished fellow at the Georgetown Institute for Technology & Law Policy who was a staff member of the FCC during the Obama administration, told Recode. “I hope it results in a lot more people being connected, but that’s the smallest part of the digital divide. The biggest part of the digital divide is affordability. He never talks about that.”
Much to the consternation of many Democrats, including the FCC’s Democratic commissioners Jessica Rosenworcel and Geoffrey Starks, the agency has dragged its feet on updating programs like E-Rate and Lifeline that could help people afford increasingly necessary internet services in their homes.
Pai will perhaps best be remembered for repealing the Obama-era’s net neutrality decision, which he vehemently opposed as a minority party commissioner. When Trump took office and promoted Pai to chair, he immediately set about undoing that decision. Under Chairman Tom Wheeler, the Obama FCC had classified broadband internet as a Title II service, subjecting it to increased oversight and establishing internet service as a necessary utility for Americans. This meant internet access would no longer be treated as a luxury, like cable television, but rather protected and ensured like telephone service. Pai’s FCC reclassified broadband as a Title I service which was largely under the purview of the Federal Trade Commission.
This was perhaps one of the most controversial decisions in the FCC’s history, seen by its opponents as a gift to internet service providers that could now charge consumers more for accessing certain sites or using different internet services. Pai framed it as “restoring internet freedom” and encouraging internet service providers to pour more money into extending their reach across the country without having to worry about burdensome regulations that would cut into their bottom line. Pai’s order was protested by millions of Americans, in person and online. Meanwhile, millions of comments supporting the end of net neutrality were determined to be fake.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        One of the many protests against the Trump FCC’s net neutrality repeal.
      
      
        Chip Somodevilla/Getty Images
      
    
  


So that’s how Pai’s FCC began. Here’s how it’s going: Pai’s reign will likely end, ironically enough, with an attempt to introduce more regulation through Section 230, a 25-year-old law that lets websites moderate third party content as they see fit without being liable for that content (with a few exceptions). Simply put, you can sue a Twitter user if they tweet something defamatory about you, but you can’t sue Twitter. This is what allows websites that rely on user-generated content to exist. Trump hoped to weaponize the FCC, a supposedly independent agency that has become increasingly partisan in recent years, against social media companies that he believes censor conservative speech by making rules that could remove their Section 230 protections.
Repealing or significantly changing Section 230 has become Trump and his surrogates’ rallying cry in the latter half of his one-term presidency. But Republican lawmakers’ bills that would change Section 230 to force platforms to be “politically neutral” in their moderation or make their moderation rules more transparent and clear to users have so far come to nothing. An executive order Trump issued in late May attempted to circumvent the legislative process by asking the FCC to “clarify” what content platforms can and cannot moderate if they want to keep their Section 230 protections. Some scoffed at this authority, arguing that it was both wrong and in direct conflict with Pai’s reasoning behind repealing the Obama-era’s net neutrality rules. In effect, Pai’s willingness to accede to Trump’s demands over Section 230 means his tenure, once defined by the desire to impose as few rules as possible on private businesses, will likely end with a failed attempt to introduce more rules on some of the biggest companies in the world.
Rosenworcel and Starks have publicly stated that they do not think the FCC should play a role in Section 230, and this opinion seems to be shared by Democratic lawmakers. While Biden expressed a desire to revoke Section 230 to the New York Times in January — an opinion that a campaign spokesperson told Recode he hasn’t changed — he has yet to follow that up with any proposed action to do so, and Section 230 is not likely to be a major priority for the administration anytime soon.
The Trump FCC could still try to get something done with Section 230 before the administration changes hands. But the agency almost certainly doesn’t have enough time since it still needs to confirm a new commissioner in order to get the majority it would need to do anything meaningful. House Democrats have also asked the FCC to stop any work on controversial items. This request was made of the Obama FCC when Trump won the election, and it was followed. At the time, then-commissioner Pai issued a statement supporting the pause, so it would be hypocritical for him to forge ahead with the controversial Section 230 business.
Wheeler, who was the FCC chair during Obama’s second term, said he would be disappointed in Pai if he refused to honor the Democrats’ request but not necessarily surprised: “It wouldn’t be beyond the way that the Trump administration has been operating: ‘It’s all about us.’”
Pai has yet to publicly acknowledge that Biden won the election at all. When Recode asked  about his plans during the transition period, he did not respond.
Who will be on the FCC when Biden takes office
The FCC can only have three commissioners from the same political party and currently has a 3-2 majority of Republicans. But it won’t have the same lineup when Biden takes office. Michael O’Rielly, a Republican commissioner nominated by Obama, finished his first full term in July 2019. But Trump rescinded his renomination after O’Rielly stated that he didn’t think the FCC should regulate Section 230. Trump then nominated National Telecommunications and Information Administration (NTIA) senior adviser Nathan Simington, who assisted in carrying out Trump’s anti-Section 230 executive order and is seen as a Trump loyalist.
But Simington is not a sure thing to be confirmed before Biden takes office. Republicans likely feel that they have more important things to address before they lose the executive branch in January, and they may want to go with a commissioner they pick instead of the outgoing president’s choice, which was largely based on his personal vendetta against social media companies. 
At his confirmation hearing before the Senate Commerce Committee on Tuesday, Simington wouldn’t commit to supporting Democratic initiatives like expanding the E-Rate program, which provides discounted internet access to schools and libraries, into homes that have become classrooms during the pandemic. Perhaps in an attempt to demonstrate how much work is now being done in alternate spaces, Sen. Ed Markey (D-MA) asked Simington about E-Rate via video chat from the backseat of his car. He did not seem to like Simington’s answers. Meanwhile, Sen. Richard Blumenthal (D-CT) threatened to place a hold on Simington’s confirmation because of his association with Trump’s Section 230 executive order. A spokesperson for Blumenthal told Recode that the senator has “significant concerns” about Simington’s independence, integrity, and judgment.
And then there’s Pai’s future. Biden will get to appoint his own chair when he takes office, and chairs traditionally leave the agency when a new administration comes in. But Pai won’t have to do that — he can stay on as a commissioner until his term expires, which could be as late as 2023. It’s hard to see Pai wanting to stay at the FCC in a lesser role, but Republicans may ask him to stay to have a 2-2 split if Simington is not confirmed. The most likely outcome, however, is that Pai packs up his trademark giant mug and goes. 
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        A large mug, and outgoing FCC chairman Ajit Pai.
      
      
        Alex Wong/Getty Images
      
    
  


“It really is a fascinating situation here,” Wheeler said. “If Ajit sticks with precedent, then it’s 2-1 [with a Democratic majority]. If he doesn’t, then he can stymie any action until the Republicans in the Senate decide it’s time to approve somebody.”
There is also the question of who Biden will select as the FCC’s new chair, if he does indeed get the opportunity. Many believe that Biden will appoint a woman here, as the FCC has never had a chairwoman in its 86-year history (unless you count Mignon Clyburn’s acting chairwomanship for several months in 2013). Clyburn and Rosenworcel have been circulated as likely choices here. Both have FCC experience and both have championed broadband affordability and expanding the Lifeline program, which subsidizes phone bills for low-income people, to include broadband internet.
But Clyburn seems to have moved on from her time at the FCC, which ended in 2018. She joined the boards of Lionsgate in July and RingCentral, a cloud communications provider, in November. The Senate would also have to confirm Clyburn, and with a Republican majority it may well refuse to do so. That could be a point in Rosenworcel’s favor, since she doesn’t have to be confirmed. Rosenworcel has long advocated for FCC measures to close what she calls the “homework gap” between students who have access to reliable high-speed internet to do their schoolwork at home and students who don’t. That gap has never been more apparent or destructive than during the pandemic. 
“Commissioner Jessica Rosenworcel is brilliant and effective, and possesses a broad and deep knowledge of all things FCC,” Rep. Eshoo said in an email. “Hands down, she’s my #1 choice for Chairwoman of the FCC. She would hit the ground running from Day One.”
Of course, it’s also entirely possible that Biden nominates someone else — perhaps even someone completely unexpected — to head up the FCC. Clinton-era FCC chair Reed Hundt, for example, was unknown and had very little to no telecommunications experience before he was appointed. He was, however, Vice President Al Gore’s college roommate.
“I know that a whole bunch of people want it,” Wheeler said. “The fact of the matter is that Joe Biden’s been around this town for 47 years. He knows a lot of people, and it doesn’t have to be the usual suspects.”
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        Former FCC Chairman Tom Wheeler with then-commissioner Mignon Clyburn (left) and Jessica Rosenworcel (right) in 2015. Both women are rumored to be likely picks as the next FCC chair.
      
      
        Mark Wilson/Getty Images
      
    
  


What the FCC will do
Having a Democratic majority will make it significantly easier for whoever becomes the new FCC chair to accomplish their vision. But even without that advantage, there are ways to get things done.
“There’s still a lot you can do because the chair controls the bureau and the offices,” Harold Feld, senior vice president at open internet advocacy group Public Knowledge, told Recode. “And you can do a lot on what’s called delegated authority. … The chairman is not toothless in terms of the ability to use the power of the FCC.”
What’s pretty clear is that a Biden FCC will want to do as much as possible to address the digital divide. Broadband affordability is a major part of this. Along with expanding E-Rate and Lifeline programs and continuing work to increase access in rural and tribal areas, expect a Biden FCC to reverse the net neutrality repeal and reclassify broadband internet as a Title II service under the Communications Act. This would subject broadband internet carriers to the same increased oversight and rate regulations that phone companies have. So, where Pai had to ask companies not to cut off homes or businesses from the internet if they couldn’t pay their bills during the pandemic and to expand their low-income programs, an FCC that classified broadband as a Title II carrier would have more leverage to require it.
There is also one possible privacy benefit if internet service providers become Title II carriers, as Wheeler pointed out. Under Title II, the FCC was able to establish the authority to require ISPs to get consumers’ permission before sharing certain information about their internet lives, including browsing history, location, and email contents. This was seen as a big win for data privacy, and Wheeler hopes that the new FCC will find a way to restore those privacy protections.
The Biden FCC will also have to help facilitate the spread of 5G across the country and will be responsible for freeing up more bands in the spectrum to provide it. Increased 5G access would give more Americans access to higher internet speeds in more places, which has become a priority during the pandemic. While the current FCC is already working on this effort, some think the Biden administration will promote the inter-agency cooperation necessary to do it quickly. During the Trump administration, different agencies fought over spectrum, which held back efforts to open up more bands and expand 5G’s potential.
“The way that Trump ran things was to set everybody against each other,” Feld explained. “It has become much more of a problem in that federal agencies have now just increasingly said ‘no’ to the FCC. ... It’s critically important that a Biden administration takes steps to smooth this over.”
All this said, it’s hard to say with certainty just what the Biden administration can do, especially when it comes to this already atypical transition process. The uncertainty regarding the new FCC even extends now to when and if the Biden transition team will get access to the FCC, or if the Trump administration will hold out for as long as possible just to make life difficult for the Biden team. Given the issues on the table — bridging the digital divide, restoring net neutrality, and expanding 5G — any delay in getting the new FCC running would ultimately be to the detriment of the American people. But there will be a new FCC eventually. 
“It’s gonna be interesting,” Wheeler said. “This will be a great time to be chairman of the FCC.”
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Social media is making a bad political situation worse,"When Eli Pariser coined the term “filter bubble” a decade ago, he narrowly defined it to be a situation in which algorithms skew the variety of information we get online in favor of stuff we like. At the time, he worried that might lead to political polarization through less exposure to divergent viewpoints. 
Ten years later, America is in the aftermath of a hyperpartisan presidential election in which people not only disagree with those on the other side, they actively hate them. Different parties are operating in what seem like different realities, with different sets of facts or at least completely different reactions to those facts. Social media seems to be making a bad situation worse.
A divided America was on full display as record rates of voters turned out, in part to vote their own guy in but, perhaps more trenchantly, to keep the other guy out. Biden won by a close 4.6 million votes (so far) in an election with an expected turnout of 159 million voters. Some of the political lessons we learned recently include that conspiracy theories have real currency — fake news can spread faster than real facts on social media — and that if we don’t agree on a shared reality, more mundane things like political compromise will remain out of reach.
Filter bubbles are undeniably part of the problem, but their causes, consequences, and solutions seem less clear than they used to be. Part of the issue is it’s often difficult to understand which comes first: a polarized situation or the social media that aggravates that situation. Rather, it’s become a self-reinforcing system.
“The inputs are also the outputs,” Pariser told Recode recently, describing how our differences are magnified online. “Where I live and who my friends are and what media I consume all shape what I see, which then shapes decisions I make about what media I consume and where to live and who to be friends with.”
And by a number of accounts, those inputs are getting more extreme.
The inputs
We’re living at a heightened time of partisanship — and not in the “we have differences of opinion” kind of way. And those divides have a way of compounding through social media.
Animosity toward members of opposing parties is very high even though our divisions over policy preferences don’t appear to have grown, according to new research published in Science magazine. The paper brings together a number of different studies on the topic and is written by scholars from six disciplines who found that, these days, we’re more likely to hate the opposing side and consider them to be “different,” “dislikable,” and “immoral.” The result is a “political sectarianism” in which one’s party identity seems to come first, before policy, religion, or common ground. Political identity, in turn, shapes our other views instead of the other way around. For example, after seeing a clip of Donald Trump espousing a liberal policy, followers exhibited a more liberal attitude, according to the paper, which presumes Democrats would do the same for their political leaders.
  
  
    
    
      
        
  


  






      
    
    
  
  


The results of this kind of alignment are disastrous for a functioning democracy. As the researchers argue, “holding opposing partisans in contempt on the basis of their identity alone precludes innovative cross-party solutions and mutually beneficial compromises.”
Other researchers believe severe inequality puts America at the brink of political violence.   BuzzFeed recently wrote about a so-called “political stress indicator,” created in part by a sociologist who previously led the CIA’s State Failure Task Force, that incorporates a variety of statistics, including wage stagnation, national debt, inequality, and distrust of government, among others. The indicator currently shows American political instability to be in line with the lead-up to the Civil War.
Then there’s distrust — encouraged by the president — of facts and journalism organizations, which are necessary to protect democracy. A series of Pew Research Center polls shows that Republicans rely on and trust fewer news sites for politics than they used to, with Fox News, Trump’s mouthpiece and a fount of disinformation, being one of few sources they regularly read and believe. However, research by Andy Guess, assistant professor of politics and public affairs at Princeton University, looks at web traffic rather than people’s survey responses to reveal that there’s considerable and consistent overlap in media consumption between the parties, except among a smaller set of extremists. This suggests many people might be reading the same sources but coming to totally different conclusions. Wildly divergent interpretations of the same news is a more difficult problem to fix.
The outputs
Hyperpartisanship, tense societal factors, and divergent news diets — or at least divergent interpretations of the news — are then fed back through social media, which is likely amplifying our divisions. We don’t know exactly how the social media algorithms work that select what information we see because the technology is a black box controlled by the respective social media company that built it.
What we do know is that Facebook has put less of an emphasis on news and more on engagement, and that posts with strong, emotional language have more engagement. We also know Facebook has continually promoted Groups since 2016, which can function as their own echo chambers, even without algorithmic help. YouTube, whose algorithms like other platforms were designed to make people spend more time on the site, has been shown to radicalize people through inflammatory messaging. Most recently, it has been awash in election misinformation.
“There’s little doubt in my mind that the way our media ecosystem works is enflaming political sectarianism,” Eli Finkel, one of the authors of the aforementioned Science paper, told Recode. “Social media is not focused on making the world a better place; it’s primarily focused on engagement, so it listens to us and gives us what we want.”
  
  
    
    
      
        
  


  






      
    
    
  
  


We also know that more people are getting their news from social media. The share of Americans who often get their news from social media grew 10 percentage points to 28 percent last year, according to Pew. Those who mainly get their news that way were also less informed about current events and more likely to have been exposed to conspiracy theories.
Funnily enough, despite getting so much news from social media, Americans don’t trust it. 
“Distrust about social media platforms is one of few places Republicans and Democrats agree,” Katerina Eva Matsa, associate director of journalism research at Pew, told Recode.
A new study from the University of Virginia found increased Facebook usage among conservatives is associated with reading more conservative sites than they normally do. The effect was less dramatic among liberals.
The study’s authors conjectured that the way Facebook works might have something to do with this outcome. In addition to algorithms favoring engagement, the very structure of Facebook limits who we talk to: You have to “friend” others to see their posts, meaning you’re less likely to see people outside of your real-life friends and family, who are more likely to have similar lives and viewpoints. Facebook also tweaked its algorithms after the 2016 election to promote posts from friends and family and show far fewer posts from news outlets, which likely further contributed to filter bubbles and division.
“These platforms at this point are huge, they’re mature, they have all sorts of resources, all sorts of ability to figure out ahead of time — and certainly monitor afterwards — what kind of impacts all of their algorithmic tweaks are having on users’ information consumption,” study co-author Steven L. Johnson told Recode.
Pariser had originally thought filter bubbles could be deflated by exposure to different viewpoints. But that doesn’t appear to be the case.
Research highlighted in the Wall Street Journal suggests that people on social media do see opposing viewpoints. But since sites like Facebook are calibrated to highlight posts that elicit reactions, we’re seeing the most acerbic of opposing views, which can lead people to be even more repelled by them. The result is even more entrenched viewpoints and more polarization.
What to do about it
The answer to all this polarization isn’t easy. It likely involves huge structural changes in our society to deal with inequality, investments in public institutions like schools and libraries,  as well as serious, truthful, and mediated discussion between people of opposing viewpoints. 
It doesn’t require more social media — at least not in its current iteration.
“It’s not just a matter of coming into contact with the other side,” Pariser told Recode about how his conception of filter bubbles has changed since he first coined the term. “It’s doing so in a way that leads us to greater understanding.”
And the way opposing views are presented on social media is not leading to greater understanding. Conversations on Facebook and Twitter, for example, happen through text, not voice, which can be another impediment to understanding. Pariser pointed to work by Berkeley professor Juliana Schroeder that shows conversations through text fail to garner the empathy evoked through hearing someone’s voice, making it an unproductive medium for constructive conversations.
“It’s sort of like the ‘don’t have an argument by text with your partner’ [rule], but for society,” Pariser said.
Mediating thoughtful in-person conversations, of course, is expensive, and it has been even harder to do during a pandemic, when being face-to-face with people outside your household is actually dangerous. 
But it’s more necessary than ever.
Social media companies are constantly tinkering with how their platforms work, so perhaps that’s a way forward. In the lead-up to the election, Twitter and Facebook were able to limit misinformation spread on their platforms much more effectively than they had before, by more actively taking down or marking misinformation and limiting its spread. But as New York Times tech columnist Kevin Roose pointed out, these platforms did so by mitigating their own major features.
Social media companies may not have a choice if the government steps in and forces them to make changes. They are under increased scrutiny from the government to quash misinformation and to disclose how the information they see might differ from what others see. And advertisers, social media’s main source of revenue, can also choose to vote with their spending.
However we get there, it’s high time we deal with how social media has made a bad political situation worse. 
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Amazon gets hit with antitrust charges in Europe,"The European Union announced antitrust charges against Amazon on Tuesday, alleging that the online retail giant has broken EU competition laws by using non-public data from the small-business merchants who stock its virtual shelves to compete against those same sellers.
Amazon’s use of seller data to compete against its own merchants has also been a focus of antitrust probes in the United States, both in Congress and at the Federal Trade Commission. Now the European Union has announced that it believes the tech giant’s data-mining practices in Germany and France have broken EU competition laws.
“We must ensure that dual role platforms with market power, such as Amazon, do not distort competition,” Margrethe Vestager, the EU official overseeing digital competition, said in a statement. “Data on the activity of third-party sellers should not be used to the benefit of Amazon when it acts as a competitor to these sellers.”
In a statement, Amazon said it disagrees “with the preliminary assertions of the European Commission and will continue to make every effort to ensure it has an accurate understanding of the facts.” 
“No company cares more about small businesses or has done more to support them over the past two decades than Amazon,” the company added, noting that more than 150,000 European businesses sell through its online stores. 
More than half of Amazon’s global product sales come from small and midsize merchants who list merchandise for sale on its site. Amazon also stocks and sells merchandise itself, including an assortment of Amazon-branded products. Both in Europe and in the US, antitrust officials and lawmakers have been scrutinizing how Amazon uses non-public data from its sellers’ performance on the site to compete against them, by acting as a reseller of other brands’ merchandise as well as by creating Amazon-branded products for sale.
In the EU case announced on Tuesday, the competition commission said Amazon’s data-harvesting practices allow “Amazon to focus its offers in the best-selling products across product categories and to adjust its offers in view of non-public data of competing sellers.”
The case against Amazon in Europe has been expected for months, and Amazon now has an opportunity to formally respond to the charges. Outcomes can range from severe monetary penalties to a settlement between the two parties to even the case being dismissed.
The same commission also announced a separate antitrust investigation focused on Amazon. The probe will look at whether Amazon unfairly prioritizes merchandise for sale that uses Amazon’s warehouse storage and shipping program, known as Fulfillment by Amazon (FBA). Historically, Amazon sellers who want their listings to carry a Prime shipping badge typically have had to use the FBA program. And Amazon’s “Buy Box” — which features the winning seller for a given search query — typically favors items that carry the Prime badge.

  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Is social media ready for a Covid-19 vaccine?,"On Monday, Pfizer and BioNTech announced in a press release that their vaccine candidate was more than 90 percent effective at preventing Covid-19 infection, based on initial results from their ongoing phase 3 clinical trial. The company expects to have applied for emergency use authorization with the Food and Drug Administration (FDA) by the end of November and could have as many as 50 million doses produced by the end of 2020. 
This is tremendous news — and misinformation about it is already circulating on social media. According to research from VineSight, a slew of Twitter accounts, including those of Donald Trump Jr. and Sen. Ted Cruz, are already questioning the timing of the results’ release just days after the presidential election. By midday, tweets pushing that narrative had racked up more than 20,000 shares. The researchers estimate that Donald Trump Jr.’s tweet alone could have been seen by nearly 7 million people.  


The timing of this is pretty amazing. Nothing nefarious about the timing of this at all right?   https://t.co/nS5rkywKXT— Donald Trump Jr. (@DonaldJTrumpJr) November 9, 2020



The dream of bringing a speedy end to the pandemic is a complicated one. Even when a vaccine does win initial FDA authorization in the United States, we should expect a lengthy period of “chaos and confusion,” one expert recently told the New York Times. Much of that disarray could play out on social media.  
From the possibility of multiple vaccines to regionally distinct distribution plans to still-evolving research, the process of vaccine implementation is already stoking anxiety and misinformation. Since the pandemic began, Facebook, Twitter, and YouTube have faced pressure to combat conspiracy theories about Covid-19 vaccines. When one or more vaccines are ultimately offered to the public, the companies will also need to continue to promote accurate information about ever-evolving public health precautions. And they must act sooner rather than later to grapple with the task of communicating and moderating this next period of the pandemic, according to Jennifer Reich, a sociology professor at the University of Colorado Denver who has studied vaccine hesitance.
“This is not going to be magic,” Reich told Recode. “I think that the way the vaccine has been messaged has been like, ‘Just wait till we have a vaccine and then we can all go back to life as normal.’ That’s probably not a realistic expectation.” 
Public health and social media experts told Recode that social media companies should expect anti-vaccination communities to use social media to capitalize on peoples’ understandable concerns about a potential Covid-19 vaccine. At the same time, many will be confused and frustrated at the distribution of the vaccine, and some may be angry when they see others getting a vaccine before they do. That will come amid conspiracy theories and other misinformation that has already spread about potential Covid-19 vaccines.
Basically, it could be a very, very complicated mess.
In preparation for a vaccine, social media platforms are fine-tuning their rules
As news of a viable vaccine draws closer, social media companies are fine-tuning their policies in anticipation of misinformation and changes in public health guidance. Notably, their approach seems similar to how they’ve moderated content around the 2020 presidential election as well as the pandemic in general. Facebook, Twitter, and YouTube have looked to elevate reliable sources, like local officials and organizations such as the Centers for Disease Control and Prevention (CDC) and the World Health Organization (WHO), and they say they will continue turning to official sources of health information if and when a vaccine is announced. 
Facebook has changed its approach to clamping down on misinformation, evaluating the need for accurate public health messaging in recent months. For much of the pandemic, the company had a policy of taking down misinformation that could cause imminent, physical harm, like the false claim that face masks cause Covid-19, and reducing the prominence of vaccine hoaxes flagged by global health authorities in places like its News Feed and search. But starting this fall, Facebook became more proactive, launching a campaign that urged people to get the flu vaccine and banning advertisements that discourage people from getting vaccinated. Ads related to legislation about vaccines are still permitted, as are false claims about specific vaccines still undergoing trials. Facebook has argued that these ads don’t meet its potential-for-physical-harm threshold.
“While public health experts agree that we won’t have an approved and widely available Covid-19 vaccine for some time, we understand it will pose new challenges and we are actively consulting with health experts on our approach,” Facebook’s vaccine policy lead, Jason Hirsch, told Recode in an email. “In the meantime, we continue to work with them to remove verifiably false claims about the virus that could lead to imminent harm.”
Hirsch is the same Facebook executive who told Reuters in August, “There’s a ceiling to how much we can do until the facts on the ground become more concrete.” At the same time, the company echoed concern that more forceful takedowns of vaccine-critical views could actually drive more people toward not taking a vaccine. 
Meanwhile, a Twitter spokesperson told Recode that the company recognizes its role in spreading credible public health information and is still crafting how its policies and product might change upon the announcement of a medically authorized vaccine. Currently, Twitter says it blocks misleading advertising about vaccines and directs people to public health authorities like the Department of Health and Human Services. 
YouTube, for its part, is currently building the infrastructure to ensure that content about Covid-19 vaccines from public health authorities is elevated. The company has also banned misinformation about a Covid-19 vaccine. The company — which currently bans people from saying there is a proven vaccine — recently announced that it would remove videos that include information about vaccines that go against the guidance of local public health officials or organizations like the WHO. YouTube is also limiting the distribution of videos about vaccines that are “borderline,” the same approach it has taken to other on-the-edge content. 
But while these three platforms will focus on misinformation about a Covid-19 vaccine, they’re still allowing for criticism of such a vaccine and expressions of reluctance toward getting it. Public health experts told Recode that room for criticism and questioning is vital, and peoples’ concerns about a vaccine should not be unilaterally removed from platforms.  
Still, some potentially worrisome content is already on social media. On YouTube, there are some videos of people proclaiming why they will not take a Covid-19 vaccine. On Twitter, Recode found an account purporting to sell a Covid-19 vaccine made in China. And on Facebook, there are specific groups focused on organizing against taking a Covid-19 vaccine if and when one arrives. 
Anti-vaccine content has swirled online for years. It could get a lot worse.
Many have grown more concerned about taking a Covid-19 vaccine in recent months. As Pew found in September, just over half of Americans now say they would or probably would get the vaccine. That figure is down from 72 percent in May. 
It’s not a mystery why there are varying levels of hesitation about a Covid-19 vaccine. Some are skeptical of the comparatively short time it will have taken to produce a vaccine — it would likely be one of the fastest vaccines produced in human history — and many are worried that the vaccine development process has been politicized. 

!function(){""use strict"";window.addEventListener(""message"",(function(a){if(void 0!==a.data[""datawrapper-height""])for(var e in a.data[""datawrapper-height""]){var t=document.getElementById(""datawrapper-chart-""+e)||document.querySelector(""iframe[src*='""+e+""']"");t&&(t.style.height=a.data[""datawrapper-height""][e]+""px"")}}))}();


At the same time, the amount of vaccine misinformation has varied — and at times surged — amid the pandemic, according to research from VineSight. Some conspiracy theories have focused on false claims that billionaires like Bill Gates were behind a made-up effort to secretly implement microchip-sized tracking devices. More recently, theories have emerged that Democrats are somehow behind efforts to stall a vaccine. 
Adding to confusion and tension will be those who politicize the vaccine’s research and distribution. 
And when a medically approved Covid-19 vaccine is announced, we should expect that anti-vaxxers, political activists, and conspiracy theory groups like QAnon will go after the pharmaceutical companies involved. Jonathon Morgan, the CEO of the social intelligence firm Yonder, is working with some of these firms and says some groups will target researchers in order to use them “as a platform to get more attention for whatever they’re pursuing.” 
At the same time, expected delays and pauses in trials — these are normal occurrences that should make the process more trustworthy — could be weaponized to exacerbate the growing feeling among the public that a Covid-19 vaccine is too new and too untested, even if public health officials give it the all-clear. 
“We have a new virus coupled with a new vaccine coupled with a new way of life — it’s too much newness to people,” Ysabel Gerrard, a digital sociologist at the University of Sheffield, told Recode. “I think the pushback against a Covid-19 vaccine is going to be on a scale we’ve never seen before.”
On a brighter note, it’s also likely that people will spread a significant amount of positive content about the Covid-19 vaccine, as well. We should expect family and friends, as well as high-profile people like celebrities and politicians, to post supportive messages about the importance of getting vaccinated. 
Platforms still have time to prepare for nightmare scenarios
Whether they like it or not, social media platforms will be a primary place for many people to learn about a Covid-19 vaccine, and the stakes will be incredibly high. One major challenge will be that, even when we have an approved vaccine, there could be scenarios that nobody prepared for. These situations won’t be as simple as directing people to correct information when people share false ideas about a Covid-19 vaccine.
“We can certainly expect that, since it’s a novel vaccine, there are going to be things that we didn’t anticipate,” notes David Broniatowski, a George Washington University engineering professor who has studied social media and vaccines. 
But there are things that social media companies probably should do now to prepare for such situations. In addition to lowering expectations for the first vaccine, platforms must also prepare for the kinds of questions people will have about it, and ensure that people have room to openly discuss and question aspects of the vaccine. Inevitably, one of the most powerful things social media companies could do is play a role in making the argument for vaccination itself as a public health imperative.
We still don’t have a vaccine approved yet, but news of Pfizer’s initial results hints that one could be coming, and more vaccine candidates may be down the line. That means that as the status of a vaccine shifts, so will social media discussions. Misinformation won’t go away, even with companies banning it. But, from preparing people for a complicated and lengthy distribution process to elevating accurate public health updates, these companies could still make a big difference. 
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
The former CEO of Google has applied to become a citizen of Cyprus,"The former CEO of Google, Eric Schmidt, is finalizing a plan to become a citizen of the island of Cyprus, Recode has learned, becoming one of the highest-profile Americans to take advantage of one of the world’s most controversial “passport-for-sale” programs.
Schmidt, one of America’s wealthiest people, and his family have won approval to become citizens of the Mediterranean nation, according to a previously unreported notice in a Cypriot publication in October. While it is not clear why exactly Schmidt has pursued this foreign citizenship, the new passport gives him the ability to travel to the European Union, along with a potentially favorable personal tax regime.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        A screenshot from the Cypriot publication Alithia, announcing Schmidt’s citizenship application.
      
      
        Alithia
      
    
  



The move is a window into how the world’s billionaires can maximize their freedoms and finances by relying on the permissive laws of countries where they do not live. Schmidt’s decision in some ways mirrors that of another famous tech billionaire, Peter Thiel, who in 2011 controversially managed to secure citizenship in New Zealand.
Interest from Americans in non-American citizenship has been spiking during the coronavirus pandemic, which has sharply limited Americans’ ability to travel overseas. Experts say some of that increase is also due to concerns about political instability in the United States. 
But it is still uncommon to see Americans apply to the Cyprus program, according to published data and citizenship advisers who work with the country. The program is far more popular with oligarchs from the former Soviet Union and the Middle East, and it has become mired in so many scandals that the Cypriot government announced last month that it was to be shut down.
A representative for Schmidt declined to comment on the move or Schmidt’s thinking.
The Cyprus program is one of about a half-dozen programs in the world where foreigners can effectively purchase citizenship rights, skirting residency requirements or lengthy lines by making a payment or an investment in the host country. They have become the latest way for billionaires around the world to go “borderless” and take advantage of foreign countries’ laws, moving themselves offshore just like they might move their assets offshore, a phenomenon documented by the journalist Oliver Bullough in the recent book Moneyland.
Small, financially struggling countries — beginning with St. Kitts and Nevis in the Caribbean — have embraced the idea over the last few decades, raking in money that they would otherwise never see in exchange for citizenship papers. But what can be good for one country can be bad for the world: Anti-corruption activists have grown deeply worried about a race to the bottom with these programs, concerned that criminals can purchase foreign citizenship to escape prosecution in their home countries, or to funnel drugs through friendly borders, or to hide their assets from tax authorities.
The Cyprus program in particular — despite helping save the country after its 2013 bankruptcy by bringing in $8 billion since then — has become notorious.
The lion’s share of the 4,000 Cypriot citizenship recipients since 2013 have been wealthy individuals from Russia, according to people who advise these individuals on obtaining Cypriot citizenship. It has historically not even been marketed to Americans, whose passports usually allow them to travel freely in Europe. It is not unheard of, however, for Americans to take advantage of the program, and advisers say it has been happening more frequently over the last few months.
An Al Jazeera investigation discovered the identities of 2,500 people who had bought Cypriot citizenship between 2017 and 2019 — and only 32, or about 1 percent, were Americans.
That investigation helped spell the end of the program, which had drawn scrutiny for years. Undercover journalists found that Cyprus government officials were saying they could arrange a passport for someone despite being told that the person was a criminal, a scandal that ended up leading to the officials’ resignations. Cyprus announced in mid-October that due to “abusive exploitation,” it was shutting the program down. (Which is also, coincidentally, around when Schmidt’s approval was published.)
“European values are not for sale,” a European Union official said.
It isn’t known what role the coronavirus and new travel restrictions might have played in Schmidt’s decision to apply to Cyprus. Schmidt likely applied between six months ago, when the pandemic was raging, and about a year ago, when it had yet to begin, according to advisers. Schmidt’s wife, the philanthropist Wendy Schmidt, and his daughter, the media executive Sophie Schmidt, have also applied and been approved, according to the listing in the Cypriot publication, Alithia.
Theo Andreou, who heads the Cyprus program for Astons, an “investment immigration firm,” said that 90 percent of the firm’s clients seek Cyprus citizenship either as a backup plan or an insurance policy due to concerns in their home country, such as the coronavirus, or for financial reasons. Andreou speculated that Schmidt could be making the move for two possible reasons.
“One reason is to have a Plan B during Covid. The other reason is that they are expanding their business in Europe,” he said.
Nuri Katz, the founder of Apex Capital Partners and who has advised the Cypriot government on immigration matters, guessed that Schmidt “feels the need to diversify his citizenship.”
“Eric Schmidt cannot travel to Europe,” Katz noted. “He’s like everybody else — like a lot of other high-net-worth people who want to have options.”
Individuals who claim Cyprus citizenship can also be attracted by a reduction in their tax burden, especially if they’re willing to renounce their US citizenship. Immigration attorney Andy Semotiuk said that his only American client who had claimed Cypriot citizenship did so to avoid paying US income tax.
The way the program works is that once a foreigner lays down between $2 million and $3 million worth of investment in Cyprus, typically through a real estate purchase, they can apply to what is technically called the “Citizenship by Investment” program. After the government reviews the applicant’s background, conducts a security check, and hosts a visit from the foreigner, their application can be approved.
Schmidt, with a net worth of $15 billion and many homes around the US, is a titan of the technology industry: The longtime CEO of Google helped make the company into an international powerhouse and served as the tip of the spear of the company’s US lobbying program. While he stepped down as CEO in 2011 and left the board last year, he still serves as a technical adviser to the company and is one of its largest shareholders. These days, he spends most of his time as a philanthropist, investor, and Democratic political donor at Schmidt Futures, the organization that gives away his and his wife’s money, and speaking out on issues like competition with China and how Silicon Valley can cooperate with the US military.
At Google, Schmidt was a proponent for the company paying as little in taxes as possible, even if that meant capitalizing on foreign countries’ tax rules. The company has long been dogged by allegations that it was not paying its fair share of American taxes by utilizing foreign tax rules in places like Bermuda or the United Kingdom.
“I am very proud of the structure that we set up. We did it based on the incentives that the governments offered us to operate,” Schmidt told one interviewer in 2012. “It’s called capitalism.”
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Silicon Valley leaders celebrate the Biden win — and send a message to Trump,"Silicon Valley is celebrating the election of Joe Biden as the next president — and sending the message that they see this race as done, no matter what Donald Trump might say.
Tech’s highest-profile figures and richest people offered their first reactions on Saturday in the aftermath of the Associated Press and the major news networks calling the race for Biden. Biden’s relationship with the tech industry will be closely watched — and could grow tense if his administration aggressively polices misconduct by Big Tech companies. But it is all smiles for now.
Implicit or explicit in a lot of the messaging from tech industry luminaries was that the race between Biden and Trump was over. Trump has made unsubstantiated claims that widespread voter fraud and other irregularities should call the outcome into question, and his first statement on the results made it clear he has no plans to concede the race. Business leaders reportedly have been talking with one another about sending a collective message that corporate America does not agree with the president.
Jeff Bezos, the CEO of Amazon and the world’s richest person, has had a fiery relationship with Trump, mostly revolving around Bezos’s ownership of the Washington Post. On Saturday, Bezos — who did not endorse a presidential candidate — said he saw Biden’s election as a sign that “unity, empathy, and decency are not characteristics of a bygone era.”
“By voting in record numbers, the American people proved again that our democracy is strong,” he wrote on Instagram.




The next-wealthiest person in the world, Microsoft founder Bill Gates, also sent the signal that the race has concluded. Gates prides himself on staying out of the partisan fray, but he has been a sharp critic of Trump’s coronavirus response.


I look forward to working with the new administration and leaders on both sides in Congress on getting the surging pandemic under control, engaging partners around the world on issues like poverty and climate change, and addressing issues of inequality and opportunity at home.— Bill Gates (@BillGates) November 7, 2020



Sheryl Sandberg, the No. 2 at Facebook who has become an icon for many women in leadership, has long had a personal close relationship with Kamala Harris, the new vice president-elect. Sandberg was sure to portray the election as finished — “The votes are in,” she said — but also zeroed in on the history made by Harris.
“For the first time in 231 years, our next vice president will be a Black and South Asian American woman who is the daughter of immigrants,” Sandberg wrote. “There are times when America takes a big step toward creating a government that reflects the diverse country we are. Today is one of those days. I’m thinking with joy about young people across the country watching the news today and thinking, ‘Maybe I can lead this nation too.’”




As of Saturday afternoon, Sandberg’s boss, Mark Zuckerberg, had yet to weigh in. Perhaps more than any other figure in Silicon Valley, Zuckerberg has had to walk a very fine line in the Trump era as he strived to both root out misinformation while also maintaining the platform’s neutrality. Figuring out the Biden era will be a whole other challenge for Facebook’s CEO.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
YouTube is awash with election misinformation — and it isn’t taking it down,"In the hours and days after polls closed in the United States, misleading and outright false content about the presidential election was easy to find on YouTube. A slew of videos claimed to be proof of voter fraud, while the right-wing channel One America News Network (OANN) racked up hundreds of thousands of views on videos incorrectly declaring that Donald Trump had already won the election. YouTube was even running ads on some videos amplifying claims of voter fraud.
While YouTube has added a lightly worded label on some videos noting that election results were not yet final, most of these misinformation videos were still readily accessible by Friday afternoon. Meanwhile, a slew of content stirring doubt in the electoral process was drawing a growing number of views. Those include videos posted in the official Donald Trump channel, which has more than 2 million subscribers, of Trump’s Thursday speech amplifying false conspiracy theories about the election’s legitimacy.
Moderating YouTube requires analyzing large amounts of video content, which can be harder to study and evaluate than text. Still, some have criticized the platform, saying it takes a soft approach to misinformation and other claims that aim to sow doubt in the election process. While it’s difficult to measure how “well” YouTube is doing at finding and eliminating election misinformation compared to its peers, it’s clear that some misinformation and content questioning the election’s integrity are allowed on the platform. Keep in mind that YouTube has previously been criticized for radicalizing its users through its recommendation algorithm and serving as a platform for conspiracy theorists. 
Between November 3 and November 5, there were nearly 100 million views on videos from politics-focused channels with at least 10,000 subscribers that mention keywords related to “election fraud,” according to initial research from Transparency Tube, an independent tool that tracks politics-focused YouTube channels. More than 2.5 million of those views were on channels known for promoting conspiracy content. These large numbers of views demonstrate that the narrative is gathering significant attention. 
“Many of these videos are reporting on claims being made by the president or his supporters, but a significant number, especially from partisan right and conspiracy channels, are endorsing claims of ‘election fraud,’” researcher Sam Clark told Recode in an email. 
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        A video with nearly half a million views from Donald Trump’s channel falsely implies that Joe Biden used voter fraud to win the election.
      
      
        YouTube
      
    
  


“YouTube has always been a welcome home for conspiracy theorists and extremists and has largely paid lip service to making meaningful changes to address misinformation rampant on their platform,” Angelo Carusone, the president of Media Matters, told Recode in an email. “We saw this again in their half-hearted attempts to rein in election misinformation when they insisted on including Fox News — a persistent source of misinformation about voting — as an authoritative news partner.” 
Recode identified about 20 videos that questioned the election in some capacity, such as promoting that Trump had actually won or pushing claims of voter fraud, to see how YouTube would respond. YouTube removed only one for violating its policies on deceptive practices and spam, which specifically bars discouraging voting and interfering in democratic processes. The company said it also took action on content that violated the company’s monetization policy, which prohibits ads on videos that undermine electoral processes. 
YouTube has established a sliding scale for what content is and is not allowed on the platform, and much of its approach to content moderation depends on algorithms. For instance, searches for particular topics have been adjusted to elevate content from news outlets, such as CNN and Fox News. The platform also scales back recommendations for videos that are considered borderline but don’t quite violate YouTube’s rules. Content that violates its community guidelines is supposed to be taken down. That includes videos that allege mail-in ballots have been interfered with to influence an election or that call for violence at polling places. 
“Over the last few years, we’ve heavily invested in the work that allows us to remove violative content, raise up authoritative content, and reduce the spread of borderline content,” YouTube spokesperson Ivy Choi told Recode in a statement. “Our policies prohibit misleading viewers about voting or encouraging interference in democratic processes, and we surface an information panel under videos discussing voting by mail. We continue to be vigilant with regards to election-related content in the lead-up and post-election period.”

  
    Related
  

  
    Why the Trump campaign is going all-in on YouTube 
  

The fact that it takes a bit of work to find these more extreme videos reflects that YouTube’s algorithmic approach to moderation works to a degree and that moderation isn’t always designed to address every single instance of violative content. 
“It’s hard to do this kind of rigorous quantitative analysis in real time, but my impression of doing some searches — firing up so many anonymous browsers and looking at the recommendations — is that they’re definitely not pushing this, and it actually is somewhat hard to find unless you’re really, really looking for it,” said Kevin Munger, a political scientist at Penn State who has studied YouTube. 
Results for terms like “election,” “voting,” and even “Trump won” do indeed usually lead to content from legitimate sources or news outlets, as Recode found when it did its own searches. Even searching for phrases like “voter fraud” generally reveals content refuting the idea that voter fraud was a significant factor in the election. Voter fraud is incredibly rare in the United States.
Videos that give more credence to voter fraud concerns include interviews that originally aired on cable television and talk radio, like Good Morning Britain and Fox News. But despite not showing up in the top search results, several videos that push the idea that the election is somehow being “stolen” from Donald Trump are still attracting a hefty number of views. (At the time of publication, Decision Desk HQ had called the election for Joe Biden, and there was no evidence of a stolen election.) 
A video from One America News, claiming that “Trump won” on the night of November 3, had attracted nearly 420,000 views by Friday afternoon. While YouTube removed ads on this video, the company did not remove it because it didn’t “materially discourage voting,” YouTube told CNBC. Another video from OANN, published Thursday morning, claimed that Trump won but that Democrats were trying to steal the election. It now has more than 260,000 views. YouTube attached a label to both videos that reads “Results may not be final” and directs users to Google’s election tracker.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        A University of Texas advertisement running on a video that alleges “Voter FRAUD for Joe Biden” was caught on video.
      
      
        YouTube
      
    
  



Most of the videos getting millions of views seem to be recordings of mainstream sources, like Fox News, rather than YouTube-native content creators, according to Munger from Penn State. YouTube has been successful in cutting down on recommendations to fringe channels, according to a report from the New York Times, though this has also boosted referrals to Fox New’s content on the site. 
“I think this is consistent with what we’ve been seeing for how they’ve changed their recommendation system to essentially give precedence to mainstream conservative sources over fringe, right-wing conservative sources,” Munger said. 
Still, amid ongoing anxiety about how social platforms deal with content that sows doubt in electoral and civic processes, some feel that YouTube has sidestepped scrutiny amid focus on platforms like Twitter and Facebook. 
As the election has unfolded, it’s become clear how these three companies have differing approaches to content moderation. Facebook, for instance, took down a group with 350,000 members associated with the #StopTheSteal conspiracy and also blocked the hashtag. As of Friday afternoon, searching the same hashtag produced a slew of results on YouTube, including videos with tens of thousands of views. 
  
  
    
    
      
        
  


  






      
    
    
  
  


“We’re so focused on the other platforms that we don’t demand the same accountability and transparency from (YouTube), and nobody kicks up a fuss,” Evelyn Douek, a lecturer at Harvard Law School, told the Washington Post. “We can’t just let them get away with this.”
It’s unrealistic to expect that YouTube will take down every single problematic piece of content — and many would say that’s not the role of social media companies. But it also appears YouTube has become an easy place for the president and conspiracy theorists to spread doubt about the election’s integrity. And so far, it looks as though YouTube appears willing to host videos that do just that. 
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.

  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
The New York Times is thriving in chaos,"We are living, the cliche goes, in unprecedented times. The New York Times, however, seems to be in a very familiar Groundhog Day scenario: The news goes nuts, and more people subscribe to the New York Times.
That’s what happened this summer and fall when the country was consumed with a pandemic, a presidential race, and a reckoning over racial injustice: Through July, August, and September of this year, the Times added close to 400,000 subscribers; it has added 2 million over the last year. 
It’s the best performance the Times has ever had in that timespan. And it is unreservedly good news for the Times, which now has 7 million subscribers and says it is confident it will soon get to 10 million. 
It is also, sadly, not useful news for the rest of the news business, which even as the Times thrives is struggling to scare up revenue and hang on to newsroom resources, making it difficult to provide crucial information in a crucial period for the nation.
But back to the Times for now: Thursday’s numbers also provide the paper with another answer to the question it has been facing since Donald Trump got elected and its subscription numbers soared: What happens when the “Trump bump” goes away? The Times answer: Our subscribers stick around, and we add new subscribers.
But the Times is still going to get asked versions of that question. The can-you-believe-what-just-happened pace of news has to slow down eventually, right? 
It’s not an academic question. Because for years now, the Times has been more dependent on its subscribers, instead of advertisers, for its revenue.
That’s a result of an intentional strategy: The Times put up an online paywall in 2011 and started aggressively marketing digital-only subscriptions to a new generation of readers. And it’s also the result of industry trends: Advertising-based businesses other than Google and Facebook were having a hard time well before the pandemic.
You can see the challenge of running an ad business in the Times’s quarterly results today as well: The Times’s print ads and digital ads both plummeted, and its overall ad revenue dropped 30 percent compared to the same period a year ago.
The Times says some of the drop is because of the pandemic, which hurt most ad-based businesses (again, with the exception of the Facebook/Google duopoly). But even though advertisers have started to spend again in the fall, the Times doesn’t think its ad business will get better: It’s predicting another 30 percent drop for the next three months.
But the Times insists that it’s prepared to thrive in a world that isn’t completely bonkers, whenever that happens. 
“We’re ... not reliant on any single story or topic to drive our growth,” CEO Meredith Kopit Levien told investors today. “It’s worth noting that over time, the model is becoming more resilient to big swings in the news cycle.” That is: Levien is saying the Times will keep growing its subscriber business when we get through the election and the pandemic. 
All of which should make the Times a model for the news business. But it’s not. The Times stands nearly alone as an example of a paper that has trained customers to pay for it online while weaning itself off of ad revenue. 
The Wall Street Journal and the Washington Post are also in decent shape, for different reasons: The WSJ has a longstanding subscription business, which relies on investors and businesses; the Post is owned by the wealthiest man on earth. And a variety of niche publications, like The Information (tech business news) and The Athletic (sports news) are signing up paying customers, too. But for news publishers in between — that is, pretty much everyone else — that model hasn’t worked, which means we’re seeing a grim cycle of declining revenue, which leads to fewer resources, which leads to fewer subscribers. That’s bad news for everyone. 
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Facebook took down a massive “Stop the Steal” group after its members called for violence,"Facebook took down a massive group tied to Republican operatives where people were spreading misinformation about the 2020 presidential election process and calling for violence. While votes are still being counted in key battleground states, President Trump and his campaign are insisting — without proof  — that Democrats are stealing the election through mass voter fraud.
The group, called “Stop the Steal,” gained more than 350,000 members in less than 24 hours starting on Wednesday before it was taken down on Thursday afternoon. Members were convening around unproven allegations of mass ballot-counting fraud, such as the “Sharpiegate” ballot hoax, and posting incitements to violence. While some misinformation researchers applauded Facebook for the move, conservative groups behind it were quick to accuse the company of political censorship. Already, new “Stop the Steal” groups have formed since this one was taken down, raising the question of whether Facebook will be able to consistently moderate groups like this that violate its rules.
Facebook explained its reasoning for taking down the group in a statement to Recode: “In line with the exceptional measures that we are taking during this period of heightened tension, we have removed the Group ‘Stop the Steal,’ which was creating real-world events. The group was organized around the delegitimization of the election process, and we saw worrying calls for violence from some members of the group.” 
Before Facebook removed the group, Recode reviewed the group’s page and found dozens of examples of blatant misinformation about voting at the top of its recent posts section — such as the debunked notion that there was an influx of over a million last-minute mail-in ballots for Joe Biden, and the baseless conspiracy theory that Democrats were using the coronavirus as a “Trojan horse” to increase mail-in voting. According to screenshots from the Center for Countering Digital Hate nonprofit, some members were also directly inciting violence, posting comments like, “Time to clean the guns, time to hit the streets.” The group had also organized several Facebook events supporting real-life protests on Thursday in areas such as Philadelphia, where mail-in ballots are still being counted. Recent protests in battleground states like Michigan and Arizona have disrupted, or attempted to disrupt, vote-counting procedures. 
The “Stop the Steal” group had ties to Republican digital consultants and Tea Party activists, including people involved in Steve Bannon’s “Build the Wall” project, according to reporting from Mother Jones and The Daily Beast. A conservative political organization called Women for Trump was listed as the group’s official creator on its page.
The “Stop the Steal” hashtag has been used to spread false statements about the voting process around the election, including about alleged voter fraud in battleground states like Pennsylvania. Previously, the campaign was linked to former Trump adviser Roger Stone. 
Conservatives on social media immediately condemned Facebook’s move to shut down the group, with some asking whether Facebook ever took such an aggressive stance against Black Lives Matter protests organized on Facebook.
On the other side of the aisle, some commended Facebook for taking quick action to take the group down, even if they thought the company could have acted faster.
“It’s amazing that they let it stay up for so long,” said Imran Ahmed, CEO of Center for Countering Digital Hate. The Stop the Steal group remained up for around 24 hours. “This goes to show that the long-term solution is going to require a sea change in the way that groups can be set up and the kind of content and accountability mechanisms that are there.”
In the past, Facebook groups have been connected to politically motivated violence, such as the recent Kenosha Guard page which rallied armed militia groups to show up on the streets of Kenosha, Wisconsin, during Black Lives Matter protests. A 17-year-old shooter killed two protesters in Kenosha; he was not a member of the Kenosha Guard page but was a member of other militia groups on Facebook that urged members to attend protests. In the months leading up to the election, Facebook began encouraging users to join more groups, though it later turned off its recommendations for political groups just days before the election.
Joan Donovan, who is the research director at Harvard University’s Shorenstein Center on Media, Politics and Public Policy, said that leftist groups on Facebook have been taken down in the past for violent rhetoric as well, such as protest pages linked to the Occupy movement. But people aren’t as aware of that, in part because of the opacity around Facebook’s enforcement decisions.
“Because Facebook has not set public expectations clearly about what will be moderated in this election cycle, people are experiencing content moderation as censorship,” said Donovan. 
Facebook’s reaction to the Stop the Steal group is a sign that it’s starting to move faster to shut down people on its platform who are organizing in ways that could lead to violence. But for many, it’s still unclear what crosses that line — especially before the rhetoric escalates to dangerous levels. In this case, hundreds of thousands of people were already exposed to conspiracy theories and misinformation, and possibly encouraged to commit violence because of it, before Facebook acted. At a time when the country is so deeply divided over the fundamentals of our democracy, it would help if the company provided greater transparency into its decision-making processes around political speech.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
What’s really going on with the mail-in ballots the US Postal Service can’t trace ,"Several news outlets reported on Election Day that the United States Postal Service did not have records of delivery scans for 300,000 mail-in ballots across a dozen states, stoking fears that changes to the Postal Service implemented earlier this year by new Postmaster General Louis DeJoy, a top Trump donor, had potentially disenfranchised hundreds of thousands of voters.
But the president of the largest postal worker union corroborated in an interview with Recode on Wednesday morning what the Postal Service has repeatedly said about the data in court filings in recent days: There are numerous reasons why ballots in the days leading up to the election would not receive a delivery scan and that it’s highly unlikely that the number of undelivered ballots totaled anywhere near 300,000.
“Just because something didn’t have [a delivery scan] does not translate at all into ‘it was not delivered,’” Mark Dimondstein, president of the American Postal Workers Union, told Recode on Wednesday. (The APWU has previously been critical of operational changes DeJoy implemented earlier this year — and then put on pause — that its leaders say led to delivery delays.) “What we had in place … is the ballots were given such priority treatment, even beyond first-class treatment, that ballots were being purposely pulled out” of normal mail-processing procedures and given expedited delivery in the days leading up to Election Day.

  
    Related
  

  
    Vox live results: Joe Biden’s path to victory widens
  

Dimondstein outlined various scenarios in which a ballot could be scanned into a facility but not scanned for delivery. The scenarios typically involve ballots not running through a normal automated processing procedure and being hand-sorted to be delivered directly to a Board of Elections facility or to await pickup from the Board of Elections.
“We weren’t worried about the scan,” he added. “We were worried about getting to the Board of Elections on time. Our whole goal is to make it as quick and efficient as possible.”
In a statement Wednesday afternoon, USPS spokesperson Dave Partenheimer said, “The assumption that there are unaccounted ballots within the Postal Service network is inaccurate,” adding that the ballots in question “were delivered in advance of the election deadlines.” He also said ballots delivered directly to local election boards to save time as Election Day approached did not receive a final scan because they didn’t flow through regular mail processing.
But around the same time his statement was issued, a senior USPS official overseeing election mail processing was testifying in federal court on election mail issues, including about the untraced ballots, and said he would have to look into whether any ballots did not make it to their counting destination.
“I wouldn’t be surprised that there were some,” the USPS official, Kevin Bray, said, “[but] I’d be very surprised if they were in the thousands.”
Bray, who was called to testify on short notice earlier in the day, said he hadn’t seen the documents highlighting ballots that were scanned into postal facilities but not scanned out.
Partenheimer did not immediately respond to a question from Recode about why his statement definitively said there were no untraced ballots even as Bray’s remarks left open the possibility that some could have been left behind.
The case of the supposed hundreds of thousands of untraced ballots drew attention on Election Day when a federal judge ordered “all clear” checks of postal facilities in a dozen states that were intended “to ensure that no ballots have been held up and that any identified ballots are immediately sent out for delivery.”
The ordered sweeps included facilities in several swing states including Florida, Arizona, and Michigan, which do not count ballots received after Election Day, and it left open the question of whether some mail-in votes would be disqualified if not delivered by state cutoff times.
US District Judge Emmet Sullivan in Washington, DC, had imposed a 3 pm deadline earlier on Tuesday as part of a lawsuit filed by plaintiffs including the NAACP against the USPS and Postmaster General DeJoy. The suit alleges DeJoy “impeded the timely distribution of mail, implemented crippling policies on postal workers, and sabotaged the United States Postal Service in a blatant attempt to disenfranchise voters of color.” The deadline was also in response to a USPS court filing from Monday indicating that just over 300,000 mail-in ballots nationwide had been scanned upon receipt at mail-processing plants but that there were no records indicating these ballots had been delivered.
Department of Justice lawyers, representing the USPS, responded after the judge’s deadline on Tuesday, saying that regular daily sweeps were conducted in the morning and that the USPS could not move up Election Day facility reviews already scheduled for later in the day, between 4 pm and 8 pm.
On Wednesday, lawyers for the USPS said in a court filing that the Election Day sweeps were carried out and that they turned up just 13 ballots, all in Pennsylvania, that were referred to management for delivery.
At a noon hearing on Wednesday, the judge still scolded USPS leadership for failing to comply with his Tuesday afternoon deadline and threatened that DeJoy may have to testify or be deposed. 
A USPS spokesperson told Recode on Tuesday that since October 29, the US Postal Inspection Service “has been conducting daily reviews at all 220 facilities that process ballots” and that “ballots will continue to be accepted and processed as they are presented to us and we will deliver them to their intended destination.” 
Lawyers for the USPS said in a court filing on Wednesday that postal workers were instructed to run continuous sweeps of their facilities on Election Day and get ballots to their destination by a state’s cutoff time.
“This is super frustrating,” NAACP attorney Allison Zieve told the Washington Post on Tuesday. “If they get all the sweeps done today in time, it doesn’t matter if they flouted the judge’s order. They say here they will get the sweeps done between 4 pm and 8 pm, but 8 pm is too late, and in some states, 5 pm is too late.”
What’s clear is that the 300,000 figure is likely unreliable at best, and perhaps a vast overstatement at worst. What’s still unclear is whether any ballots at all did not make it from a postal facility to a ballot-counting center on time — and it’s not certain that there will be an answer. But there is hope, based on Bray’s testimony on Wednesday, that the USPS will provide more clarity soon.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
"No, Joe Biden did not mysteriously gain 138,000 Michigan votes all at once","Several news outlets reported on Election Day that the United States Postal Service did not have records of delivery scans for 300,000 mail-in ballots across a dozen states, stoking fears that changes to the Postal Service implemented earlier this year by new Postmaster General Louis DeJoy, a top Trump donor, had potentially disenfranchised hundreds of thousands of voters.
But the president of the largest postal worker union corroborated in an interview with Recode on Wednesday morning what the Postal Service has repeatedly said about the data in court filings in recent days: There are numerous reasons why ballots in the days leading up to the election would not receive a delivery scan and that it’s highly unlikely that the number of undelivered ballots totaled anywhere near 300,000.
“Just because something didn’t have [a delivery scan] does not translate at all into ‘it was not delivered,’” Mark Dimondstein, president of the American Postal Workers Union, told Recode on Wednesday. (The APWU has previously been critical of operational changes DeJoy implemented earlier this year — and then put on pause — that its leaders say led to delivery delays.) “What we had in place … is the ballots were given such priority treatment, even beyond first-class treatment, that ballots were being purposely pulled out” of normal mail-processing procedures and given expedited delivery in the days leading up to Election Day.

  
    Related
  

  
    Vox live results: Joe Biden’s path to victory widens
  

Dimondstein outlined various scenarios in which a ballot could be scanned into a facility but not scanned for delivery. The scenarios typically involve ballots not running through a normal automated processing procedure and being hand-sorted to be delivered directly to a Board of Elections facility or to await pickup from the Board of Elections.
“We weren’t worried about the scan,” he added. “We were worried about getting to the Board of Elections on time. Our whole goal is to make it as quick and efficient as possible.”
In a statement Wednesday afternoon, USPS spokesperson Dave Partenheimer said, “The assumption that there are unaccounted ballots within the Postal Service network is inaccurate,” adding that the ballots in question “were delivered in advance of the election deadlines.” He also said ballots delivered directly to local election boards to save time as Election Day approached did not receive a final scan because they didn’t flow through regular mail processing.
But around the same time his statement was issued, a senior USPS official overseeing election mail processing was testifying in federal court on election mail issues, including about the untraced ballots, and said he would have to look into whether any ballots did not make it to their counting destination.
“I wouldn’t be surprised that there were some,” the USPS official, Kevin Bray, said, “[but] I’d be very surprised if they were in the thousands.”
Bray, who was called to testify on short notice earlier in the day, said he hadn’t seen the documents highlighting ballots that were scanned into postal facilities but not scanned out.
Partenheimer did not immediately respond to a question from Recode about why his statement definitively said there were no untraced ballots even as Bray’s remarks left open the possibility that some could have been left behind.
The case of the supposed hundreds of thousands of untraced ballots drew attention on Election Day when a federal judge ordered “all clear” checks of postal facilities in a dozen states that were intended “to ensure that no ballots have been held up and that any identified ballots are immediately sent out for delivery.”
The ordered sweeps included facilities in several swing states including Florida, Arizona, and Michigan, which do not count ballots received after Election Day, and it left open the question of whether some mail-in votes would be disqualified if not delivered by state cutoff times.
US District Judge Emmet Sullivan in Washington, DC, had imposed a 3 pm deadline earlier on Tuesday as part of a lawsuit filed by plaintiffs including the NAACP against the USPS and Postmaster General DeJoy. The suit alleges DeJoy “impeded the timely distribution of mail, implemented crippling policies on postal workers, and sabotaged the United States Postal Service in a blatant attempt to disenfranchise voters of color.” The deadline was also in response to a USPS court filing from Monday indicating that just over 300,000 mail-in ballots nationwide had been scanned upon receipt at mail-processing plants but that there were no records indicating these ballots had been delivered.
Department of Justice lawyers, representing the USPS, responded after the judge’s deadline on Tuesday, saying that regular daily sweeps were conducted in the morning and that the USPS could not move up Election Day facility reviews already scheduled for later in the day, between 4 pm and 8 pm.
On Wednesday, lawyers for the USPS said in a court filing that the Election Day sweeps were carried out and that they turned up just 13 ballots, all in Pennsylvania, that were referred to management for delivery.
At a noon hearing on Wednesday, the judge still scolded USPS leadership for failing to comply with his Tuesday afternoon deadline and threatened that DeJoy may have to testify or be deposed. 
A USPS spokesperson told Recode on Tuesday that since October 29, the US Postal Inspection Service “has been conducting daily reviews at all 220 facilities that process ballots” and that “ballots will continue to be accepted and processed as they are presented to us and we will deliver them to their intended destination.” 
Lawyers for the USPS said in a court filing on Wednesday that postal workers were instructed to run continuous sweeps of their facilities on Election Day and get ballots to their destination by a state’s cutoff time.
“This is super frustrating,” NAACP attorney Allison Zieve told the Washington Post on Tuesday. “If they get all the sweeps done today in time, it doesn’t matter if they flouted the judge’s order. They say here they will get the sweeps done between 4 pm and 8 pm, but 8 pm is too late, and in some states, 5 pm is too late.”
What’s clear is that the 300,000 figure is likely unreliable at best, and perhaps a vast overstatement at worst. What’s still unclear is whether any ballots at all did not make it from a postal facility to a ballot-counting center on time — and it’s not certain that there will be an answer. But there is hope, based on Bray’s testimony on Wednesday, that the USPS will provide more clarity soon.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Live results for California’s Proposition 22 on ride-hailing drivers,"UPDATE: California voters passed Proposition 22, which means that ride-hailing companies like Uber and Lyft can consider drivers independent contractors, not employees.The future of the so-called gig economy is in the hands of California voters deciding on Proposition 22, the latest development in an ongoing fight over whether app-based drivers should be considered independent contractors or employees. 
The proposition, which has the support of a pricey campaign funded by companies like Uber and Lyft, would allow these companies to continue to classify their drivers as independent contractors, while providing some limited benefits and protections. Classifying drivers in this way has kept costs lower for these services, and been central to their business model. 
But critics of these firms — including a movement made up of drivers who want the right to unionize — argue that the work these gig workers do makes them employees, and that they deserve protections given to employees, like overtime pay and paid leave. 
Proposition 22 isn’t the first time California has considered the employee-independent contractor question. Last year, the state approved a law called AB 5, which created new standards for classifying people as independent contractors that built on a previous ruling from the state’s Supreme Court. But companies like Uber and Lyft have not complied, inviting a court case from state officials. The companies hoped to win that case, so that their delivery and ride-hailing apps would be able to maintain business as usual. 
But they’ve had no such luck. In a recent decision, a California appeals court reaffirmed that yes, ride-hailing drivers ought to be considered employees. That means that Proposition 22  could potentially be these companies’ last chance to protect their businesses as they know them. But if Proposition 22 succeeds, it could also spell defeat for ride-hailing drivers who are demanding better protections and pay. 
California Proposition 22
A yes vote would mean ride-hailing companies can consider drivers independent contractors who are not entitled to the same benefits as employees.
A no vote would mean ride-hailing drivers should be considered employees, and given additional benefits and protections.




(function() {
  var eles = document.querySelectorAll('[data-iframe]')
  for ( var i = 0; i < eles.length; i++ ) {
	var ele = eles[i]
	if ( ele.getAttribute('data-iframe-loaded') == 'true' ) continue
	var src = ele.getAttribute('data-iframe')
	var iframe = document.createElement('IFRAME')
	iframe.src = src
	iframe.width = '100%'
	ele.appendChild(iframe)
	ele.setAttribute('data-iframe-loaded', 'true')
	var handleSizingResponse = function(e) {
  	if (iframe.contentWindow != e.source) return;
  	if (!e.data || e.data.type != 'embed-size') return;
  	iframe.setAttribute('height', e.data.height)
	}
	window.addEventListener('message', handleSizingResponse, false);
  }
})();



  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Live results for California’s data privacy ballot initiative ,"UPDATE: California passed ballot measure Proposition 24, strengthening its digital privacy protections.California has the toughest — and one of the only — consumer data privacy laws in the US: the California Consumer Privacy Act (CCPA). And a ballot measure called the California Privacy Rights and Enforcement Act, or Proposition 24, may make it even stronger.
As of Wednesday, at 12:50 am ET, more than 55 percent of ballots were cast in support of the measure, with more than 64 percent of the vote reported, according to Vox’s partners at Decision Desk. 
The CCPA gave Californians a measure of control over how their personal data was collected, accessed, and sold. But it contained some loopholes businesses have used to get around the restrictions imposed by the law — loopholes Proposition 24 would close by giving extra protection to data about “sensitive” areas including race, health, religion, biometric information, and precise location. The proposition would also establish and fund a new state agency to enforce the law, a duty currently left to the underresourced attorney general’s office.
Also, Proposition 24 may be the first California ballot measure to get its own rap:

Proposition 24 has some surprising pro-privacy opponents. The Electronic Frontier Foundation, which advocates for digital civil rights, doesn’t support it (it doesn’t oppose it, either, calling the law a “mixed bag of partial steps forwards and backwards”) and the American Civil Liberties Union is firmly against it. One big reason: The initiative would allow businesses to charge users who opt out of having their data sold or shared more, making privacy rights less accessible to people with lower incomes.
One thing the proposition’s supporters and opponents seem to agree on is that CCPA was a good first step, but a law with a lot of room for improvement. Now we’ll find out what a second step might look like.
California Proposition 24
A yes vote would close some loopholes in California’s data privacy law. It would also establish and fund a new state agency to enforce privacy law.
A no vote would mean no extra protections would be added to California’s data privacy law.




(function() {
  var eles = document.querySelectorAll('[data-iframe]')
  for ( var i = 0; i < eles.length; i++ ) {
	var ele = eles[i]
	if ( ele.getAttribute('data-iframe-loaded') == 'true' ) continue
	var src = ele.getAttribute('data-iframe')
	var iframe = document.createElement('IFRAME')
	iframe.src = src
	iframe.width = '100%'
	ele.appendChild(iframe)
	ele.setAttribute('data-iframe-loaded', 'true')
	var handleSizingResponse = function(e) {
  	if (iframe.contentWindow != e.source) return;
  	if (!e.data || e.data.type != 'embed-size') return;
  	iframe.setAttribute('height', e.data.height)
	}
	window.addEventListener('message', handleSizingResponse, false);
  }
})();



  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
California just strengthened its digital privacy protections even more,"The California ballot measure Proposition 24, or the California Privacy Rights Act (CPRA), has passed, pushing the state even further ahead of the rest of America when it comes to data privacy legislation.
CPRA adds to California’s existing law, the California Consumer Privacy Act (CCPA). CCPA is one of the strongest privacy laws in a country with few of them, giving Californians the power to know what data businesses have and collect about them and to tell those businesses not to sell that data to anyone else. 
CCPA went into effect on January 1, and while it wasn’t perfect by any means, most privacy advocates seemed to agree that it was a good start, both for the state and for any other state or federal laws its passage may inspire. 
Californians for Consumer Privacy was behind Proposition 24, which it believed would further strengthen the CCPA and close some of the loopholes businesses were using to get around the law. 
The group’s founder, Alastair Mactaggart, is also the reason the CCPA exists. He’s put up millions of dollars of his own money to get CCPA and CPRA passed, beginning with a ballot measure about consumer privacy back in 2018. Mactaggart came to agreement with the state legislature that he would withdraw the measure from the ballot if California passed its own version (which Mactaggart helped write). That became the CCPA. But Mactaggart wanted more from the law and came up with CPRA: a 52-page ballot measure that he thought would fix its shortcomings.
“I think that the regulations are, overall, pretty good, but it can be tightened up,” Mactaggart told Recode.

  
    Related
  

  
    Live results for California’s data privacy ballot initiative 
  

Mactaggart said the CCPA had weaker consumer protections than his original ballot measure in the interest of getting the law passed (“so businesses couldn’t argue this person is going to shut down commerce”). Now CPRA will add stronger privacy protections to its predecessor, giving California a law on par with the European Union’s General Data Protection Regulation.
“My approach is, now’s the time to close the gap and give Californians first-world privacy,” Mactaggart said.
What California Proposition 24 does, briefly explained 

Proposition 24’s provisions give Californians the ability to tell businesses not to use certain categories of sensitive information, including race, health, religion, location, sexual orientation, and biometrics. It makes more explicit that “do not sell” includes data shared between companies. And it triples fines for violations if the affected consumer is younger than 16 years old. 
The new measure also makes it very difficult to weaken the law through additional amendments — though any amendments that strengthen it can pass with a simple majority. Finally, it provides funding for a Privacy Protection Agency that would be charged with enforcing privacy laws. The CCPA only gave the state’s attorney general the ability to do that, and Attorney General Xavier Becerra has said that his office has limited resources to do so.
While Proposition 24 had several supporters — including the NAACP of California, a handful of state politicians, US Rep. Ro Khanna (D-CA), Andrew Yang, and privacy advocates and experts including Shoshana Zuboff, Chris Hoofnagle, and Ashkan Soltani (who co-authored the measure) — it also had its opponents. 
Most notably, the American Civil Liberties Union of California was very much against it, saying that it actually weakened parts of the CCPA and citing concerns that it allowed companies to charge consumers who opt out of having their data sold or shared more than those who don’t. This, the ACLU argued, means people with lower incomes will have less access to privacy protections than people with greater assets. Still others either reluctantly supported it or declined to endorse or oppose it. The digital civil liberties nonprofit the Electronic Frontier Foundation, for example, said the measure was too much of a “mixed bag” to take a position. 
What Proposition 24 means for federal privacy laws
Proposition 24’s passage adds to California’s reputation as the state that pioneers progressive laws that the rest of the country later adopts. Since CCPA, other states have tried to pass their own privacy laws — with varying degrees of success — though none has managed to get one on the books that’s quite as strong. 
Some companies have extended CCPA protections to everyone in America, but they don’t have to, and many haven’t. Seeing Californians pass another digital privacy law may be the encouragement the federal legislature needs to get going on its own version. And Mactaggart thinks Proposition 24’s rules that make it very difficult to change the law will tell businesses — and federal lawmakers — that privacy laws are here to stay.
“This is a new reality for one in eight Americans, it ain’t going away,” Mactaggart said. “I think you’ll start to see more of a push to get good protections in the country. And if that doesn’t work, I think other big states will adopt something like ours.”
Companies that make most of their money through internet advertising and the data collection that powers it have been allowed to self-regulate for most of their existence, and data privacy is nonexistent as a result. Over the past few years, however, there’s been an increased focus on, and criticism of, Big Tech — especially Google and Facebook, two of the biggest and most well-known data-sucking companies out there — which has resulted in a push for privacy laws to force those companies to do what they won’t on their own. 
Going into 2020, the question wasn’t if a federal privacy law would be passed but what it would look like. The Senate Commerce Committee had a hearing to discuss proposed legislation, and its ranking member, Sen. Maria Cantwell (D-WA), put out her version of a bill. (The committee chair, Mississippi Sen. Roger Wicker, put out his own almost a year later, in September 2020.) 
There was also a bipartisan bill from Sens. Amy Klobuchar (D-MN) and John Kennedy (R-LA) back in 2018; Sen. Ron Wyden (D-OR) has released countless privacy bills, including his October 2019 Mind Your Own Business Act; and Sen. Josh Hawley (R-MO) has put out plenty of privacy bills of his own, some of which are bipartisan. California Democratic Reps. Anna Eshoo and Zoe Lofgren unveiled their data privacy bill in November 2019, while Sen. Kirsten Gillibrand (D-NY) rolled hers out in February 2020. Both of those bills provided for a separate federal agency to investigate privacy or data protection violations. 
By March, of course, there were more pressing concerns than privacy bills. In the earlier days of the pandemic, there was even a possibility that all that data companies collected about people and their movements would actually help stop the spread of the coronavirus; companies that specialize in location data sure wanted us to think so. Health privacy rules were relaxed to give people greater access to telehealth services. And millions of students being forced into remote learning came with its own privacy issues. In the first few months, Congress was too busy trying to pass pandemic recovery legislation to do much for digital privacy.
By the second half of the year, Big Tech regulation became increasingly politicized, with Republicans taking cues from President Trump and railing against perceived political biases on social media platforms — and turning to legislation that would undo or change Section 230, which protects platforms from liability for the things people say on them, to try to stop it. There is bipartisan support for using antitrust laws to regulate the largest tech companies, part of which includes those companies’ privacy practices. But even here, some Republicans have hijacked antitrust hearings to rail about censorship of conservatives rather than the actual issues.
So now the question is, what will 2021 bring, if anything, to privacy legislation? Democrats have said they are ready and willing to move forward on it if given the opportunity. Republicans have been more focused on Section 230, but that won’t matter much if they lose control of the Senate — or even the presidency.
“We need a Data Protection Agency and comprehensive data privacy legislation,” Gillibrand told Recode. “I am committed to working with my colleagues in Congress to hold tech firms accountable, while maintaining the most innovative, successful tech sector in the world.”
If nothing happens at all on a federal level, well, we’ve still got California, right?


  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
"California has rejected a major gig economy reform, leaving workers without employee protections","Proposition 22, created to decide the future of the California gig economy, has passed.
The proposition concerned whether app-based drivers for companies like Uber and Lyft are employees or independent contractors. And its success, which the Associated Press called before midnight Wednesday PT, means those companies will effectively be exempted from a California law that would have pushed such drivers to be classified as employees.
The decision is a major win for gig companies that cements their influence over state policy. And it is a serious loss for gig workers hoping for stronger workplace protections as well as labor advocates in other states hoping California could become a model for gig economy reforms. While this proposal concerned California, the question is one of national importance as it could hint at how other cities and states might handle this same issue in the future. 
Proposition 22 isn’t the first time California has weighed whether these workers are independent contractors or employees; it comes on the heels of a California law passed last year called AB 5. That legislation created more stringent standards for classifying someone as an independent contractor, expanding on a previous decision from the state’s Supreme Court. 

  
    Related
  

  
    Live results for California’s Proposition 22 on ride-hailing drivers
  

At the time, AB 5’s passage was a big deal and was considered a major win for labor advocates. “The pride of California is tech. Now they’re passing a law that says these people are your employees, and you need to take care of them. It shows that labor unions and activists have a lot of pull,” then-Illinois Institute of Technology labor law professor César Rosado Marzán told Vox last year when the law was approved.  
While this law includes exemptions for some types of work, drivers for companies like Uber and Lyft were not included in those exemptions and were expected to fall under the law’s purview and be considered employees.
But that didn’t stop companies like Uber and Lyft from continuing to treat their drivers as independent contractors, a move that again pushed the matter to the California courts, where these tech giants hoped to wriggle out of the law’s provisions. But after an appeals court recently affirmed that these companies must start treating their drivers as employees, Proposition 22 became one of the final opportunities for these companies to keep their drivers from being considered employees and preserve their longtime business model.  
Against Proposition 22 were labor organizations that said ride-hailing drivers deserve the protections of employee classification, like sick leave and health care, and that the current approach of companies like DoorDash, Lyft, and Uber exploits drivers. They argued that Proposition 22 will potentially leave drivers with pay below the minimum wage, prevent them from accessing overtime, and provide insufficient health care protections. 
Before the November 3 election, polls did not indicate a clear Proposition 22 preference among California residents. But major national politicians did chime in, with Democratic presidential and vice presidential candidates Joe Biden and Kamala Harris, as well as Sen. Bernie Sanders, all urging people to vote against the measure. 
Supporting Proposition 22 were the gig economy giants, who argued that treating their drivers as independent contractors as employees would hurt the ride-hail industry, reduce jobs, and limit drivers’ opportunity to work for multiple companies. Uber, for instance, had warned that forcing the company to classify drivers as employees could mean small cities’ prices could as much as double and would drastically reduce the number of people who drive for the service. 
Importantly, the Yes on Prop 22 campaign was heavily funded by these companies; about $200 million overall had been spent in support of the initiative as of mid-October. Millions of dollars went into Facebook advertisements alone. And some went further, with Uber pushing pro-Proposition 22 content inside of the driver version of its app (that move also prompted a lawsuit). 
These efforts were apparently enough: Voters decided the law should not apply to these ride-hailing companies. With their business model secure, Uber and Lyft are certainly celebrating. But without the promise of employee protections, drivers hoping to secure better benefits and working conditions must now weigh their next steps. 

  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Twitter and Facebook both label Trump’s post baselessly asserting that the election is being “stolen”,"Twitter and Facebook both labeled a post President Donald Trump shared at the end of Election Day in which he baselessly said the election was being “stolen” from him. Twitter took more aggressive action by warning users the post is “potentially misleading” and slowing its reach; Facebook posted a label that said ballots could take days or weeks to count.
In fact, it’s standard process in the United States for votes to be counted well after election night, and that was even more anticipated this year, given the record volume of mail-in ballots due to people staying at home during the Covid-19 pandemic.
Democrats worried about this very scenario — that Trump would declare a premature victory via social media — for months leading up to the election, pressing social media companies for more details on how they would respond. Trump’s posts came ahead of a speech he’s expected to give on broadcast television, in which major networks have said they would fact-check false claims by Trump in near-real time.
Just as Democratic presidential candidate Joe Biden was finishing his televised speech, during which he said he thinks he’s “on track” to win the election, Trump posted on his Facebook and Twitter accounts. “We are up BIG, but they are trying to STEAL the Election,” he wrote. “We will never let them do it. Votes cannot be cast after the Poles are closed!”
  
  
    
    
      
        
  


  






      
    
    
  
  


It appears that a few minutes after Trump’s original post, his account deleted and reposted the tweet after fixing a spelling error; his first tweet had spelled “polls” as “Poles.”
Regardless, Twitter labeled the spell-checked version of Trump’s tweet with a warning label for violating its policies against civic integrity. Twitter’s label covered Trump’s words, so you can only see the actual post if you click on a note that says the content in the tweet is “disputed” and “might be misleading about an election or other civic process.” Twitter also seemingly prevented users from replying to, liking, or sharing the tweet without comment.
Shortly after Twitter moderated Trump’s post, Facebook also labeled Trump’s identical post on the platform with a less-prominent warning label stating that “final results may be different from initial vote counts, as ballot counting will continue for days or weeks,” and included a link to voting information. Unlike Twitter, Facebook has not limited people’s ability to reply to or share the post.
  
  
    
    
      
        
  


  






      
    
    
  
  


Once again, it seems that Twitter took the lead over Facebook in more decisively moderating Trump’s posts. But as Trump continues to comment on the results of an incomplete election in which key battleground states are expected to spend the next few days or more finalizing their counts, both companies will likely face continued instances of unproven claims about the outcome.



  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
"Technical glitches on Election Day are annoying, but they are not unusual","As millions of Americans cast their votes on Election Day, there are scattered reports across the country that voting machines aren’t working, causing delays and long lines at some polling sites. While this isn’t desirable, it’s also perfectly normal. Don’t panic just yet.
During an election cycle awash with accusations of election interference from both sides, not to mention the threat of cyberattacks from foreign governments, it’s understandable that people would assume the worst when anything goes wrong. But those assumptions are likely misplaced. Every election, voting machines break or have technical issues for perfectly innocent reasons, and 2020 has, so far, been no different.
In an election that most predict will come down to who wins battleground states, issues with voting machines in those states are the most concerning. Voters in Spalding County, Georgia, were forced to cast provisional ballots due to a “technical issue,” apparently caused by human error, which was resolved within hours. Several polling sites in Nevada’s Clark County had to delay opening due to “technical problems” with voter check-in kiosks, although the voting machines themselves worked just fine. Three sites in North Carolina had opening delays due to issues with their printers. The state is extending voting hours to make up for the time lost. (If you’re having issues with voting machines or polling sites, you should report them to your local board of elections or call 1-866-OUR-VOTE.)
“We’ve seen equipment failures in every election and know that election officials must be prepared to respond when they inevitably occur,” Mark Lindeman, co-director of Verified Voting, an advocacy group for voting technology, said in a statement. “Right now, the key is for election officials to recover from these issues by providing the means for every voter to cast a completed ballot.”
Cybersecurity and Infrastructure Security Agency director Christopher Krebs and acting Homeland Security Secretary Chad Wolf said in a press conference on Tuesday that they had full confidence in the country’s voting infrastructure and no indications that it had been hacked. While security researchers have shown that it’s technically possible to hack voting machines in demonstrations and there have been reports of Boards of Elections being hacked, what hackers can do in a controlled environment does not necessarily translate to real-world elections.
“To my knowledge, there is no verified report of a machine being hacked during an election,” Lindeman told Recode. “Definitely verified reports of machines malfunctioning, scanners being misprogrammed, etc., but nothing tying those to [a] cyberattack.”
On the other hand, voter suppression and intimidation tactics, from parties both foreign and domestic, is very real. 
In an ideal world, of course, everything would work perfectly and run smoothly. But we don’t live in that world, and America’s voting infrastructure leaves a lot to be desired and has been underfunded for a long time. Machines have glitches, and human beings make mistakes. We can only hope those problems don’t disenfranchise any voters or affect the results ... whenever those come in.
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Misleading claims about voter fraud in Pennsylvania are going viral online,"Just hours after the polls opened, misleading claims about voting in Pennsylvania, a key battleground state in the presidential election, were running rampant on social media platforms like Twitter and Facebook. The flurry of social media posts focused on alleged examples of voter suppression and polling location malfeasance, such as broken voting machines and ballots being discarded.
Conservatives — including the official Philadelphia Republican Party, Trump campaign operative Mike Roman, and right-wing media personalities — spread some of these posts on Twitter and Facebook, framing them as indicative of a widespread plot to harm Trump’s campaign. Some of the accusations have been disputed by election officials but continue to proliferate on social media. Local officials such as the Philadelphia District Attorney’s Office called one of Roman’s tweets about Democratic Party signs outside a polling station “deliberately deceptive,” and Twitter has put a warning label on at least one of Roman’s recent posts.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        Trump campaign operative Mike Roman posted several unproven allegations of widespread politically motivated voting interference in Pennsylvania, like this one, which was flagged by Twitter with a warning label.
      
      
    
  


By the time the Philadelphia District Attorney’s office disputed Roman’s tweet, it had already been widely shared.


Members of our Election Task Force have investigated this allegation. This polling place is located in an interior room and the sign in question is further than 10 feet from it. This tweet is deliberately deceptive. #PhillyVotes #Election2020 https://t.co/szKgxoigVm— Philadelphia DAO (@philadao) November 3, 2020



While it’s hard to fact-check every one of the claims, election researchers say that, even when true, the accusations of wrongdoing are being deceptively exploited to discredit the entire voting process. For months, President Trump has been sowing doubt about the integrity of mail-in voting, despite the fact that there is virtually no evidence of mass mail-in ballot fraud in the United States. Now, it seems that some conservatives are turning their focus to unsubstantiated allegations of mayhem at the in-person polling booths and at drop-off ballot boxes. 
“Bad actors have really set the stage leading up to this to be able to amplify true information in a misleading way,” said Maddy Webb, a researcher with First Draft News, an organization that studies the spread of misinformation online. “Our voting system is not infallible, occasionally there are mistakes.” But that doesn’t mean there is “widespread, intentional, malfeasant voter fraud — that just isn’t the case,” she added. 
In particular, the hashtag #StopTheSteal has been linked to misleading allegations of mass electoral fraud. From 8 am to 11 am ET, the hashtag appeared on as many as 3,000 tweets per hour, according to First Draft News. The hashtag was driven primarily by a single tweet showing a video of a poll observer being denied entry to a Philadelphia polling location. A voting official in the city told ProPublica that this was an isolated incident and that the watcher was ultimately admitted to the site — but that didn’t stop the video from going viral and stirring up anger.
Another popular thread of misinformation circulating on social media has been around how ballot boxes work in Pennsylvania as well as whether voting machines are working or not and what poll workers might be doing to influence the vote.
Some of the most egregiously false claims were that poll machine booths in Scranton,  Pennsylvania, were not working in the afternoon (an election official told Davey Alba at The New York Times there was only a temporary glitch that was fixed by 9 am), and that a person alleging to be a poll worker confessed to throwing away 100 Trump ballots (the person is in fact not a poll worker, according to local election officials). 


“This morning we had a glitch getting one of the machines up & running, but it has been running all day,"" Donald Frederickson, solicitor for Lackawanna County Board of Elections, told me. This was a glitch that was resolved before 9AM or so. Tweet below is 2PM. pic.twitter.com/8ilMOsrehJ— Davey Alba (@daveyalba) November 3, 2020



In particular, researchers at both First Draft News and Zignal Labs, an online intelligence firm, noticed an unusual spike in social media posts Tuesday morning about alleged Philadelphia voting malfeasance using the hashtag #StopTheSteal.
First appearing in 2016, the Stop the Steal campaign was originally linked to former Trump campaign operative Roger Stone. Since then, it’s also been used by liberal activists. But beginning this morning, it exploded when conservative social media accounts with hundreds of thousands of followers like Will Chamberlain, editor-in-chief of the conservative publication Human Events, tweeted about Pennsylvania polling incidents using the hashtag. Zignal Labs estimated the hashtag raked in nearly 13,000 mentions on social media in the course of several hours Tuesday morning. 
Altogether, this torrent of confusion — even if it’s eventually corrected by fact-checkers and election officials — serves to chip away at people’s confidence in the electoral process.
“It’s what we’ve seen this entire year, which is complete erosion of faith in any institution — I can’t see a circumstance where people are not going to contest the election,” said Webb, “And this is just piling on even more that election results are not to be trusted.”
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
Why the Trump campaign is going all-in on YouTube ,"For all of Election Day, the Trump campaign will dominate the homepage of YouTube. If you click through to the campaign’s channel, you’ll find featured videos with clickbait-styled titles like “Trigger Warning” and “Prevent a Zombie Uprising.” The thumbnail of the latter video, which is the same 10-second ad on loop for more than 30 minutes, features Democratic presidential nominee Joe Biden’s face turned green and flanked by the zombie emoji. 
Since it was published a few days before Halloween, the Joe Biden zombie video has been viewed more than 7 million times. The homepage takeover ad — which sometimes features a video of Ultimate Fighting Championship fighter Jorge Masvidal expressing support for Trump — was seen by millions in the days leading up to the election. The Masvidal ad was targeted to voters in Florida.
The prime advertising slot is one that the Trump campaign secured months ago, before the Democratic Party had even settled on a nominee. It’s just one part of an aggressive YouTube strategy from the Trump campaign, one that has used tactics like colorful ombre thumbnails and bombastic headlines. Many of the videos seem to be targeted toward the younger audience on the platform, and the strategy has helped Trump land some of the most-viewed political videos on YouTube.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        One of the most popular videos on Trump’s YouTube channel suggests that Joe Biden is a zombie.
      
      
        YouTube
      
    
  


These ads represent the finale of the Trump campaign’s months-long effort to capture the attention of YouTube users. It’s difficult to know how effective his strategy has been and whether the barrage of YouTube content is a useful way to mobilize support for a potential second term, or whether it is yet another sign of the Trump campaign being Extremely Online. At the same time, the extensive focus on the platform is a reminder that Trump originally built his following on television and is reportedly interested in building his own media empire if he’s defeated in this election. 
By several measures, the Trump campaign has succeeded in establishing a dominant presence on YouTube, having collected hundreds of millions of views. Ten of the top 20 viewed political videos from the past week came from Donald Trump’s account, and data collected over the past month reveals a similar trend, according to the independent tracker Transparency Tube. On November 2 alone, the Trump campaign posted more than 50 videos to the platform, many of them cut-ups of his campaign rallies. Biden, in comparison, posted 15. 
YouTube is a powerful platform. It’s where lots of Americans, often young Americans, go for entertainment. Just over one-quarter of Americans get their news from YouTube. Overall, the company claims that just the mobile version of YouTube reaches more people in the United States than any television network. It’s also a place where conspiracy theorists and far-right influencers have been able to find audiences and flourish. Political strategists are increasingly turning to the platform to reach niche audiences. 
“The YouTube recommendation algorithm is a vortex of attention, and so the campaign that’s better at tapping into that is really just reaping free mindshare from voters,” Eric Wilson, a political technologist who has worked with Republican campaigns, told Recode. “The Trump campaign is being efficient with their resources and tapping into their strength.”
Biden and Trump have overall spent just about the same — between about $70 million and $80 million each — on Google platform advertisements since May 2018, according to the company’s ad library. When looking at YouTube specifically, it’s clear that Trump has aimed to prime the platform with his content, publishing everything from hyperbolic ads to misleading information. There are also recycled Fox News segments and at least one 16-second clip of first lady Melania Trump insulting Biden. 
Whether this barrage of video content will help Trump win the election, we don’t know. Trump was still down in the polls on the eve of Election Day, but it was clear that his campaign was winning attention on YouTube. Even if Trump doesn’t prevail, his tactics stand to inspire future conservative campaigns in search of new and younger conservative-leaning online audiences. 
The fight over the YouTube homepage
For the Trump campaign, the homepage takeover on Election Day is a big prize, one the campaign won thanks to an early-access program YouTube created for large advertisers. That clearly frustrated Democrats. 
“At best, the process lacked transparency and clarity,” DNC spokesman Chris Meagher told the New York Times last week. “At worst, it intentionally cut Democrats out of the process.”
Election Day isn’t the first time the Trump campaign has commandeered the YouTube homepage. The campaign secured the same spot in advance of the first presidential debate and during the Democratic National Convention, as well as to feature Trump’s Oval Office speech to announce that he’d be traveling to Walter Reed National Military Medical Center to be treated for Covid-19 (this is currently the Trump page’s most popular video). Biden has also seized the opportunity to take over over the YouTube homepage, including one big ad buy on the Friday before Election Day. 
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        One of the videos on Trump’s Election Day takeover of the YouTube homepage features mixed martial arts fighter Jorge Masvidal, who is from Miami, Florida. 
      
      
        YouTube
      
    
  


YouTube homepage takeovers aren’t just run-of-the-mill ad campaigns. When the takeover is live, anyone who visits the YouTube homepage will see whichever ad copy and video the advertiser wants them to see. Such a big audience also comes with a big price tag. A homepage takeover can reportedly cost $2 million, though it’s unclear if the Election Day buy cost more or less. (YouTube did not comment on these prices, when Recode asked.) This expensive and possibly scattershot tack represents a markedly different approach for the Trump campaign, which built a strategy that involved highly targeted ads on Facebook in 2016.
But big expensive ad efforts don’t necessarily win political campaigns. Tegan O’Neill, the digital communications director at the liberal political group NextGen America, questions whether YouTube’s base will be motivated by these ads — especially since the platform is so popular with young people, who don’t particularly lean toward Trump. 
“A kind of last-minute ad blitz on YouTube, when this administration really has no legs to stand on with this audience? I’m not worried about it,” O’Neill told Recode, arguing that the Trump approach to YouTube is a sign of a campaign “throwing anything at the wall because what they’ve been doing hasn’t been working.”
YouTube video ads are powerful and more comparable to ads on services like Roku and Hulu than those on Facebook and other social media platforms, several strategists told Recode. People go to YouTube specifically to watch videos, so they can’t aimlessly scroll past ads like they might on Facebook or Twitter. It’s also worth noting that users can’t always block ads on YouTube, so if the Trump campaign pays for visibility, it can get it.
“The homepage of YouTube is some of the most valuable real estate on the internet,” Wilson, the Republican technologist, said. “Being able to capture that, that level of attention is tremendously valuable for a campaign.” 
“The value of an asset like that is that it’s zero-sum, right?” Wilson added. “If I have it, you can’t have it.” 
Both Google and the Trump campaign have argued it won the slot fair and square.
“Both presidential campaigns have used and continue to use YouTube to successfully engage with voters, both seeing hundreds of millions of views on their respective channels,” YouTube spokesperson Ivy Choi told Recode regarding each candidate’s overall performance on the platform. “We’ll continue our work to make YouTube a platform for healthy political discourse.”
The peculiar popularity of Trump’s YouTube videos
If you’re watching Trump on YouTube in any given minute, you’re not watching Joe Biden. Through advertisements and organic views, the campaign has adopted a certain style for some videos that it’s promoting heavily with ads targeted to specific locations. 
Like on Twitter and Facebook, Trump has a much bigger following on YouTube than Biden does. Trump has nearly 1.9 million subscribers on YouTube; Biden has just over half a million. In the last 30 days, Donald Trump’s channel has captured nearly 350 million views compared to just over 30 million on Biden’s channel, according to data collected by Social Blade. Importantly, those views include both organic and paid promotions. 
Ads from Trump and Biden strike a markedly different tone; Trump’s have resorted to hyperbole, misinformation, and almost cartoonish editing. In recent weeks, the Trump campaign has paid to promote a series of ads that, like the aforementioned zombie video, feature bright colors, emoji, and meme-inspired text on the thumbnails. One could argue the videos are designed to look like they came from a young YouTube creator rather than something that might air on Fox News:
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        The thumbnail for the Masvidal video, like those on many other videos Trump’s campaign is promoting, features emoji and clickbait-y test.
      
      
        YouTube
      
    
  


“That clicky-style headline is definitely based on the YouTube aesthetic [or] they’re at least trying to meet YouTube consumers where they are,” said Penn State political scientist Kevin Munger. “I guess that makes sense for Trump’s somewhat more anarchic, internet-based, anti-establishment aesthetic. It would be harder to pull off for Democrats and Joe Biden, who are currently running on stability, legitimacy, and professionalism.”
Like other social media platforms, YouTube has adjusted its rules in advance of the election. The platform has also established rules against certain election-related misinformation, like spreading false information about when to vote and promoting the racist birtherism conspiracy. (Over the summer, Google took down hundreds of Trump ads for violating its policies.) The platform also will warn viewers that election results may not be available right away, and no political ads will be allowed after Election Day.
But there’s a catch. Google, which owns YouTube, announced last year that it would limit the ability of campaigns to target political advertisements this election cycle, meaning that users couldn’t be shown ads based on their presumed political leanings or prospective voter lists. Instead, YouTube now allows people to advertise to people based on their age, gender, and zip code, as well as on particular video topics. That diverges from the approach of other tech companies: Facebook has allowed users to turn off targeted political ads, while some platforms, like Twitter, Nextdoor, and TikTok, have opted out of offering them altogether.
  
  
    
    
      
        
  


  






      
    
    
  
  
    
      
        With the exception of his video announcement about traveling to Walter Reed to be treated for Covid-19, Donald Trump’s most popular video on YouTube is the one featuring Masvidal.
      
      
        YouTube
      
    
  


But the Trump campaign has largely accepted YouTube’s limitations on ad targeting. Even some of the more extreme Trump ads are seen by a wide range of people, as they’re not targeted by age or gender. Of course, some of the most-viewed videos do target specific swing states. For instance, the “Trigger Warning” video that features fighter Jorge Masvidal has been targeted to users in Florida. “You know what else is not going to work for them?” Masvidal says in the video, “Playing ‘Despacito’ on your cellphone to pander to us.” 
We’ll soon know whether heavily promoting ads like these — which also include boisterous animations declaring that Donald Trump is still president and meme-y, conspiratorial videos floating that Biden is senile — in the final days of a campaign will help Trump win a second term. 
But regardless of whether he wins or loses the 2020 election, Trump’s YouTube channel reflects an aggressive media strategy that’s designed to attract attention, perhaps at the expense of adding substance to conversations about politics. And while YouTube is pausing election ads after November 3, there’s no reason to think that Trump will be gone from the platform for good. We’ll also have to wait and see if upcoming conservative campaigns won’t try to mimic his approach with emoji-laced memes of their own. 
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.

  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
"They hate Trump for a living. They might miss him, too.","Donald Trump made Sarah Cooper famous. 
She can’t wait for him to leave.
“I’m very excited about him being gone,” says the comedian, who went from (mostly) unknown to omnipresent this spring with a brilliant series of Trump lip-sync videos. “I want my career to do other things, and I don’t want to talk about him anymore.”
Cooper doesn’t have a love-hate relationship with Trump. She hates him. Which puts her in the same boat as other media personalities and companies that have turned the Trump era to their advantage by focusing their ire into opportunities. 
And now that it looks as though Trump might be leaving, they need to figure out what to do next. Even if some of them aren’t ready to say that out loud quite yet. 
To be clear: A post-Trump world doesn’t mean the political and cultural divisions that brought us Trump — and that Trump has exploited — get closed up. But if your reason for being is defeating Donald Trump, and that happens, then … what?
The Lincoln Project, a group of “Never Trump” Republicans who came together less than a year ago to deploy ads against Trump in the 2020 election, now wants to become a media company, according to Axios. The Lincoln Project says that’s not exactly true. But it could be, per a statement from the company:
“We have not floated the idea of becoming producers or a media company … people have approached us about it, and we’ve said to one and all, ‘This is a convo for after the election. We’re locked down tight on the mission of defeating Trump.’”  
So if they were to do that, they’d be following in the footsteps of Crooked Media, the company run by Obama White House veterans, which formed after Trump’s 2016 election. For the last four years, the company has primarily leaned on its flagship Pod Save America podcast but has branched out into other ventures like a newsletter, an HBO show, and other politically-tinged podcasts; industry executives expect the company to add other kinds of nonpolitical programming in a post-Trump world.
One indicator of Crooked Media’s ambition: It has hired Jason Concepcion, a high-profile podcaster from The Ringer, where he specialized in pop culture projects like Binge Mode, a series dedicated to franchises like Harry Potter and Game of Thrones; and NBA Desktop, an inventive version of SportsCenter for the Google Doc + Insta Stories generation. (Of note: Crooked Media’s core team also started their podcasting career at The Ringer.)
Crooked Media co-founder Jon Favreau wouldn’t comment on Concepcion’s role or his company’s post-Trump strategy, but sent a statement hinting at the company’s expanded ambitions: “Crooked has always been in this for the long haul to inform, entertain, and inspire action. We’ll have a lot more to say soon about what’s next, once we all get a chance to breathe after this election.”
Some anti-Trump media will have no choice but to pivot to something else if Trump loses the election. Slate started its popular Trumpcast podcast in the spring of 2016 when it started to look like Trump might be a serious presidential candidate — but not an actual president. It’s still going, but if Trump loses, the show will at least change its name while keeping host Virginia Heffernan, says a Slate PR rep.
“This is a problem we wanted to have,” says Jacob Weisberg, who started Trumpcast at Slate and now runs the podcast studio Pushkin Industries. Pushkin, Weisberg notes, doesn’t have an explicitly anti-Trump show in its lineup. “But I expect a lot of political shows, which are really built on the Trump phenomenon, are going to decline.”
Of course, there are plenty of media outlets that existed before Trump and haven’t said they are directly opposed to his administration but have still benefited from his tenure: The “Trump bump” that the New York Times, Washington Post, CNN, and MSNBC have all seen are well-documented. 
The same goes for individual talents like Maggie Haberman, the Times’s star Trump reporter. Michael Barbaro was a well-regarded but unfamous Times reporter prior to February 2017 when he launched the paper’s The Daily podcast weeks after Trump’s inauguration. Now he’s a star and a star-maker. Jake Tapper has gone from a CNN anchor into a charismatic truth-teller and bluffer-buster: Maybe someone else could have gotten Trump’s chief of staff to announce the White House had given up on containing the pandemic, but Tapper did it on a big platform.
One obvious thing that would go away in a Biden administration is the “can-you-believe-he-did-that” story, which Trump has been reliably serving up since 2015 when he announced his candidacy. Which is different from saying people won’t be outraged — there will be plenty of that going around. But there’s unlikely to be a single focus for that outrage — or someone who seemingly enjoys being that focus.
“There’s going to be a certain kind of easy story that has the potential to go away for all outlets if there’s a change of administration — ‘Administration Official Says Outrageous Thing,’” says Noah Shachtman, editor-in-chief of the Daily Beast. “If Biden does win, his people have shown that they’re pretty careful.”
One big unknown is what kind of interest Trump would generate outside of the White House. Traditionally, presidents have kept a low profile after leaving office, but no one expects that to happen with Trump. The question is how much attention he’ll be able to attract if he’s tweeting as a private citizen instead of a guy with access to nuclear codes and pardon power. 
It’s quite likely that Trump and his remaining hangers-on will try to create some kind of media company after he leaves — an idea they are floating now, just as they had floated in 2016. Then again, he may not need to build much of an operation: Fox News has already demonstrated that it thrives when a Democrat is in the White House, as it did throughout the Obama administration. And it already has an audience that thrills to Trump’s provocations. 
Cooper, meanwhile, has been planning on a post-Trump world for months. She says she made her first Trump-sync, “How to Medical,” as a spur-of-the-moment project to occupy her for a few hours during the pandemic lockdown. 
But over the next few months, as her clips kept going viral, she says they started to feel like an obligation. And in the summer, when her newly acquired talent managers arranged an online Q&A for her, she realized that many of her fans hated Trump more than they liked her.
So she’s been trying to move beyond Trump. Last month she debuted “Everything’s Fine,” a one-off Netflix sketch comedy. She’s also producing a sitcom for CBS. She’s mostly stopped making Trump videos, though she’ll still pop one off occasionally: Last week, when Trump mused publicly about getting in a truck and driving away, she couldn’t help herself. 


How to regret pic.twitter.com/M40KLcw6XL— Sarah Cooper (@sarahcpr) October 26, 2020



But she also knows she’s never going to get completely away from Trump. Her Netflix special includes a different take on her Trump-sync, where she and Helen Mirren re-create the infamous “grab them by the pussy” Access Hollywood audio. And she knows she’ll always be known as someone who got her big break from Donald Trump.
“I just have to keep doing other things for the next few years so all of that gets buried,” she says. “I’m still very proud of these videos — I don’t think I’ll ever not be proud of them. They’re on the right side of history.”
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
How Wikipedia is preparing for Election Day,"If you’re looking for up-to-the-minute results on election night, Wikipedia might be one of the first sites to pop up in your Google search. But, in this case, the crowd-sourced encyclopedia of human knowledge likely won’t have the immediate answers you seek. And that’s by design. 
In yet another election cycle defined by copious amounts of misinformation from a variety of sources, Wikipedia wants — and is set up — to be a carefully curated resource of impartial facts. There’s no rush to be the first to declare a winner (quite the opposite, in fact). It’s also difficult for trolls to vandalize associated pages, let alone keep those edits up for a prolonged period of time or to allow them to spread.
For the 2020 United States presidential election page, as well as the pages for presidential candidates Donald Trump and Joe Biden and vice presidential candidate Kamala Harris, only editors whose accounts are at least 30 days old and who have made at least 500 edits can change the article. This is what Wikipedians, the editors who run the site, call “extended confirmed protection.”
The election page lock was put in place on October 21 by Molly White, who goes by the handle “GorillaWarfare” on the site. She’s been a Wikipedia editor for almost 15 years and also serves as an administrator. This gives her some additional abilities, like the power to lock pages. But White is not anticipating any major issues on Wikipedia with regard to the upcoming election.
“For the most part, things will be business as usual on Wikipedia,” White told Recode. “Wikipedia editors and administrators have plenty of tools at our disposal to ensure that our readers are only seeing accurate information, even as things are changing quickly behind the scenes.”


  Help Vox’s reporting
Vox wants to hear from you about your 2020 voting experience. To share, fill out this short Google form or email crowdsource@vox.com. 


This probably won’t be the case elsewhere online. Like Wikipedia, social media companies run on user-generated content, and they’re once again scrambling to come up with ways to stop the spread of misinformation and disinformation on their platforms. After being blamed for influencing the outcome of the 2016 election, Facebook is particularly concerned with how it will handle Election Day this year.
But Wikipedia, which will be 20 years old on January 15, has been around longer than Facebook, Twitter, and YouTube. This will be the sixth presidential election in Wikipedia’s lifetime, and the site’s all-volunteer army of thousands of editors has used those years of experience to develop and refine methods of combating lies and inaccuracies during prominent breaking new events while also identifying and deleting anything incorrect or poorly sourced that happens to make it onto their pages.
Wikipedia editors are currently discussing how to handle Election Day and its results in public forums on the site. They’re debating how many sources to use for election-related updates, which ones to rely on when a presumptive winner is declared, and how long after polls close to start adding the results to the page.
“Wikipedia is intended to be an encyclopedia, not a news organization, and so we are much more concerned with being accurate than we are with being quick,” White said.
Indeed, Wikipedia’s stated mission is to be a repository for all human knowledge. The site has 55 million articles across its 300 versions — the most popular version, English, has 6.2 million articles. Wikipedia is also one of the most-read websites in the world, with 1.5 billion unique visitors per month.  
So while huge social media platforms tend to expose their users to content that generally fits their existing worldview and political sensibilities, Wikipedia has quietly emerged as a website for people who are actively seeking accurate information. What’s behind the effort is a community that strives to provide that information as neutrally and as accurately sourced as possible.  
Wikipedia’s Election Day plan
Wikipedia is ruled by consensus, its articles are fluid, and discussions over how and why they should be changed are ongoing. Wikipedia putting up information about the presidential election is no different.
Most pages associated with the election and candidates have some kind of edit protection on them, though the level of protection might vary. For example, while Harris currently has extended confirmed protection, her opponent, Mike Pence, has a page that is only “semi-protected.” That means edits can only be made by registered users whose accounts are at least four days old and have made at least 10 edits — though, again, this might change as Election Day nears. 
Similarly, many United States politics-associated pages are also subject to additional rules limiting edits to reverse a previous edit or requiring a consensus to apply any edits that have been challenged. To reach consensus, editors will typically argue their respective viewpoints on an article’s accompanying “talk” page, citing various Wikipedia rules and procedures to back up their case until a majority of editors agree on what to do next. Administrators can block or ban editors who don’t follow those rules.
When it comes to the election results, editors are still hashing out whether the Associated Press’s projections are a good enough single source or if at least three news sources should be used. They’re also considering just locking certain pages from edits for everyone except administrators for a set period of time.
With standards, rules, and a community of editors to uphold them, “moving slowly has been a Wikipedia superpower,” Noam Cohen recently wrote in Wired. That, Cohen added, makes the site a less attractive target “to those bent on campaigns of misinformation with immediate payoffs.” Vandalism is hard to add, usually doesn’t stay up for long, and therefore doesn’t spread widely. 
While Facebook and Google have spent billions of dollars on content moderators and other measures to combat misinformation and abuse on their platforms, Wikipedia’s editors do this work for free. Wikipedia is hosted by the nonprofit Wikimedia Foundation, which covers its associated costs, including servers, software, and legal fees. The Foundation relies on donations and gifts and gets a lot of them: The organization received $113 million last year alone.
“The Foundation’s role is to support those folks in every way that that they need us to,” Ryan Merkley, Wikimedia Foundation’s chief of staff, told Recode. “That means everything from keeping the servers up and running, to running our security operation, to communications, fundraising. But also working with trust and safety, and then supporting [editors] with the tools that they need in order to edit.”
Some of those tools include bots that can quickly detect article vandalism and either get rid of it or flag it to an editor. Editors can also add articles to their “watch lists” to be immediately alerted of any changes (nearly 550 editors have put the 2020 US presidential election page on their watch lists). And they can lock pages that might or already have become targets for vandalism.
The Foundation has also done some of its own work to prepare for the election.
“We put together an internal task force, with staff representatives from every part of the foundation who relate to disinformation,” Merkley said. “So that includes the security team, trust and safety, legal policy, communications, our partnerships group that works with the other platforms that engage with Wikimedia content.”
Wikipedia has its own challenges and high stakes
The guiding principle behind Wikipedia is that anyone can contribute anything to it. This being the internet, not everyone operates in good faith or knows what they’re talking about, so the site has a longstanding reputation for inaccuracy. That’s no longer wholly deserved, but Wikipedia itself will tell you that it’s not a reliable source for this very reason.  
The site has also been criticized for systemic bias, with a lack of representation from certain demographics — there’s a lot of white English-speaking men who contribute — that can create a hostile environment for minority editors. The lack of diversity also has the potential for bias to make it into the articles themselves. The Wikipedia Foundation and Wikipedians have made efforts to improve this, but they still have work to do.
Other things get overlooked on a site as big as Wikipedia, too. For instance, you might stumble across vandalized articles, usually lurking in Wikipedia’s lower-trafficked corners, that have managed to escape the notice of editors. You may even find a version of Wikipedia that contains thousands of articles written by someone who doesn’t really know the language they’re supposed to be written in.
While anyone can become a Wikipedia editor, only a tiny fraction of Wikipedia’s readers actually will. And it’s deceptively difficult. The initial process of making an edit is as simple as signing in and changing some text, but Wikipedia’s editorial rules and processes — and the various code words and language around them — can be a barrier to doing it correctly, which is necessary for the edit to be accepted. 
But the people who get it, like White, may spend a considerable amount of their time doing unpaid work on the site. They might also become the target of harassment as a result. White, who spends two or three hours a day working on Wikipedia, said she’s been doxxed, threatened with violence and lawsuits, and people have even tried to get her fired from her day job because of it.
“It is at best frustrating and at worst extremely frightening, but I both care deeply about the importance of Wikipedia and I am also a very stubborn person who does not like to feel like I am giving in to threats,” White said, attributing some of that harassment to her position as an administrator, her gender, and the controversial articles and topics she often works on (she created the Boogaloo movement page, for example).
And Wikipedia is important. It’s one of the top results for most internet searches, and so, for better or worse, Wikipedia is the site people are most likely to visit when they want more information about something. That means the stakes are high when big topics are involved. 
Notably, its coverage of Covid-19 has drawn praise. This involved the creation of a “WikiProject” dedicated to the virus with over 200 participating editors (anyone can join!) who may focus on pandemic case data, the virus’s impact on specific locations, or the industries affected. One professor who studies misinformation told the Washington Post that Wikipedia was “a ray of hope in a sea of pollution” and handled the virus “exceptionally well.”
“There’s a lot of really great work done through these WikiProjects, especially during times of crisis where a lot of hard-hitting, late-breaking stuff is coming out,” Zachary J. McDowell, an assistant professor in the Department of Communication at the University of Illinois at Chicago, told Recode.
So if Wikipedia, with its high visibility and wide-open door for anyone’s contributions, can still provide readers with well-sourced, neutral articles, why can’t the social media platforms that play such a big role in the spread of misinformation do the same? Clearly, some of them see the merits of Wikipedia’s work; Facebook and Google use Wikipedia articles to provide additional knowledge in user searches.
Freeing information from the algorithms
Social media is designed to keep users on their platforms for as long as possible, both to show them as many ads as possible and to collect their data, which is then used to show them even more ads. They are incentivized to keep your attention, not to ensure that what you’re reading or seeing is accurate. That business model is unlikely to change anytime soon. Meanwhile, Wikipedia’s model is quite different.
“[Wikipedia has] no algorithms designed to serve content in certain ways to some people,” Merkley said. “None of that structure exists which can be later gamed, in order to advance this post about a person or to target this message to that person.” 
Wikipedia is also very transparent, Merkley said. An article’s associated history and talk pages will tell you, in great and granular detail, all the edits that have been made, who made them, and any associated discussions between editors about them.
This transparency helps create trust, but good luck getting, say, Facebook to implement it. Facebook is notoriously secretive about its algorithms, which determine what you see on the site, from ads to posts from your friends to recommendations for groups you should join or people you should befriend. These algorithms create filter bubbles of information that tends to line up with your political viewpoints, offering little exposure to anything that might conflict with them. You get what Facebook thinks you want to hear or watch what YouTube thinks you want to watch, and that’s not always what’s true. 
“It is essentially a game where the entire system is already rigged for disinformation, fake news,” McDowell said. “It’s monetarily incentivized to get people riled up and to click. It will always be a game where those who are trying to control the information flow will be the ones who are one step behind.”
McDowell’s studies include Wikipedia’s value as a teaching tool for information literacy. He stresses that Wikipedia itself shouldn’t be seen as a source but rather as a collection of information, clearly cited, that users can follow if they want to learn more or verify what they’ve read.
“Having a critical eye toward information is absolutely imperative right now,” McDowell said. “And a lot of people don’t.”
For their part, social media platforms have, in recent years, tried to hold back the flow of misinformation in some cases, including during the election. Facebook has made rules around political ads, voter suppression, and even premature declarations of victory. But social media still receives plenty of criticism from both sides of the aisle, and it will almost certainly be blamed for influencing the outcome of the election in some way, regardless of the winner.
Wikipedia, on the other hand, will just tell you who reliable sources say the winner is — as soon as its editors reach a consensus on what those sources are.
Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.
  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
The long-term consequences of Trump’s conspiracy theory campaign,"Over the past few months, President Trump has repeatedly attacked the integrity of the US election by pushing a conspiracy theory that mail-in voting will lead to mass voter fraud. 
Never mind that mail-in ballot voter fraud rates have historically been extremely low, and Americans have voted by mail with very few problems since the Civil War. Trump has still baselessly called the election “rigged,” accused Democrats of trying to “steal” the election, and urged his followers to join an “army” of poll watchers to monitor this unproven voting malfeasance. 
Democrats, too, have spread unproven theories and anxiety about voting. Some have  alleged that Trump was trying to cripple the US Postal Service in order to slow the election. (The USPS is struggling to deliver ballots in time but it’s not proven this is due to a directive by Trump.) And some have asserted that Republicans are engaging in voter suppression tactics. (Trump’s campaign is making legal efforts to make it harder for people across the country to vote; it says these efforts are in support of election transparency.) 
The result is that a high percentage of Americans believed the election would be unfair in some way, even before it started.
About 42 percent of Americans — evenly split between Democrats and Republicans — thought it was somewhat or very likely that fraud would play a role in the 2020 election if their favored presidential candidate didn’t win, according to a national poll in October of more than 2,000 people conducted by political science professor Joseph Uscinski and his colleague at the University of Miami. 
Some of the conspiracy theories split across party lines — 70 percent of Republicans versus 30 percent of Democrats polled believed that allowing ballots to be sent by mail would increase instances of voter fraud, suggesting that Trump’s repeated promotion of this theory has had some impact on his Republican base. Democrats, meanwhile, were more likely to believe that there is an effort to stop the US Postal Service from processing mail-in ballots.  
“There are always a good amount of people who believe the election is going to be rigged — that’s sort of standard,” Uscinski told Recode. “This year, those numbers tend to be really high.”
This is bad news for the 2020 election. But it also has potential ramifications that extend far beyond it. If the conditions that made people likely to believe in fraud continue, some experts worry we may see a prolonged loss of confidence in the voting process.
“What’s worrisome to me is that no matter what the election outcome is, the effect found on our democratic institutions are going to be felt for years to come,” said Nina Jankowicz, a researcher on disinformation for the Woodrow Wilson Center. “People are not trusting that their ballots are going to be counted. I mean, this is pretty fundamental stuff.” 
Other experts, like Uscinski, aren’t so sure.
“Trump is different than any other president in that he is not really a party politician. He ran not just against the other party but against establishment writ large, and he built a coalition using a lot of unsavory rhetoric, including conspiracy theories,” said Uscinski. “I think it’s largely unhealthy, but I think once he’s gone and we have another president who doesn’t engage in that, things may return to normal.” 
It’s too soon to say how much of a lasting effect Trump’s presidency will have on political norms in this country (whether he remains in office beyond 2020 or not). But the increase in conspiratorial thinking about this election shows how the public’s trust in facts has eroded — and that poses a threat to our democracy and society. 
Right now, some of the most prevalent conspiracy theories are focused on the election. But conspiracy theorists have already gotten to work spreading misinformation about arguably an even higher-stakes issue: Covid-19, which continues to spread at a record pace in the US as the country heads into winter. 
Around 30 percent of the American public believes in some coronavirus conspiracy theory, including that the threat of the virus is exaggerated to harm Trump and that the virus was purposely created, according to a recent study published in the Harvard Misinformation Review. This denial of the basic science about things like mask-wearing or the seriousness of the disease, both endorsed by Trump, have contributed to real harm. Almost 230,000 Americans have died from Covid-19. 
The question moving forward, researchers say, is whether or not Trump will continue to  influence people’s beliefs. How much will movements that have formed in the last four years continue to infiltrate mainstream thinking and politics, even if Biden does win?
Why it feels like we’re hearing about conspiracy theories more than ever
Polls show that, overall, the percentage of Americans who believe in conspiracy theories hasn’t changed much over time. So then why do we hear about them so often lately — including on major political stages? 
“It’s not a new phenomenon, but it feels like we are living in a new era because information spreads so quickly,” said Kathryn Olmsted, a professor at UC Davis who has studied the history of conspiracy theories. “In the Middle Ages, with something like blood libel [which is the idea that Jewish people were using Christian people’s blood for ritualistic sacrifices], people heard about that by word of mouth. But now you can reach a lot more people through social media.” 
Take Plandemic, a 26-minute video that made egregiously false claims about the coronavirus, including that it was planned by Anthony Fauci and global elites like Bill Gates. Within days of being posted in May, the video racked up 8 million views across social media platforms like Facebook, YouTube, and Twitter. 
Though social platforms eventually took the Plandemic video down, Trump and his advisers tweeted a video with some similar claims a few months later.
Still, there’s no tangible data that videos like Plandemic have actually changed most people’s beliefs. Uscinski’s polling showed that the percentage of Americans who say they believe Covid-19 is a hoax remained stable in the months before and after Plandemic was released.
A different way to study the effects of something like the Plandemic video would be to track if the specific behavior and beliefs of people who watched it changed over time. But Facebook and other social media companies make it very difficult for academics to do that because they limit access to such data due to what they say are privacy concerns.
But perhaps whether or not these conspiracy theories are recruiting more believers via social media isn’t the biggest concern. A more important question, researchers told Recode, is whether social media can push people into echo chambers of their own beliefs and nudge them toward being more extreme.
“If you just spend time with people who say the same thing you think, you’re going to say that more and more and more. Your notion of what constitutes neutrality is completely skewed by comparison groups,” said Dannagal Young, a communications and political science professor at the University of Delaware. “Chronic exposure to homogeneous opinions will cause people’s own opinions to become more extreme in the direction they were already inclined.”
A recent example of the real-world dangers of conspiracy theories can be found in QAnon, which started off as a relatively fringe idea in the dark corners of the internet three years ago but has now penetrated mainstream American politics. It’s gained the tacit endorsement of some established Republican politicians, including Trump himself — despite the fact that the FBI has designated the theory as a domestic terrorism threat. About a dozen people inspired by QAnon have been charged with committing or attempting to commit violent crimes, including two murders and an armed police standoff at Hoover Dam. 
Nearly two dozen people who have been linked to QAnon are now running for Congress, including one, Marjorie Taylor Greene, who will likely win. And Trump himself has implicitly endorsed the theory, sharing posts from social media accounts promoting the theory hundreds of times and twice refusing to condemn the theory when questioned about it during an election town hall this month, saying he agrees with parts of the theory. 
Recent polling suggests only a small percentage of Americans actually believe that there is truth to QAnon’s wild claims. But Trump’s normalization of something that’s considered a domestic terrorist threat proves how dangerous conspiracy theories can be, regardless of their scale — especially if they’re exploited and promoted by political leaders.
Beyond Trump: Factors associated with conspiracy theories
Conspiracy theories influencing politics isn’t new. Before Trump’s presidency, parts of the American public have long embraced conspiratorial thinking. Some conspiracy theories, such as doubts about JFK’s assassination, had at one point as much as 80 percent support with the American public, far higher than the 30 percent of people who believe in Covid-19 conspiracies today. 
Researchers told Recode that conspiracy theories tend to thrive in times of heightened fear and uncertainty. When people feel scared, they may seek explanations in anything that provides a sense of control. That’s where we’re finding ourselves now, right before a presidential election that some believe will shape the future of US democracy and as Covid-19 cases spike eight months into a global pandemic.
“People are looking for some certainty now, even if that certainty comes in the form of something that is totally outlandish,” said Jankowitz.
“I always come at these questions from a standpoint of evolutionary psychology,” said Young. “We are all social animals, all looking for cues around us to cue to our systems how we are supposed to react. And everything around us is telling us we are supposed to be reacting as though there’s an imminent threat.”
And during this flurry of uncertainty about a new disease, official sources of information — like the White House and National Institute of Allergy and Infectious Diseases Director Anthony Fauci — are often actively in conflict with each other. 
Take the topic of masks. In the early months of the pandemic, public health officials like Fauci initially told Americans not to wear masks and reserve them for front-line health care workers, a message echoed by major media publications and politicians. But as the virus progressed, agencies like the World Health Organization and the Centers for Disease Control and Prevention reversed their guidance, as did most major media outlets. Yet Trump for months refused to wear a mask in public; he only recently changed his stance somewhat — while continuing to mock people who wear them.
This is just one example out of the vast number of false and misleading statements Trump has made during his four years in office, eroding the public’s trust in basic facts.
Part of the strategy of Covid-19 conspiracy theorists is to frame the initial mixed messaging in mainstream media and public health leadership as a deliberate plan to cause harm. And since many people have lost confidence in major media outlets to report the truth, they are turning to online communities as sources of information instead, where it’s easy to find such theories.
“When the information in the world is confusing, and when there are so many competing messages, what we can rely on is an understanding of group allegiances and group identity — primal allegiances to groups,” said Young.
A Biden presidency could disempower but not get rid of conspiracy theories
A Biden presidency would be likely to reduce the influence of conspiracy theories in politics. His record indicates that he listens to scientific and academic consensus rather than fringe beliefs when it comes to major issues.
But in the case of a Biden victory, Trump’s supporters could be even more likely to embrace conspiracies and feel the system is working against them.
In fact, research suggests that conspiracy theories are perpetuated more often by the political party of the “losers” in an election, meaning if Trump loses, we could expect to see more conspiracy theories launched against liberals. Until now, Trump has bucked this trend — in part, people think, because though he’s president, he presents himself as facing constant opposition.
Whether or not people will continue to listen to Trump when he leaves office — whether it’s when his current term ends or four years from now — is a harder question to answer. If Trump doesn’t continue to attract a steady stream of media attention, interest in the conspiracy theories he promotes may die down. 
But politics aside, a bigger conspiracy theory battle may play out post-election as the US tries to overcome Covid-19. 
Scientists are racing to develop a vaccine, but it will only curb the pandemic if a critical mass of people take it. In a September poll by Pew, only 51 percent of Americans said they would take a coronavirus vaccine if it were available today — a decline from some 72 percent of Americans who said they would take a vaccine in a July poll, also conducted by Pew. 
That’s worrying, because scientists say about 70 percent of the population needs immunity to the coronavirus in order to end the pandemic. 
Olmsted, who has studied the history of conspiracy theories across decades of US history, said she can’t think of a scenario involving conspiracy theories that’s higher stakes. “It’s terrifying because if these conspiracy theories mean that fewer people take the vaccine, then that endangers all of us.” 


  
  
  
    Will you help keep Vox free for all?
  
  
    Millions of people rely on Vox to understand how the policy decisions made in Washington, from health care to unemployment to housing, could impact their lives. Our work is well-sourced, research-driven, and in-depth. And that kind of work takes resources. Even after the economy recovers, advertising alone will never be enough to support it. If you have already made a contribution to Vox, thank you. If you haven’t, help us keep our journalism free for everyone by making a financial contribution today, from as little as $3.",,,,,
"Google AI Tech Will Be Used for Virtual Border Wall, CBP Contract Shows","AFTER YEARS of backlash over controversial government work, Google technology will be used to aid the Trump administration’s efforts to fortify the U.S.-Mexico border, according to documents related to a federal contract.

In August, Customs and Border Protection accepted a proposal to use Google Cloud technology to facilitate the use of artificial intelligence deployed by the CBP Innovation Team, known as INVNT. Among other projects, INVNT is working on technologies for a new “virtual” wall along the southern border that combines surveillance towers and drones, blanketing an area with sensors to detect unauthorized entry into the country.

In 2018, Google faced internal turmoil over a contract with the Pentagon to deploy AI-enhanced drone image recognition solutions; the capability sparked employee concern that Google was becoming embroiled in work that could be used for lethal purposes and other human rights concerns. In response to the controversy, Google ended its involvement with the initiative, known as Project Maven, and established a new set of AI principles to govern future government contracts.",,,,,
Protests for Black Lives,"NEW YORK STARTUP Dataminr aggressively markets itself as a tool for public safety, giving institutions from local police to the Pentagon the ability to scan the entirety of Twitter using sophisticated machine-learning algorithms. But company insiders say their surveillance efforts were often nothing more than garden-variety racial profiling, powered not primarily by artificial intelligence but by a small army of human analysts conducting endless keyword searches.

In July, The Intercept reported that Dataminr, leveraging its status as an official “Twitter Partner,” surveilled the Black Lives Matter protests that surged across the country in the wake of the police killing of George Floyd. Dataminr’s services were initially designed to help hedge funds turn the first glimmers of breaking news on social media into market-beating trades, enabling something like a supercharged version of professional Twitter dashboard TweetDeck. They have since been adopted by media outlets, the military, police departments, and various other organizations seeking real-time alerts on chaos and strife.",,,,,
The Coronavirus Crisis,"NEW YORK STARTUP Dataminr aggressively markets itself as a tool for public safety, giving institutions from local police to the Pentagon the ability to scan the entirety of Twitter using sophisticated machine-learning algorithms. But company insiders say their surveillance efforts were often nothing more than garden-variety racial profiling, powered not primarily by artificial intelligence but by a small army of human analysts conducting endless keyword searches.

In July, The Intercept reported that Dataminr, leveraging its status as an official “Twitter Partner,” surveilled the Black Lives Matter protests that surged across the country in the wake of the police killing of George Floyd. Dataminr’s services were initially designed to help hedge funds turn the first glimmers of breaking news on social media into market-beating trades, enabling something like a supercharged version of professional Twitter dashboard TweetDeck. They have since been adopted by media outlets, the military, police departments, and various other organizations seeking real-time alerts on chaos and strife.",,,,,
Facebook Contractor Downplays Coronavirus Risk for Content Moderators,"FACEBOOK CONTRACTORS TASKED with sifting through some of the most heinous and traumatizing content on the internet faced a new hurdle this week when they were told to return to company offices to do their work in person as a pandemic runs rampant around them. Audio obtained by The Intercept suggests that their employer, Accenture, is downplaying the risk of indoor exposure to Covid-19.

When the United States began a patchwork national lockdown in March, Facebook contractors, paid a relatively low hourly wage with few of the generous perks afforded to the company’s full-time staffers, began to feel even more acutely dispensable to the $750 billion company. Beginning this week, as first reported by The Verge, these contractors must now resume working in the same facilities that Facebook’s full-time can safely avoid, having been told that they’ll be permitted to work from home through July 2021. “Based on guidance from health and government experts, as well as decisions drawn from our internal discussions about these matters, we are allowing employees to continue voluntarily working from home until July 2021,” a Facebook spokesperson explained to Business Insider.

Facebook has said that the contractors in question, who must wade through so-called priority zero content encompassing the worst of child sexual abuse and graphic violence, can’t safely do this work from home. Three Facebook moderators employed through Accenture who spoke to The Intercept on the condition of anonymity, because they are not permitted to speak with the press, expressed a profound worry that the company, and their ultimate bosses at Facebook HQ, are once again ignoring their safety in the name of keeping the social network running smoothly.",,,,,
Crumbling Case Against Assange Shows Weakness of “Hacking” Charges Related to Whistleblowing,"BY 2013, the Obama administration had concluded that it could not charge WikiLeaks or Julian Assange with crimes related to publishing classified documents — documents that showed, among other things, evidence of U.S. war crimes in Iraq and Afghanistan — without criminalizing investigative journalism itself. President Barack Obama’s Justice Department called this the “New York Times problem,” because if WikiLeaks and Assange were criminals for publishing classified information, the New York Times would be just as guilty.

Five years later, in 2018, the Trump administration indicted Assange anyway. But, rather than charging him with espionage for publishing classified information, they charged him with conspiracy to commit a computer crime, later adding 17 counts of espionage in a superseding May 2019 indictment and expanding on those charges in another superseding indictment in June 2020.",,,,,
Protests for Black Lives,"BY 2013, the Obama administration had concluded that it could not charge WikiLeaks or Julian Assange with crimes related to publishing classified documents — documents that showed, among other things, evidence of U.S. war crimes in Iraq and Afghanistan — without criminalizing investigative journalism itself. President Barack Obama’s Justice Department called this the “New York Times problem,” because if WikiLeaks and Assange were criminals for publishing classified information, the New York Times would be just as guilty.

Five years later, in 2018, the Trump administration indicted Assange anyway. But, rather than charging him with espionage for publishing classified information, they charged him with conspiracy to commit a computer crime, later adding 17 counts of espionage in a superseding May 2019 indictment and expanding on those charges in another superseding indictment in June 2020.",,,,,
Protests for Black Lives,"WHEN 17-YEAR-OLD Kyle Rittenhouse killed two Black Lives Matter protesters (and wounded a third) in late August in Kenosha, Wisconsin, he instantly became a hero among white nationalist circles, in which the Second Amendment is sacrosanct.

On Wednesday, Rittenhouse and the members of the armed militias that supported him, including the Kenosha Guard and Boogaloo Bois, were named in a federal lawsuit brought under the post-Civil War Reconstruction amendments that aimed to establish Black equality.

The suit also names what it alleges was the militia groups’s most prominent enabler: Facebook. All of the parties, the complaint contends, helped deprive Kenosha Black Lives Matter protesters of their First Amendment right to assemble, thus violating the Black Lives Matter activists’ 14th Amendment right to equal protection.",,,,,
Operation Legend Is Bringing Surveillance Tech to Cities,"IN AUGUST, 40 federal agents arrived in Memphis. Some were already on the ground by the time U.S. Attorney Michael Dunavant announced the onset of Operation Legend and the city became, along with St. Louis, the seventh to be targeted by the Justice Department’s heavy-handed initiative to reduce violent crime. Many of the agents are on temporary assignment, working in collaboration with police; nearly half will relocate by November. But they will leave behind a city flush with grant money for local police — and heightened surveillance capabilities.

In Memphis, organizers have long battled police surveillance. The fight came to a head in 2017, when a lawsuit against the city of Memphis revealed years of close surveillance of Black Lives Matter activists and union organizers. “We knew we were being watched and monitored and surveilled,” said Hunter Demster, an activist who was tracked on social media by MPD. The suit was successful, and in 2018, a federal judge ordered an independent monitor to oversee policing in the city. Now, activists there say that Operation Legend is a serious blow.",,,,,
BlueLeaks,"THE RISE OF the internet-connected home security camera has generally been a boon to police, as owners of these devices can (and frequently do) share footage with cops at the touch of a button. But according to a leaked FBI bulletin, law enforcement has discovered an ironic downside to ubiquitous privatized surveillance: The cameras are alerting residents when police show up to conduct searches.

A November 2019 “technical analysis bulletin” from the FBI provides an overview of “opportunities and challenges” for police from networked security systems like Amazon’s Ring and other “internet of things,” or IoT, devices. Marked unclassified but “law enforcement sensitive” and for official use only, the document was included as part of the BlueLeaks cache of material hacked from the websites of fusion centers and other law enforcement entities.",,,,,
Online Lenders Are Preying on Desperate Borrowers and Could Trigger a New Consumer Financial Crisis,,,,,,
Facebook’s Ban on Far-Left Pages Is an Extension of Trump Propaganda,,,,,,
BlueLeaks,"WHOEVER BROKE INTO 251 law enforcement websites and obtained the BlueLeaks trove of documents appears to have reused decades-old software for opening “backdoors” in web servers.

The use of the widely available backdoors provides evidence that the hacktivist who compromised the sensitive sites, including fusion centers linked to federal agencies, didn’t need to use sophisticated digital attack methods because the sites were not very secure.",,,,,
Voices,,,,,,
Protests for Black Lives,,,,,,
BlueLeaks,"WHILE DOCTORS AND politicians still struggle to convince Americans to take the barest of precautions against Covid-19 by wearing a mask, the Department of Homeland Security has an opposite concern, according to an “intelligence note” found among the BlueLeaks trove of law enforcement documents: Masks are breaking police facial recognition.

The rapid global spread and persistent threat of the coronavirus has presented an obvious roadblock to facial recognition’s similar global expansion. Suddenly everyone is covering their faces. Even in ideal conditions, facial recognition technologies often struggle with accuracy and have a particularly dismal track record when it comes to identifying faces that aren’t white or male. Some municipalities, startled by the civil liberties implications of inaccurate and opaque software in the hands of unaccountable and overly aggressive police, have begun banning facial recognition software outright. But the global pandemic may have inadvertently provided a privacy fix of its own — or for police, a brand new crisis.",,,,,
BlueLeaks,"AFTER FAILING TO PREVENT the terrorist attacks of September 11, 2001, the U.S. government realized it had an information sharing problem. Local, state and federal law enforcement agencies had their own separate surveillance databases that possibly could have prevented the attacks, but they didn’t communicate any of this information with each other. So Congress directed the newly formed Department of Homeland Security to form “fusion centers” across the country, collaborations between federal agencies like DHS and the FBI with state and local police departments, to share intelligence and prevent future terrorist attacks.

Yet in 2012 the Senate found that fusion centers have “not produced useful intelligence to support Federal counterterrorism efforts,” that the majority of the reports fusion centers produced had no connection to terrorism at all, and that the reports were low quality and often not about illegal activity. Fusion centers have also been criticized for privacy and civil liberties violations such as infiltrating and spying on anti-war activists.

Last month, the transparency collective Distributed Denial of Secrets published 269 gigabytes of law enforcement data on its website and using the peer-to-peer file sharing technology BitTorrent. The data, stolen from 251 different law enforcement websites by the hacktivist collective Anonymous, was mostly taken from fusion center websites (including many of those listed on DHS’s website), though some of the hacked websites were for local police departments, police training organizations, members-only associations for cops or retired FBI agents, and law enforcement groups specifically dedicated to investigating organized retail crime, drug trafficking, and working with industry.",,,,,
"The Microsoft Police State: Mass Surveillance, Facial Recognition, and the Azure Cloud","NATIONWIDE PROTESTS AGAINST racist policing have brought new scrutiny onto big tech companies like Facebook, which is under boycott by advertisers over hate speech directed at people of color, and Amazon, called out for aiding police surveillance. But Microsoft, which has largely escaped criticism, is knee-deep in services for law enforcement, fostering an ecosystem of companies that provide police with software using Microsoft’s cloud and other platforms. The full story of these ties highlights how the tech sector is increasingly entangled in intimate, ongoing relationships with police departments.

Microsoft’s links to law enforcement agencies have been obscured by the company, whose public response to the outrage that followed the murder of George Floyd has focused on facial recognition software. This misdirects attention away from Microsoft’s own mass surveillance platform for cops, the Domain Awareness System, built for the New York Police Department and later expanded to Atlanta, Brazil, and Singapore. It also obscures that Microsoft has partnered with scores of police surveillance vendors who run their products on a “Government Cloud” supplied by the company’s Azure division and that it is pushing platforms to wire police field operations, including drones, robots, and other devices.",,,,,
Protests for Black Lives,"LEVERAGING CLOSE TIES to Twitter, controversial artificial intelligence startup Dataminr helped law enforcement digitally monitor the protests that swept the country following the killing of George Floyd, tipping off police to social media posts with the latest whereabouts and actions of demonstrators, according to documents reviewed by The Intercept and a source with direct knowledge of the matter.

The monitoring seems at odds with claims from both Twitter and Dataminr that neither company would engage in or facilitate domestic surveillance following a string of 2016 controversies. Twitter, up until recently a longtime investor in Dataminr alongside the CIA, provides the company with full access to a content stream known as the “firehose” — a rare privilege among tech firms and one that lets Dataminr, recently valued at over $1.8 billion, scan every public tweet as soon as its author hits send. Both companies denied that the protest monitoring meets the definition of surveillance.

A History of Police Work

Dataminr helps newsrooms, corporations, and governments around the world track crises with superhuman speed as they unfold across social media and the wider web. Through a combination of people and software, the company alerts organizations to chatter around global crises — wars, shootings, riots, disasters, and so forth — so that they’ll have a competitive edge as news is breaking. But the meaning of that competitive edge, the supercharged ability to filter out important events from the noise of hundreds of millions of tweets and posts across social media, will vary drastically based on the customer; the agenda of a newspaper using Dataminr to inform its breaking news coverage won’t be the same as the agendas of a bank or the FBI. It’s this latter category of Dataminr’s business, lucrative government work, that’s had the firm on the defensive in recent years.

In 2016, Twitter was forced to reckon with multiple reports that its platform was being used to enable domestic surveillance, including a Wall Street Journal report on Dataminr’s collaboration with American spy agencies in May; an American Civil Liberties Union report on Geofeedia, a Dataminr competitor, in October; and another ACLU investigation into Dataminr’s federal police surveillance work in December. The company sought to assure the public that attempts to monitor its users for purposes of surveillance were strictly forbidden under its rules, and that any violators would be kicked off the platform. For example, then-VP Chris Moody wrote in a company blog post that “using Twitter’s Public APIs or data products to track or profile protesters and activists is absolutely unacceptable and prohibited.” In a letter to the ACLU, Twitter public policy chief Colin Crowell similarly wrote that “the use of Twitter data for surveillance is strictly prohibited” and that “Datatminr’s product does not provide any government customers with … any form of surveillance.”

Twitter also said that Dataminr, one of its “official partners,” would “no longer support direct access by fusion centers” to information such as tweet locations; fusion centers are controversial facilities dedicated to sharing intelligence between the federal government and local police. Dataminr at the same time announced it would no longer provide a product for conducting geospatial analysis “to those supporting first reponse” and added that such clients did not have “direct firehose access.”

But based on interviews, public records requests, and company documents reviewed by The Intercept, Dataminr continues to enable what is essentially surveillance by U.S. law enforcement entities, contradicting its earlier assurances to the contrary, even if it remains within some of the narrow technical boundaries it outlined four years ago, like not providing direct firehose access, tweet geolocations, or certain access to fusion centers.

Dataminr relayed tweets and other social media content about the George Floyd and Black Lives Matter protests directly to police, apparently across the country. In so doing, it used to great effect its privileged access to Twitter data — despite current terms of service that explicitly bar software developers “from tracking, alerting, or monitoring sensitive events (such as protests, rallies, or community organizing meetings)” via Twitter.",,,,,
Controversial Data-Mining Firm Palantir Vanishes From Biden Adviser’s Biography After She Joins Campaign,"IN THE RUN-UP to the 2020 election, former Vice President Joe Biden’s campaign is putting together a foreign policy team for a potential future administration. Among those described as being part of the team is Avril Haines, former deputy director of the CIA during the Obama administration. According to an NBC News report from last week, Haines has been tapped to work advising on policy, as well as lead the national security and foreign policy team.

In addition to her past national security work and impressive presence in the D.C. think tank world, Haines has in the past described herself as a former consultant for the controversial data-mining firm Palantir. Haines’s biography page at the Brookings Institute, where she is listed as a nonresident senior fellow, boasted of this affiliation until at least last week, when it suddenly no longer appeared on the page.

The nature of the consulting work that Haines did for Palantir is not clear. As of press time, requests for comment to her, the Biden campaign, Palantir, and Brookings were not answered. Prior to being removed from the Brookings page, the connection to the data-mining company was listed alongside a long list of other affiliations that were similarly pared down.",,,,,
Protests for Black Lives,"THE FEDERAL BUREAU of Investigation may be watching what you tweet and where people gather.

The federal law enforcement agency’s records show a growing focus on harnessing the latest private sector tools for mass surveillance, including recent contracts with companies that monitor social media posts and collect cellphone location data.

On June 9, after demonstrations around the country erupted over the police killing of George Floyd, the FBI signed an expedited agreement to extend its relationship with Dataminr, a company that monitors social media.

About a week prior, the agency modified an agreement it signed in February with Venntel, Inc., a Virginia technology firm that maps and sells the movements of millions of Americans. The company purchases bulk location data and sells it largely to government agencies.",,,,,
"Weeks After PTSD Settlement, Facebook Moderators Ordered to Spend More Time Viewing Online Child Abuse","WITH THE INK still drying on their landmark $52 million settlement with Facebook over trauma they suffered working for the company, many outsourced content moderators are now being told that they must view some of the most horrific and disturbing content on the internet for an extra 48 minutes per day, The Intercept has learned.

Following an unprecedented 2018 lawsuit by ex-Facebook content moderator Selena Scola, who said her daily exposure to depictions of rape, murder, and other gruesome acts caused her to develop post-traumatic stress disorder, Facebook agreed in early May to a $52 million settlement, paid out with $1,000 individual minimums to current and former contractors employed by outsourcing firms like Accenture. Following news of the settlement, Facebook spokesperson Drew Pusateri issued a statement reading, “We are grateful to the people who do this important work to make Facebook a safe environment for everyone. We’re committed to providing them additional support through this settlement and in the future.”

Less than a month after this breakthrough, however, Accenture management informed moderation teams that it had renegotiated its contract with Facebook, affecting at least hundreds of North American content workers who would now have to increase their exposure to exactly the sort of extreme content at the heart of the settlement, according to internal company communications reviewed by The Intercept and interviews with multiple affected workers.

The new hours were announced at the tail end of May and beginning of June via emails sent by Accenture management to the firm’s content moderation teams, including those responsible for reviewing Child Exploitation Imagery, or CEI, generally graphic depictions of sexually abused children, and Inappropriate Interactions with Children, or IIC, typically conversations in which adults message minors in an attempt to “groom” them for later sexual abuse or exchange sexually explicit images. The Intercept reviewed multiple versions of this email, apparently based off a template created by Accenture. It refers to the new contract between the two companies as the “Golden SoW,” short for “Statement of Work,” and its wording strongly suggests that stipulations in the renewed contract led to 48-minute increases in the so-called “Safety flows” that handle Facebook posts containing depictions of child abuse.",,,,,
"Protesters, Here’s How to Set Up a Cheap Burner Phone","WITH THE INK still drying on their landmark $52 million settlement with Facebook over trauma they suffered working for the company, many outsourced content moderators are now being told that they must view some of the most horrific and disturbing content on the internet for an extra 48 minutes per day, The Intercept has learned.

Following an unprecedented 2018 lawsuit by ex-Facebook content moderator Selena Scola, who said her daily exposure to depictions of rape, murder, and other gruesome acts caused her to develop post-traumatic stress disorder, Facebook agreed in early May to a $52 million settlement, paid out with $1,000 individual minimums to current and former contractors employed by outsourcing firms like Accenture. Following news of the settlement, Facebook spokesperson Drew Pusateri issued a statement reading, “We are grateful to the people who do this important work to make Facebook a safe environment for everyone. We’re committed to providing them additional support through this settlement and in the future.”

Less than a month after this breakthrough, however, Accenture management informed moderation teams that it had renegotiated its contract with Facebook, affecting at least hundreds of North American content workers who would now have to increase their exposure to exactly the sort of extreme content at the heart of the settlement, according to internal company communications reviewed by The Intercept and interviews with multiple affected workers.

The new hours were announced at the tail end of May and beginning of June via emails sent by Accenture management to the firm’s content moderation teams, including those responsible for reviewing Child Exploitation Imagery, or CEI, generally graphic depictions of sexually abused children, and Inappropriate Interactions with Children, or IIC, typically conversations in which adults message minors in an attempt to “groom” them for later sexual abuse or exchange sexually explicit images. The Intercept reviewed multiple versions of this email, apparently based off a template created by Accenture. It refers to the new contract between the two companies as the “Golden SoW,” short for “Statement of Work,” and its wording strongly suggests that stipulations in the renewed contract led to 48-minute increases in the so-called “Safety flows” that handle Facebook posts containing depictions of child abuse.",,,,,
Facebook Pitched New Tool Allowing Employers to Suppress Words Like “Unionize” in Workplace Chat Product,"DURING AN internal presentation at Facebook on Wednesday, the company debuted features for Facebook Workplace, an intranet-style chat and office collaboration product similar to Slack.

On Facebook Workplace, employees see a stream of content similar to a news feed, with automatically generated trending topics based on what people are posting about. One of the new tools debuted by Facebook allows administrators to remove and block certain trending topics among employees.

The presentation discussed the “benefits” of “content control.” And it offered one example of a topic employers might find it useful to blacklist: the word “unionize.”",,,,,
Voices,,,,,,
The Coronavirus Crisis,"SURVEILLANCE FIRMS around the world are licking their lips at a once-in-a-lifetime opportunity to cash in on the coronavirus by repositioning one of their most invasive products: the tracking bracelet.

Body monitors are associated with criminality and guilt in the popular imagination, the accessories of Wall Street crooks under house arrest and menace-to-society parolees. Unlike smartphones, de facto tracking devices in their own right, strapped-on trackers are expressly designed to be attached to the body and exist solely to report the user’s whereabouts and interactions to one or more third parties; they don’t play podcasts or tell you how many steps you took that day to sweeten the surveillance.

But a climate of perpetual bio-anxiety has paved the way for broader acceptance of carceral technologies, with a wave of companies trying to sell tracking accessories to business owners eager to reopen under the aegis of responsible social distancing and to governments hoping to keep a closer eye on people under quarantine.",,,,,
The Coronavirus Crisis,,,,,,
The Coronavirus Crisis,"EARLIER THIS MONTH, Facebook debuted its group video chat offering, Messenger Rooms, to a world under widespread pandemic lockdown, one that’s in large part replaced face-to-face meetings with streamed conversations. The chief beneficiary of this shift, Zoom, has spent months as a punching bag for privacy advocates, so Facebook was quick to assure users that it had “built Rooms with privacy in mind” and that “we don’t watch or listen to your audio or video calls.”

But today, well over a week after the rollout and nearly a month after Facebook announced and offered the privacy assurances about Messenger Rooms, it’s impossible to determine exactly what information will be collected about you and your life if you decide to use the product. The company’s public documentation of Messenger Rooms, including a post focused on privacy, offers very few details, although the privacy post promises, narrowly, that “audio and video from Rooms won’t be used to inform ads.” Facebook’s communications department spent weeks researching my questions about Messenger Rooms privacy, only to come back with few answers, and offering instead only links to a spate of vague policies that predate the product.",,,,,
The Coronavirus Crisis,"EARLIER THIS MONTH, Facebook debuted its group video chat offering, Messenger Rooms, to a world under widespread pandemic lockdown, one that’s in large part replaced face-to-face meetings with streamed conversations. The chief beneficiary of this shift, Zoom, has spent months as a punching bag for privacy advocates, so Facebook was quick to assure users that it had “built Rooms with privacy in mind” and that “we don’t watch or listen to your audio or video calls.”

But today, well over a week after the rollout and nearly a month after Facebook announced and offered the privacy assurances about Messenger Rooms, it’s impossible to determine exactly what information will be collected about you and your life if you decide to use the product. The company’s public documentation of Messenger Rooms, including a post focused on privacy, offers very few details, although the privacy post promises, narrowly, that “audio and video from Rooms won’t be used to inform ads.” Facebook’s communications department spent weeks researching my questions about Messenger Rooms privacy, only to come back with few answers, and offering instead only links to a spate of vague policies that predate the product.",,,,,
The Coronavirus Crisis,"BLUETOOTH HAS SPENT much of its life ignobly associated with crummy headphones, byzantine connection procedures, and car stereo systems that never quite seem to work right. Now this wireless technology concocted in the ’90s to help PCs and mobile phones communicate is being asked to step up and save the planet from a global pandemic. According to its two co-inventors, there could be some issues.

Named for the 10th century king Harald “Bluetooth” Gormsson, famous in Scandinavia for uniting (and Christianizing) the Danes, the humble, oft-derided wireless technology included in some form in nearly every portable device from the past decade and beyond is central to coronavirus contact tracing apps pushed by Apple, Google, and governments across the world. Banking on the standard’s ubiquity, and considerably improved reliability since the ’90s, these entities hope to turn billions of Bluetooth-enabled devices into an army of public health automatons that can map anyone who came into contact with someone who tests positive for Covid-19.",,,,,
The Coronavirus Crisis,"A WINDOW MAY soon open for banks and lenders to use robocalls during the coronavirus crisis. Backed by a push to provide consumers with economic relief, a more expansive exemption could lead to unsolicited debt collection and marketing.

A law passed in 1991 created a working definition of unsolicited robocalls. Last year, in response to outrage over hundreds of millions of unwanted robocalls, Congress passed a new law giving the Federal Communications Commission enhanced power to crack down on the practice with stepped-up penalties for spam callers. Generally, consumers can only receive lawful automated calls if they have opted in or provided their phone number for a financial service.

Now, the coronavirus crisis has sparked an unusual alliance of consumer advocates and the banking industry to come together to seek exemptions to the 1991 definition — and therefore the penalties that accompany enforcement. Together, the unlikely allies called for reinstating the limited use of automatic telephone dialing systems for prerecorded or artificial voice calls made without the consent of consumers.

Normally political foes, the National Consumer Law Center and the American Bankers Association came together to ask the FCC for an expedited, limited exemption to anti-robocalling regulations to allow for automated calls designed explicitly for financial relief. The exemption would allow alerts to inform consumers of loan modifications or payment forbearance options during the Covid-19 epidemic.",,,,,
The Coronavirus Crisis,"JAIL AND PRISON officials in at least three states are using software to scan inmate calls for mentions of the coronavirus, a move advocacy groups believe paves the way for abuse while raising stark questions about carceral health care.

The monitoring software was created by LEO Technologies, a Los Angeles company backed primarily by scandal-plagued Republican fundraiser Elliott Broidy. Known as Verus, it was first deployed several years ago to forestall suicide attempts, mine calls for investigative tips, and for a range of other purposes. In recent weeks, it has been marketed as a system “that can mitigate the effects of the COVID-19 pandemic across our nation’s jail and prison facilities” by alerting prison authorities to sickness-related conversations between inmates and the outside world.",,,,,
The Coronavirus Crisis,"A SMARTPHONE TRACKING firm helping Donald Trump clinch his 2020 presidential reelection recently told investors it’s identified a promising new profit opportunity: the global coronavirus pandemic.

Phunware is part of a vast galaxy of obscure advertising technology companies that help clients follow and target their customers — to “capitalize on users’ daily digital trail,” as Phunware’s site puts it. By embedding Phunware code in their app, a developer can easily glean detailed records of where a user goes and what they do, creating a rich behavioral history to sell on to others.",,,,,
The Coronavirus Crisis,"FACEBOOK INFORMATION TECHNOLOGY contractors have been told their physical presence is required to set up laptops for new hires and other remote employees, and have been given letters to carry on their commutes stating that they are helping to provide “essential services” amid the Covid-19 pandemic.

The contractors, who are employed through global staffing firm Astreya, serve Facebook offices across the country, including in the cities of New York; Austin, Texas; and, Menlo Park, California, all of which require nonessential workers to remain at home. Facebook is eager to get hundreds of laptops and phones set up and shipped to its newly remote workforce across the country, two contractors told The Intercept, a task delegated to them at the same time the social network has emphasized a companywide work-from-home initiative.",,,,,
"Zoom’s Encryption Is “Not Suited for Secrets” and Has Surprising Links to China, Researchers Discover",LEIA EM PORTUGUÊS ,,,,,
The Coronavirus Crisis,LEIA EM PORTUGUÊS ,,,,,
"Zoom Meetings Aren’t End-to-End Encrypted, Despite Misleading Marketing",LEIA EM PORTUGUÊS ,,,,,
The Coronavirus Crisis,LEIA EM PORTUGUÊS ,,,,,
TikTok Told Moderators to Suppress Posts by “Ugly” People and the Poor to Attract New Users,,,,,,
The Coronavirus Crisis,LEIA EM PORTUGUÊS ,,,,,
The Coronavirus Crisis,"LIKE OTHER tech firms scrambling in the face of the Covid-19 pandemic, Facebook is encouraging staff worldwide to work from home, part of a so-called social distancing strategy to slow the new coronavirus’s spread. But some in the social network’s army of contract workers, already often treated like second-class employees, have complained that they have no such luxury and are being asked to choose between their jobs and their health.

Discussions from Facebook’s internal employee forum reviewed by The Intercept reveal a state of confusion, fear, and resentment, with many precariously employed hourly contract workers stating that, contrary to statements to them from Facebook, they are barred by their actual employers from working from home, despite the technical feasibility and clear public health benefits of doing so.",,,,,
ICE’s New York Office Uses a Rigged Algorithm to Keep Virtually All Arrestees in Detention. The ACLU Says It’s Unconstitutional.,"IN 2013, U.S. Immigration and Customs Enforcement quietly began using a software tool to recommend whether people arrested over immigration violations should be let go after 48 hours or detained. The software’s algorithm supposedly pored over a variety of risk factors before outputting a decision.

A new lawsuit, however, filed by the New York Civil Liberties Union and Bronx Defenders, alleges that the algorithm doesn’t really make a decision, at least not one that can result in a detainee being released. Instead, the groups said, it’s an unconstitutional cudgel that’s been rigged to detain virtually everyone ICE’s New York Field Office brings in, even when the government itself believes they present a minimal threat to public safety.",,,,,
Citizen App Again Lets Users Report Crimes — and Experts See Big Risks,"IN 2013, U.S. Immigration and Customs Enforcement quietly began using a software tool to recommend whether people arrested over immigration violations should be let go after 48 hours or detained. The software’s algorithm supposedly pored over a variety of risk factors before outputting a decision.

A new lawsuit, however, filed by the New York Civil Liberties Union and Bronx Defenders, alleges that the algorithm doesn’t really make a decision, at least not one that can result in a detainee being released. Instead, the groups said, it’s an unconstitutional cudgel that’s been rigged to detain virtually everyone ICE’s New York Field Office brings in, even when the government itself believes they present a minimal threat to public safety.",,,,,
Leaked Reports Show EU Police Are Planning a Pan-European Network of Facial Recognition Databases,"A POLICE INVESTIGATOR in Spain is trying to solve a crime, but she only has an image of a suspect’s face, caught by a nearby security camera. European police have long had access to fingerprint and DNA databases throughout the 27 countries of the European Union and, in certain cases, the United States. But soon, that investigator may be able to also search a network of police face databases spanning the whole of Europe and the U.S.

According to leaked internal European Union documents, the EU could soon be creating a network of national police facial recognition databases. A report drawn up by the national police forces of 10 EU member states, led by Austria, calls for the introduction of EU legislation to introduce and interconnect such databases in every member state. The report, which The Intercept obtained from a European official who is concerned about the network’s development, was circulated among EU and national officials in November 2019. If previous data-sharing arrangements are a guide, the new facial recognition network will likely be connected to similar databases in the U.S., creating what privacy researchers are calling a massive transatlantic consolidation of biometric data.",,,,,
TikTok Livestreamed a User’s Suicide — Then Got Its PR Strategy in Place Before Calling the Police,LEIA EM PORTUGUÊS ,,,,,
Election Insecurity,LEIA EM PORTUGUÊS ,,,,,
Voices,,,,,,
"The Rise of Smart Camera Networks, and Why We Should Ban Them","THERE’S WIDESPREAD CONCERN that video cameras will use facial recognition software to track our every public move. Far less remarked upon — but every bit as alarming — is the exponential expansion of “smart” video surveillance networks.

Private businesses and homes are starting to plug their cameras into police networks, and rapid advances in artificial intelligence are investing closed-circuit television, or CCTV, networks with the power for total public surveillance. In the not-so-distant future, police forces, stores, and city administrators hope to film your every move — and interpret it using video analytics.

The rise of all-seeing smart camera networks is an alarming development that threatens civil rights and liberties throughout the world. Law enforcement agencies have a long history of using surveillance against marginalized communities, and studies show surveillance chills freedom of expression — ill effects that could spread as camera networks grow larger and more sophisticated.

To understand the situation we’re facing, we have to understand the rise of the video surveillance industrial complex — its history, its power players, and its future trajectory. It begins with the proliferation of cameras for police and security, and ends with a powerful new industry imperative: complete visual surveillance of public space.

Video Management Systems and Plug-in Surveillance Networks

In their first decades of existence, CCTV cameras were low-resolution analog devices that recorded onto tapes. Businesses or city authorities deployed them to film a small area of interest. Few cameras were placed in public, and the power to track people was limited: If police wanted to pursue a person of interest, they had to spend hours collecting footage by foot from nearby locations.

In the late 1990s, video surveillance became more advanced. A company called Axis Communications invented the first internet-enabled surveillance camera, which converted moving images to digital data. New businesses like Milestone Systems built Video Management Systems, or VMS, to organize video information into databases. VMS providers created new features like motion sensor technology that alerted guards when a person was caught on camera in a restricted area.

As time marched on, video surveillance spread. On one account, about 50 years ago, the United Kingdom had somewhere north of 60 permanent CCTV cameras installed nationwide. Today, the U.K. has over 6 million such devices, while the U.S. has tens of millions. According to marketing firm IHS Markit, 1 billion cameras will be watching the world by the end of 2021, with the United States rivaling China’s per person camera penetration rate. Police can now track people across multiple cameras from a command-and-control center, desktop, or smartphone.

While it is possible to link thousands of cameras in a VMS, it is also expensive. To increase the amount of CCTVs available, cities recently came up with a clever hack: encouraging businesses and residents to place privately owned cameras on their police network — what I call “plug-in surveillance networks.”",,,,,
"Ring Ukraine News Suppressed at Amazon’s Request, Journalists Say","ON NOVEMBER 21, the Ukrainian business publication Vector published a genuine regional success story: An Amazon research lab in Kyiv, affiliated with the company’s Ring home security division, was receiving a “rebrand” makeover and a broader new role within the company. The office was already involved “in many other Amazon projects,” a lab manager told Vector. “We are no longer part of a small startup,” he said in Ukranian, “but a full-fledged R&D center working for one of the world’s largest corporations.”

Ring Ukraine has repeatedly drawn scrutiny and criticism over the past year. In November, five U.S. senators, in a letter to Amazon CEO Jeff Bezos, released the day before the Vector story, had raised concerns about the Kyiv office’s access to Ring home security footage and other private information and asked whether a foreign government could access the material as well. The letter cited an Intercept report that many employees in the office were provided blanket, inappropriate access to a web server containing customer video files. In response, Ring revealed that it had fired four employees over “access to Ring video data” that “exceeded what was necessary for their job functions.” The company did not say what, if anything, it was doing prevent such incidents in the future.",,,,,
Facebook Warrant Targeting Student Journalists in Puerto Rico Prompts Fears of Political Surveillance,"AS SEVEN University of Puerto Rico students prepare to face trial in February for participating in a nonviolent protest more than two years ago, documents released to their defense attorneys reveal that Facebook granted the island’s Justice Department access to a trove of private information from student news publications. The department’s sweeping search warrant was part of a hunt for crimes committed by members of the youth anti-austerity movement, and it has raised fears among civil liberties advocates of a return to a period of Puerto Rico’s history when police routinely targeted citizens for surveillance on the basis of their political interests.

It was April 2017, and for weeks, University of Puerto Rico students had been holding a school-wide strike protesting austerity policies that were poised to defund public services across the island to satisfy the government’s creditors. When the university’s governing board gathered on April 27 to discuss $241 million in budget cuts, the students demanded to be let in. The board refused, locking the doors to the building where the meeting was being held. But the students stormed in anyway, pushing past security.

The action unfolded in real time on Facebook, as three student media outlets, Diálogo UPR, Pulso Estudiantil UPR, and Centro de Comunicación Estudiantil, livestreamed the protest. The students surrounded the board members and shut down the meeting, demanding that the board sign a commitment to rejecting the budget cuts. The action, one of many that took place on campus and in the streets, was over within half an hour. A glass door, some furniture, and a lamp were allegedly broken or damaged. No one was injured, and no one was arrested. But the secretary of Puerto Rico’s Justice Department, now-Gov. Wanda Vázquez, pledged to investigate the incident and arrest lawbreakers.

Two weeks later, students who had assumed leadership roles in the wider strike received citations ordering them to appear in court. When they showed up, they were handcuffed, paraded before media crews, and charged with a host of crimes related to the boardroom protest, the most severe of which — rioting and burglary — were later dropped. The remaining charges, including violating the right to assemble, aggravated restriction of freedom, and violence or intimidation against a public authority, each carry between six months and three years in prison. The seven students go to trial on February 7.

How exactly Vázquez’s Justice Department determined which students to charge out of the dozens who participated in the protest has remained a mystery to defense attorneys. The lawyers’ suspicion: that the case isn’t about crimes committed in the boardroom that day, but rather an attempt to penalize the political activity of some of the most active student organizers. The seven facing trial were members of the student strikers’ negotiating committee as well as political organizations critical of the government.",,,,,
Year in Review 2019,,,,,,
How Big Tech Manipulates Academia to Avoid Regulation,,,,,,
The Trump Campaign Is Deploying Phone Location-Tracking Technology,,,,,,
Dear Mark Zuckerberg: Facebook Is an Engine of Anti-Muslim Hate the World Over. Don’t You Care?,,,,,,
The Coronavirus Crisis,"JUST DAYS AFTER Facebook and one of its contractors, Accenture, sent teams responsible for content moderation back to their offices amid concerns about the coronavirus pandemic, one worker at the office tested positive for Covid-19, according to an internal email viewed by The Intercept.

According to a notification email sent to contractors working out of Accenture’s Facebook facility in Austin, Texas — where hourly contractors deal with the social media giant’s most graphic forms of violence and sexual abuse — the office has already been hit with a positive case. “We have learned that one of our people working at Facebook Domain 8 on the 12th floor has tested positive for COVID-19,” the email reads. “This individual was last in the office on 10/13, became symptomatic on 10/14 and received a positive test result on 10/16. Currently, this person is in self-quarantine.”",,,,,
Protests for Black Lives,"FEDERAL AGENTS from the Department of Homeland Security and the Justice Department used “a sophisticated cell phone cloning attack—the details of which remain classified—to intercept protesters’ phone communications” in Portland this summer, Ken Klippenstein reported this week in The Nation. Put aside for the moment that, if the report is true, federal agents conducted sophisticated electronic surveillance against American protesters, an alarming breach of constitutional rights. Do ordinary people have any hope of defending their privacy and freedom of assembly against threats like this?

Yes, they do. Here are two simple things you can do to help mitigate this type of threat:

As much as possible, and especially in the context of activism, use an encrypted messaging app like Signal — and get everyone you work with to use it too — to protect your SMS text messages, texting groups, and voice and video calls.
Prevent other people from using your SIM card by setting a SIM PIN on your phone. There are instructions on how to do this below.
How SIM Cloning Works

Without more details, it’s hard to be entirely sure what type of surveillance was used, but The Nation’s mention of “cell phone cloning” makes me think it was a SIM cloning attack. This involves duplicating a small chip used by virtually every cellphone to link itself to its owner’s phone number and account; this small chip is the subscriber identity module, more commonly known as SIM.

Here’s how SIM cloning would work:

First, the feds would need physical access to their target’s phone; for example, they could arrest their target at a protest, temporarily confiscating their phone.
Then they would pop out the SIM card from the phone, a process designed to be easy, since end users often have reasons to replace the card (such as traveling abroad and needing a local SIM card to access the local cellular network, or when switching cellular providers).
The feds would then copy their target’s SIM card data onto a blank SIM card (this presents some challenges, as I explain below), and then put the original SIM card back without their target knowing.

SIM cards contain a secret encryption key that is used to encrypt data between the phone and cellphone towers. They’re designed so that this key can be used (like when you receive a text or call someone) but so the key itself can’t be extracted.

But it’s still possible to extract the key from the SIM card, by cracking it. Older SIM cards used a weaker encryption algorithm and could be cracked quickly and easily, but newer SIM cards use stronger encryption and might take days or significantly longer to crack. It’s possible that this is why the details of the type of surveillance used in Portland “remain classified.” Do federal agencies know of a way to quickly extract encryption keys from SIM cards? (On the other hand, it’s also possible that “cell phone cloning” doesn’t describe SIM cloning at all but something else instead, like extracting files from the phone itself instead of data from the SIM card.)",,,,,
Protests for Black Lives,"Since May, as protesters around the country have marched against police brutality and in support of the Black Lives Matter movement, activists have spotted a recurring presence in the skies: mysterious planes and helicopters hovering overhead, apparently conducting surveillance on protesters. A press release from the Justice Department at the end of May revealed that the Drug Enforcement Agency and U.S. Marshals Service were asked by the Justice Department to provide unspecified support to law enforcement during protests. A few days later, a memo obtained by BuzzFeed News offered a little more insight on the matter; it revealed that shortly after protests began in various cities, the DEA had sought special authority from the Justice Department to covertly spy on Black Lives Matter protesters on behalf of law enforcement. 
Although the press release and memo didn’t say what form the support and surveillance would take, it’s likely that the two agencies were being asked to assist police for a particular reason. Both the DEA and the Marshals possess airplanes outfitted with so-called stingrays or dirtboxes: powerful technologies capable of tracking mobile phones or, depending on how they’re configured, collecting data and communications from mobile phones in bulk.
",,,,,
BlueLeaks,"WHILE DOCTORS AND politicians still struggle to convince Americans to take the barest of precautions against Covid-19 by wearing a mask, the Department of Homeland Security has an opposite concern, according to an “intelligence note” found among the BlueLeaks trove of law enforcement documents: Masks are breaking police facial recognition.

The rapid global spread and persistent threat of the coronavirus has presented an obvious roadblock to facial recognition’s similar global expansion. Suddenly everyone is covering their faces. Even in ideal conditions, facial recognition technologies often struggle with accuracy and have a particularly dismal track record when it comes to identifying faces that aren’t white or male. Some municipalities, startled by the civil liberties implications of inaccurate and opaque software in the hands of unaccountable and overly aggressive police, have begun banning facial recognition software outright. But the global pandemic may have inadvertently provided a privacy fix of its own — or for police, a brand new crisis.",,,,,
Controversial Data-Mining Firm Palantir Vanishes From Biden Adviser’s Biography After She Joins Campaign,"LEVERAGING CLOSE TIES to Twitter, controversial artificial intelligence startup Dataminr helped law enforcement digitally monitor the protests that swept the country following the killing of George Floyd, tipping off police to social media posts with the latest whereabouts and actions of demonstrators, according to documents reviewed by The Intercept and a source with direct knowledge of the matter.

The monitoring seems at odds with claims from both Twitter and Dataminr that neither company would engage in or facilitate domestic surveillance following a string of 2016 controversies. Twitter, up until recently a longtime investor in Dataminr alongside the CIA, provides the company with full access to a content stream known as the “firehose” — a rare privilege among tech firms and one that lets Dataminr, recently valued at over $1.8 billion, scan every public tweet as soon as its author hits send. Both companies denied that the protest monitoring meets the definition of surveillance.

A History of Police Work

Dataminr helps newsrooms, corporations, and governments around the world track crises with superhuman speed as they unfold across social media and the wider web. Through a combination of people and software, the company alerts organizations to chatter around global crises — wars, shootings, riots, disasters, and so forth — so that they’ll have a competitive edge as news is breaking. But the meaning of that competitive edge, the supercharged ability to filter out important events from the noise of hundreds of millions of tweets and posts across social media, will vary drastically based on the customer; the agenda of a newspaper using Dataminr to inform its breaking news coverage won’t be the same as the agendas of a bank or the FBI. It’s this latter category of Dataminr’s business, lucrative government work, that’s had the firm on the defensive in recent years.

In 2016, Twitter was forced to reckon with multiple reports that its platform was being used to enable domestic surveillance, including a Wall Street Journal report on Dataminr’s collaboration with American spy agencies in May; an American Civil Liberties Union report on Geofeedia, a Dataminr competitor, in October; and another ACLU investigation into Dataminr’s federal police surveillance work in December. The company sought to assure the public that attempts to monitor its users for purposes of surveillance were strictly forbidden under its rules, and that any violators would be kicked off the platform. For example, then-VP Chris Moody wrote in a company blog post that “using Twitter’s Public APIs or data products to track or profile protesters and activists is absolutely unacceptable and prohibited.” In a letter to the ACLU, Twitter public policy chief Colin Crowell similarly wrote that “the use of Twitter data for surveillance is strictly prohibited” and that “Datatminr’s product does not provide any government customers with … any form of surveillance.”

Twitter also said that Dataminr, one of its “official partners,” would “no longer support direct access by fusion centers” to information such as tweet locations; fusion centers are controversial facilities dedicated to sharing intelligence between the federal government and local police. Dataminr at the same time announced it would no longer provide a product for conducting geospatial analysis “to those supporting first reponse” and added that such clients did not have “direct firehose access.”

But based on interviews, public records requests, and company documents reviewed by The Intercept, Dataminr continues to enable what is essentially surveillance by U.S. law enforcement entities, contradicting its earlier assurances to the contrary, even if it remains within some of the narrow technical boundaries it outlined four years ago, like not providing direct firehose access, tweet geolocations, or certain access to fusion centers.

Dataminr relayed tweets and other social media content about the George Floyd and Black Lives Matter protests directly to police, apparently across the country. In so doing, it used to great effect its privileged access to Twitter data — despite current terms of service that explicitly bar software developers “from tracking, alerting, or monitoring sensitive events (such as protests, rallies, or community organizing meetings)” via Twitter.",,,,,
"Protesters, Here’s How to Set Up a Cheap Burner Phone",,,,,,
The Coronavirus Crisis,,,,,,
Citizen App Again Lets Users Report Crimes — and Experts See Big Risks,"CITIZEN, A MOBILE APP that alerts people to nearby emergencies, is testing the reintroduction of a controversial feature that lets users report crimes and incidents on their own by live streaming video.

Created by New York-based startup sp0n, Citizen first launched under the name “Vigilante” in 2016 in New York City, broadcasting alerts of 911 calls to users in the vicinity and allowing those users to send live video from incident scenes, comment on alerts, and report incidents on their own. In a splashy launch video with the hashtag #CrimeNoMore, several young men were depicted rushing to aid a woman who was chased by a menacing stranger; the video instructs users not to “interfere with the crime,” but then adds, “Good luck out there!” Vigilante was met with swift backlash from the public and police departments, and Apple soon pulled the app from its store. At that time, the New York Police Department issued a statement saying, “Crimes in progress should be handled by the NYPD and not a vigilante with a cell phone.”

Several months later, the app rebranded as Citizen, removed the incident reporting feature, and said it was shifting its focus to “safety” and “avoiding crime” — a far cry from its prior positioning.

Citizen’s return to public crime reporting has not been publicized, but is documented on the company’s user support website. The app’s latest version in Apple and Google’s app stores also includes the description: “Keep Your Community Safe: Report incidents right when they happen to protect the people around you.”",,,,,
The Trump Campaign Is Deploying Phone Location-Tracking Technology,"PRESIDENT DONALD TRUMP’S reelection effort has retained the services of a technology company that specializes in the mass collection of smartphone location data, which can be used to track voters for political targeting purposes.

Phunware, an Austin, Texas-based firm, announced the connection in a little-noticed press release in October, touting “new and existing customer wins including American Made Media Consultants,” the consulting firm set up this year by Trump campaign manager Brad Parscale to handle advertising services for a variety of official Trump reelection PACs. The release noted that the deal was signed in conjunction with the Trump-Pence 2020 reelection effort.

A growing subset of advertising firms rely on data brokers that use third-party apps — from popular mobile games to apps used for checking the weather, perfecting a selfie, and online banking — to harvest vast troves of information about potential voters. Phunware, in a section of its website, discusses the company’s ability to obtain GPS location data and the Wi-Fi network used by an individual, as well as user data that can infer an “individual’s gender, age, lifestyle preferences” — potential tools for identifying and influencing voters.

The company claims to offer a wide range of services based on user location data. Individuals who attend a political rally or protest can be identified as potential targets for ads, a technique known as geofencing. Location data can provide insights into how long a shopper spends at a particular clothing store, type of religious venues, or the night clubs they tend to frequent.

“Unfortunately Phunware does not comment on customer-specific data or information,” wrote Brent Brightwell, a spokesperson for Phunware, when contacted about the company’s work with Trump campaign. “Please contact the Trump reelection campaign directly should you have any questions about their activities or efforts.” The Trump campaign did not respond to a request for comment.",,,,,
Filmmakers Sue to Shield Visitors to U.S. From Social Media Vetting,"A FILMMAKER WORKING on a documentary that’s critical of U.S. policies. A writer who operates a pseudonymous Twitter account to evade an authoritarian regime in their home country. An activist who uses Facebook to organize protests at the U.S.-Mexico border.

These are the kinds of people who might not want U.S. immigration agents poring over their social media profiles before deciding whether they should be allowed into the country. Yet that’s exactly what the State Department now requires as part of the Trump administration’s “extreme vetting” of millions of visa applicants. As of May, people who need a visa to enter the U.S. have to disclose any social media handles they’ve used over the past five years on 20 platforms, from Instagram and Twitter to YouTube and Weibo (the Chinese microblogging service). If they don’t, their visas could be denied.",,,,,
How Amazon’s On-Site Emergency Care Endangers the Warehouse Workers It’s Supposed to Protect,In partnership with,,,,,
Amazon’s Ring Planned Neighborhood “Watch Lists” Built on Facial Recognition,"RING, AMAZON’S CRIMEFIGHTING surveillance camera division, has crafted plans to use facial recognition software and its ever-expanding network of home security cameras to create AI-enabled neighborhood “watch lists,” according to internal documents reviewed by The Intercept.

The planning materials envision a seamless system whereby a Ring owner would be automatically alerted when an individual deemed “suspicious” was captured in their camera’s frame, something described as a “suspicious activity prompt.”

It’s unclear who would have access to these neighborhood watch lists, if implemented, or how exactly they would be compiled, but the documents refer repeatedly to law enforcement, and Ring has forged partnerships with police departments throughout the U.S., raising the possibility that the lists could be used to aid local authorities. The documents indicate that the lists would be available in Ring’s Neighbors app, through which Ring camera owners discuss potential porch and garage security threats with others nearby.

Ring spokesperson Yassi Shahmiri told The Intercept that “the features described are not in development or in use and Ring does not use facial recognition technology,” but would not answer further questions.",,,,,
Shutterstock Employees Fight Company’s New Chinese Search Blacklist,"SHUTTERSTOCK, THE WELL-KNOWN online purveyor of stock images and photographs, is the latest U.S. company to willingly support China’s censorship regime, blocking searches that might offend the country’s authoritarian government, The Intercept has learned.

The publicly traded company built a $639 million-per-year business on the strength of its vast — sometimes comically vast — catalog of images depicting virtually anything a blogger or advertiser could imagine. The company now does business in more than 150 countries. But in China, there is now a very small, very significant gap in Shutterstock’s offerings. In early September, Shutterstock engineers were given a new goal: The creation of a search blacklist that would wipe from query results images associated with keywords forbidden by the Chinese government. Under the new system, which The Intercept is told went into effect last month, anyone with a mainland Chinese IP address searching Shutterstock for “President Xi,” “Chairman Mao,” “Taiwan flag,” “dictator,” “yellow umbrella,” or “Chinese flag” will receive no results at all. Variations of these terms, including “umbrella movement” — the precursor to the mass pro-democracy protests currently gripping Hong Kong — are also banned.

Shutterstock’s decision to silently aid China’s censorship agenda comes at a time of heightened scrutiny into the relationship between corporate America and President Xi Jinping’s authoritarian regime. Household names like Apple, Blizzard Entertainment, the NBA, and Google have all garnered harsh criticism for letting the policy directives of the Communist Party of China, and the gilded promise of a billion customers, dictate company strategy. Deciding to censor is a particularly stark inversion of values for Shutterstock, which markets itself as an enabler of creative expression.

The photo company’s relationship with China dates back to at least 2014, when it struck a distribution deal with ZCool, a Chinese social network and portfolio site for visual artists. Last year Shutterstock announced a $15 million investment in ZCool, noting that owing to the partnership, “Shutterstock’s content now powers large technology platforms in China such as Tencent Social Ads,” an online advertising subsidiary of the tremendously popular Chinese internet conglomerate Tencent.

Shutterstock’s censorship feature appears to have been immediately controversial within the company, prompting more than 180 Shutterstock workers to sign a petition against the search blacklist and accuse the company of trading its values for access to the lucrative Chinese market. Chinese internet users already struggle to discuss even the tamest of taboo subjects; now, it seemed, the situation would get a little worse, with the aid of yet another willing American company.

“Yes, we’re a creative photo and video marketplace, but we are also an editorial news hub,” one Shutterstock employee told The Intercept. “Want to write a story about the protests in Hong Kong? They never existed. Want to write about Taiwan? It never existed. Xi Jinping is NOT a dictator because he specifically said so. This is dark shit.”

The text of the petition, provided to The Intercept, can be read in full below.

Shutterstock’s founder and CEO Jon Oringer replied to the petition several days later; those hoping for a change of heart were to be disappointed. Shutterstock’s pro-censorship compromise with the Chinese government was justified, Oringer argued, because to refuse to do business in China rather than help the country’s government expand its information control scheme would be the real act of craven corporate turpitude: “Do we make the majority of our content available to China’s 1.3 billion citizens or do we take away their ability to access it entirely? We ultimately believe, consistent with our brand promise, it is more valuable for storytellers to have access to our collection to creatively and impactfully tell their stories.” Shutterstock with a bespoke censorship feature was “more empowering” and “will better serve the people of China than the alternative,” Oringer continued.

Oringer’s company-wide response is also reproduced below.

Following Oringer’s letter and the implementation of the search term blacklist, some employees fear the use of censorship at the company will grow: “He offered no consolation in terms of what our actions will be when China requests to add an X number more search terms to the censorship list,” the Shutterstock staffer told The Intercept, “or if another country comes to us with a similar request. We are devastated.”",,,,,
An American Citizen Was Detained While Trying to Pay a Customs Fee on a Gift for His Daughter,LEIA EM PORTUGUÊS ,,,,,
Climate Crimes,"IS THE HUMAN race approaching its demise? The question itself may sound hyperbolic — or like a throwback to the rapture and apocalypse. Yet there is reason to believe that such fears are no longer so overblown. The threat of climate change is forcing millions around the world to realistically confront a future in which their lives, at a minimum, look radically worse than they are today. At the same time, emerging technologies of genetic engineering and artificial intelligence are giving a small, technocratic elite the power to radically alter homo sapiens to the point where the species no longer resembles itself. Whether through ecological collapse or technological change, human beings are fast approaching a dangerous precipice.",,,,,
"Hedge Fund-Owned Newspaper Group Outsources Design Abroad, Chasing Higher Dividends","INVESTIGATIVE JOURNALIST Thomas Peele remembers the day he learned that he and fellow reporters at the East Bay Times and the San Jose Mercury News won the Pulitzer Prize for their “relentless” coverage of the deadly Ghost Ship warehouse fire in Oakland, California.

Peele was stunned and, of course, elated that he and his team would be honored for their dogged work covering a tragedy that shook their region.

It was April 2017. One week later, MediaNews Group, owner of the two papers and scores of others around the country, announced plans to move the Bay Area’s copy desk work to Southern California, triggering 20 layoffs from a shrunken roster of fewer than 100 employees in the East Bay newsroom.

In a flash, almost a quarter of the award-winning editorial staff was gone.

“It was a kick in the teeth,” said Peele, who is an officer for the NewsGuild, the union that represents workers at the papers.

The chain’s owners and executives, he said, “didn’t even send a pizza.” But they did send layoff notices, along with “word that our papers would be edited 400 miles away by people we had no relationship with, and who had little knowledge about our region of the state. And we were basically told some stories wouldn’t be copy edited at all.”

“Pulitzer?” he asked. “What Pulitzer?’

It was all part of a growing trend of shifting tasks such as proofreading, copy editing, and page design to “hubs” that would save money. Meanwhile, the papers were profitable, not to mention Pulitzer-winning — but the hedge fund that owned their parent company wanted to skim more off the top.

Two years later, MediaNews Group, better known by its trade name Digital First Media, has decided that shutting down pressrooms, eliminating jobs, and concentrating design and printing into regional hubs hasn’t cut costs enough.

Now it’s outsourcing California news design to the Philippines, paying pennies on the dollar for work that once employed professionals who lived in the communities they served.

An employee in the production department of the design hub, who asked not to be named because of fears he’d be laid off, said Digital First once assured workers that the hubs were key to helping the papers survive. By his count, just before the Philippines contract went into effect in May, the company cut its Southern California design and copy editing pool by a half-dozen people — all on the heels of 65 layoffs across the company’s Southern California newspapers a year earlier.

“They said it was to save money,” he said. “So once we heard everything was being outsourced, we were confused, because we were supposed to be that.”

Computers Covering City Hall?

At the Denver Post, the company is pushing the envelope even further. In bargaining talks with union leaders this summer, Digital First pushed for the right to use artificial intelligence to cover high school sports. They also hope to allow computers to “gather and publish” municipal government news, including “local news stories from suburban communities, school districts and other governmental districts,” according to a company proposal obtained by The Intercept. Denver Post union official Tony Mulligan said the company has already selected a vendor and budgeted money for the prep sports transition.

Of course, artificial intelligence and data mining don’t automatically lead to job loss, and they can be useful tools in the hands of skilled journalists, said Ken Doctor, a media analyst with Nieman Lab.

“The problem is the tools are being used by those who are primarily looking at cost-cutting,” he said. “Actual journalism requires judgment.”

In the midst of this unending budget slashing, Digital First papers are making plenty of money. They netted profits of $159 million in fiscal year 2017, according to Doctor. In fact, Digital First may be the most profitable daily newspaper chain in the industry, earning an average 17 percent annual profit margin in a field where 7 or 8 percent is considered viable. Some of its papers have earned as much as 30 percent, Doctor reported.

In press releases and statements filed with the Securities and Exchange Commission this year, Digital First confirmed its “increased profitability,” which it said grew from 11.6 percent to 16.2 percent between fiscal years 2015 and 2018.

But apparently even “increased profitability” isn’t enough. That’s because Digital First is controlled by the New York hedge fund Alden Global Capital.

Since 2012, when the privately held firm took control of the chain’s hundreds of dailies and weeklies, Alden has treated them like a personal ATM, admitting in court documents that it siphoned hundreds of millions in cash from local papers across the country to gamble on unrelated businesses — many losing propositions — such the Fred’s Pharmacy chain, which on September 9 declared bankruptcy and announced that it was liquidating all its stores and assets. Other court filings show that it invested in Payless ShoeSource, which this year shuttered its more than 2,000 stores.

Under Alden’s stewardship, those companies have shuttered thousands of stores, eliminating a combined 22,000 jobs, while Alden executives and associates took in six-figure compensation packages.

This is a typical strategy for what are known as vulture funds, which push these companies into bankruptcy, preferring to make their money by selling off assets like real estate, extracting maximum profits by slashing payrolls, paying themselves handsomely by serving on the company’s boards, and charging a 2 percent management fee (which, in Alden’s case, adds up to $20 million a year).

Shuttering Newsrooms

I’ve seen firsthand what Alden can do to a company. I worked for one of its papers, the Monterey Herald, until 2015. (I now freelance as a reporter and editor for various media outlets, including websites published by the NewsGuild, the union that represents workers at 13 Digital First newspapers.)

At the Herald, it was bad enough when the hot water heater broke and never got fixed. Then employees had to put plants under the leaky roof to keep the break room from flooding. Then the presses were shut down, the building sold, and we moved into smaller rented digs.

But at least we had an office.

In 2013, Alden quietly set up a mysterious firm called Twenty Lake Holdings to sell off its newspapers’ real estate, which often includes historic buildings in prime downtown locations. In towns from Longmont, Colorado, to Pottstown, Pennsylvania, Alden has closed Digital First offices entirely, forcing reporters to work from other papers’ buildings, printing plants miles from the towns they cover — or from their homes, cars or coffee shops.

Bill Ross, executive director of the NewsGuild of Greater Philadelphia, said that in his region, three Pennsylvania newspapers have closed their offices — in Pottstown, Norristown, and West Chester. These are the papers that, according to Doctor, are earning that stunning 30 percent profit margin.

Evan Brandt, a veteran reporter at the Pottstown Mercury, now works in his attic, “up here with the Christmas decorations.”

Brandt said the biggest challenge is getting breaking news to his community. “The cops reporter doesn’t live in town, so that’s 20 minutes away.”

Local News Going Overseas

In Monrovia, 20 miles northeast of Los Angeles, a Digital First production hub of 33 full-time and three freelance employees puts together 12 daily papers that include the L.A. Daily News, the Orange County Register, the San Jose Mercury News, and a swath of smaller California papers, along with dozens of weekly papers.

But now, even that consolidation effort is apparently not saving enough. Since May, Alden has been shifting design work to the Philippines. Through an outsourcing company called AffinityX, more than 40 California weekly newspapers once designed in Monrovia are now produced in Manila.

In an August 23 email to staff, Digital First’s Southern California News Group managing editor Helayne Perry wrote that “AffinityX has taken over the design of our opinion pages.” There are “rumblings” that page two and local news sections will likely be next, the Monrovia design hub employee said.

Requests for comment to Digital First management went unanswered. An AffinityX spokesperson said company executives declined to comment.",,,,,
A Declassified Court Ruling Shows How the FBI Abused NSA Mass Surveillance Data,"THE FOREIGN INTELLIGENCE Surveillance Court found that the FBI may have violated the rights of potentially millions of Americans — including its own agents and informants — by improperly searching through information obtained by the National Security Agency’s mass surveillance program.

U.S. District Court Judge James E. Boasberg, who serves in the District of Columbia and the FISA court, made his sweeping and condemnatory assessment in October 2018 in a 138-page ruling, which was declassified by the U.S. government this week.",,,,,
Mark Zuckerberg Buckles and Will Testify to Congress on Facebook’s Cryptocurrency,"FACEBOOK CEO MARK ZUCKERBERG will be the sole witness to testify before the House Financial Services Committee on October 23 during a hearing on the company’s plans to launch its own cryptocurrency.

Members of the committee had been in talks over whether to allow Zuckerberg to skip the hearing and instead hear from Facebook COO Sheryl Sandberg, but several members pushed for the CEO to appear instead.

The hearing, titled “An Examination of Facebook and Its Impact on the Financial Services and Housing Sectors,” comes three months after Chair Maxine Waters and committee Democrats sent a letter to Facebook calling on the company to suspend plans to launch the cryptocurrency, Libra. The company is also working on a program called Calibra, which would function as a digital wallet for the cryptocurrency.",,,,,
NRA Ramped Up Facebook Advertising Immediately After Mass Shootings in El Paso and Dayton,"FACEBOOK CEO MARK ZUCKERBERG will be the sole witness to testify before the House Financial Services Committee on October 23 during a hearing on the company’s plans to launch its own cryptocurrency.

Members of the committee had been in talks over whether to allow Zuckerberg to skip the hearing and instead hear from Facebook COO Sheryl Sandberg, but several members pushed for the CEO to appear instead.

The hearing, titled “An Examination of Facebook and Its Impact on the Financial Services and Housing Sectors,” comes three months after Chair Maxine Waters and committee Democrats sent a letter to Facebook calling on the company to suspend plans to launch the cryptocurrency, Libra. The company is also working on a program called Calibra, which would function as a digital wallet for the cryptocurrency.",,,,,
Twitter Helped Chinese Government Promote Disinformation on Repression of Uighurs,"TWITTER HELPED TO promote Chinese government propaganda and disinformation about the country’s controversial internment camps in the Xinjiang region, a review of the company’s advertising records reveals.

The social media company today announced a policy change that would bar such promotion following an inquiry from The Intercept and an earlier controversy over similar propaganda related to demonstrations in Hong Kong.

In Xinjiang, a western province in China, the United Nations has estimated that 1 million ethnic minority Muslim Uighurs — including children, pregnant women, elderly people, and people with disabilities — have been detained under the pretext of fighting extremism. According to Human Rights Watch, Chinese authorities are “committing human rights abuses in Xinjiang on a scale unseen in the country in decades.”",,,,,
Google Is Deepening Its Involvement With Egypt’s Repressive Government,"GOOGLE IS SET to re-staff its Cairo office, which more or less went dormant in 2014, following the military coup that brought President Abdel Fattah el-Sisi to power in Egypt. The move comes against the backdrop of well-documented abuses by the Sisi government against dissidents and activists, which it facilitates using mass and targeted internet surveillance, and by blocking news, human rights, and blogging websites.

Google said it would begin recruiting full-time staff for the office after a meeting between Egyptian ministers and Google staff led by Google MENA head Lino Cattaruzzi, according to a June press release from the Egyptian government. The company also recently consulted with the Egyptian government on a data protection bill. And it is in talks to partner with the Egyptian government to expand its “Maharat min Google,” or “Skills From Google,” program, which has provided digital training for entrepreneurs through partner organizations over the past year. The expansion would be overseen by a government ministry.

Google’s renewed engagement with Egypt comes just a year after the company sparked outrage when The Intercept revealed that Google planned to develop a censored search engine for use in China, which it code-named Dragonfly. When Google had previously ended its search services in China in 2010, co-founder Sergey Brin referenced the government’s poor tolerance for dissent as a reason for the pullout. Executives say Dragonfly has been shelved, after harsh criticism from Google employees, advocacy groups, and the U.S. Congress.",,,,,
"Trauma Counselors Were Pressured to Divulge Confidential Information About Facebook Moderators, Internal Letter Claims","NEARLY 1,500 MILES from the Menlo Park headquarters of Facebook, at a company outpost in Austin, Texas, moderators toil around the clock to screen and scrub some the most gruesome, hateful, and heinous posts that make their way onto the social network and its photo-sharing subsidiary, Instagram. They are required to view as many as 800 pieces of disturbing content in a single shift, and routinely turn to on-site counselors to help cope with the procession of stomach-turning images, videos, and text. But some members of this invisible army have complained, in a statement widely circulated within Facebook, that the outsourcing giant that officially employs them, Accenture, has repeatedly attempted to violate the confidentiality of these therapy sessions.

The moderators work from within a special section for outsourced staffers at Facebook Austin. The Texas outpost is designed to mimic the look and feel of the company’s famously opulent Silicon Valley digs, but Accenture workers say they’re reminded daily of their secondary status and denied perks, prestige, and basic respect. This second-class tier at Facebook, a sort of international shadow workforce, has been well documented in the media, from Manila to Arizona, and it’s not clear whether the company has done anything to address it beyond issuing defensive PR statements. Moderators in Austin say their job is a brutalizing slog and that Facebook remains largely indifferent to their struggles. Access to on-site counseling is one of the few bright points for this workforce.",,,,,
A New App Allows Readers in China to Bypass Censorship of The Intercept,"Since June, people in China have been unable to read The Intercept, after the country’s government apparently banned our website, along with those of several other media organizations. Today, we are happy to announce a workaround that will allow people in China to circumvent the restrictions, access our full site, and continue to read our award-winning journalism.
",,,,,
The Trump Administration Is Using the Full Power of the U.S. Surveillance State Against Whistleblowers,,,,,,
We Tested Europe’s New Lie Detector for Travelers — and Immediately Triggered a False Positive,"THEY CALL IT the Silent Talker. It is a virtual policeman designed to strengthen Europe’s borders, subjecting travelers to a lie detector test before they are allowed to pass through customs.

Prior to your arrival at the airport, using your own computer, you log on to a website, upload an image of your passport, and are greeted by an avatar of a brown-haired man wearing a navy blue uniform.

“What is your surname?” he asks. “What is your citizenship and the purpose of your trip?” You provide your answers verbally to those and other questions, and the virtual policeman uses your webcam to scan your face and eye movements for signs of lying.

At the end of the interview, the system provides you with a QR code that you have to show to a guard when you arrive at the border. The guard scans the code using a handheld tablet device, takes your fingerprints, and reviews the facial image captured by the avatar to check if it corresponds with your passport. The guard’s tablet displays a score out of 100, telling him whether the machine has judged you to be truthful or not.

A person judged to have tried to deceive the system is categorized as “high risk” or “medium risk,” dependent on the number of questions they are found to have falsely answered. Our reporter — the first journalist to test the system before crossing the Serbian-Hungarian border earlier this year — provided honest responses to all questions but was deemed to be a liar by the machine, with four false answers out of 16 and a score of 48. The Hungarian policeman who assessed our reporter’s lie detector results said the system suggested that she should be subject to further checks, though these were not carried out.

Travelers who are deemed dangerous can be denied entry, though in most cases they would never know if the avatar test had contributed to such a decision. The results of the test are not usually disclosed to the traveler; The Intercept obtained a copy of our reporter’s test only after filing a data access request under European privacy laws.",,,,,
Google Continues Investments in Military and Police AI Technology Through Venture Capital Arm,"LAST YEAR,GOOGLE faced internal revolt from many employees over its handling of Project Maven, a secretive contract between the company and the Department of Defense to use artificial intelligence to improve the military’s drone targeting capabilities. After a series of internal, worker-led protests and resignations following reporting by The Intercept and Gizmodo, the company said it would wind down the drone project and promised a more transparent approach to similar work in the future.

Now, a number of Google workers are voicing concerns that the Mountain View, California-based search giant is continuing to deploy cutting-edge AI technology to the Pentagon and law enforcement customers.",,,,,
Voices,,,,,,
"Before Being Hacked, Border Surveillance Firm Lobbied to Downplay Security and Privacy Concerns About Its Technology",,,,,,
Middle East Dictators Buy Spy Tech From Company Linked to IBM and Google,"IT IS THE size of a small suitcase and can be placed discreetly in the back of a car. When the device is powered up, it begins secretly monitoring hundreds of cellphones in the vicinity, recording people’s private conversations and vacuuming up their text messages.

The device is one of several spy tools manufactured by a Chinese company called Semptian, which has supplied the equipment to authoritarian governments in the Middle East and North Africa, according to two sources with knowledge of the company’s operations.

As The Intercept first reported on Thursday, since 2015, Semptian has been using American technology to help build more powerful surveillance and censorship equipment, which it sells to governments under the guise of a front company called iNext.",,,,,
How U.S. Tech Giants Are Helping to Build China’s Surveillance State,"AN AMERICAN ORGANIZATION founded by tech giants Google and IBM is working with a company that is helping China’s authoritarian government conduct mass surveillance against its citizens, The Intercept can reveal.

The OpenPower Foundation — a nonprofit led by Google and IBM executives with the aim of trying to “drive innovation” — has set up a collaboration between IBM, Chinese company Semptian, and U.S. chip manufacturer Xilinx. Together, they have worked to advance a breed of microprocessors that enable computers to analyze vast amounts of data more efficiently.

Shenzhen-based Semptian is using the devices to enhance the capabilities of internet surveillance and censorship technology it provides to human rights-abusing security agencies in China, according to sources and documents. A company employee said that its technology is being used to covertly monitor the internet activity of 200 million people.

Semptian, Google, and Xilinx did not respond to requests for comment. The OpenPower Foundation said in a statement that it “does not become involved, or seek to be informed, about the individual business strategies, goals or activities of its members,” due to antitrust and competition laws. An IBM spokesperson said that his company “has not worked with Semptian on joint technology development,” but declined to answer further questions. A source familiar with Semptian’s operations said that Semptian had worked with IBM through a collaborative cloud platform called SuperVessel, which is maintained by an IBM research unit in China.",,,,,
"Hacked Border Surveillance Firm Wants To Profile Drivers, Passengers, and Their “Likely Trip Purpose” In New York City","JUST MONTHS BEFORE millions of its internal documents were stolen and dumped on the internet, the Tennessee-based surveillance company Perceptics was preparing to pitch New York’s transit authority on how it could help enforce impending “congestion pricing” rules, according to leaked documents reviewed by The Intercept. The pitch, as outlined in the files, went well beyond mere toll enforcement and into profiling New Yorkers’ travel patterns and companions, creating what experts describe as major privacy risks.

Congestion pricing, on the face of it, doesn’t seem like it would present a privacy risk — it’s a traffic policy, after all, not some new NYPD initiative. The plan is to essentially tax the cars that clog Manhattan’s streets and route the proceeds to public transportation, providing both a deterrent against and palliative for traffic. There won’t be any congestion pricing toll booths: The fee will be assessed automatically and electronically, potentially by photographing the license plates of passing cars and sending the plate owner a bill in the mail. This requires cameras running around the clock, dutifully recording every car that comes and goes. And this, Perceptics claims, is where the company truly shines.

According to an internal presentation released by the Perceptics hacker and reviewed by The Intercept, the company pitched New York’s Metropolitan Transportation Authority, or MTA, in February of this year on how Perceptics’ car-scanning camera arrays, already deployed and honed in areas like the Mexican border and an assortment of U.S. military installations, could help the MTA track down drivers. It’s unknown how the plan was received by the MTA, which administers public transit, bridges, and tolls for New York City and some of its surrounding suburbs, but leaked Perceptics emails show that the company shipped camera hardware to the MTA’s Bridges and Tunnels division for a live demonstration.

Perceptics did not respond to a request for comment. An MTA spokesperson told The Intercept that “all details are still to be determined” regarding congestion pricing enforcement.

The presentation document, titled “Smart Imaging Solutions for New York City Congestion Pricing,” makes clear that Perceptics wants to “produce vehicle-specific profiles” using cameras and “unique machine learning algorithms,” allowing the city to immediately recognize and build travel histories of every car in the congestion zone. Law enforcement and surveillance experts said the system described goes far beyond what would ever be necessary to mail scofflaws traffic tickets. Instead, it is an entirely new sort of surveillance apparatus that tracks deeply personal information like “customer travel patterns and travel consistency,” the number of passengers in the car, or “likely trip purpose,” and associates this information with a unique fingerprint of every vehicle that passes by Perceptics’ cameras.

Allie Bohm, a policy counsel with the New York Civil Liberties Union, described the Perceptics plan as an “incredibly privacy-invasive proposal” that “raises all sorts of associational and First Amendment concerns.” Bohm expressed particular alarm about the possibility of a congestion pricing enforcement system eventually feeding data into the NYPD’s existing surveillance regime. “The NYPD has fancied itself an intelligence agency for a very long time,” said Bohm. “These are folks who are pioneering some really, at best, questionable, and, at worst, alarming programs of surveillance and of drawing conclusions from innocuous behavior.”

The MTA will not deploy congestion pricing before 2021 and has yet to select a tolling vendor. But whether Perceptics wins a contract or not, its idea to bring to the heart of Manhattan military-grade surveillance technology — already provided to Saudi Special Forces and the Jordanian army, according to a Perceptics document — is an example of how something as innocuous-sounding as congestion pricing can turn into a surveillance sprawl.",,,,,
"In Court, Facebook Blames Users for Destroying Their Own Right to Privacy","IN APRIL 2018, Facebook CEO Mark Zuckerberg sat before members of both houses of Congress and told them his company respected the privacy of the roughly two billion people who use it. “Privacy” remained largely undefined throughout Zuckerberg’s televised flagellations, but he mentioned the concept more than two dozen times, including when he told the Senate’s Judiciary and Commerce committees, “We have a broader responsibility to protect people’s privacy even beyond” a consent decree from federal privacy regulators, and when he told the House Energy and Commerce Committee, “We believe that everyone around the world deserves good privacy controls.” A year later, Zuckerberg claimed in interviews and essays to have discovered the religion of personal privacy and vowed to rebuild the company in its image.

But only months after Zuckerberg first outlined his “privacy-focused vision for social networking” in a 3,000-word post on the social network he founded, his lawyers were explaining to a California judge that privacy on Facebook is nonexistent.

The courtroom debate, first reported by Law360, took place as Facebook tried to scuttle litigation from users upset that their personal data was shared without their knowledge with the consultancy Cambridge Analytica and later with advisers to Donald Trump’s campaign. The full transcript of the proceedings — which has been quoted from only briefly — reveal one of the most stunning examples of corporate doublespeak certainly in Facebook’s history.

Representing Facebook before U.S. District Judge Vince Chhabria was Orin Snyder of Gibson Dunn & Crutcher, who claimed that the plaintiffs’ charges of privacy invasion were invalid because Facebook users have no expectation of privacy on Facebook. The simple act of using Facebook, Snyder claimed, negated any user’s expectation of privacy:

There is no privacy interest, because by sharing with a hundred friends on a social media platform, which is an affirmative social act to publish, to disclose, to share ostensibly private information with a hundred people, you have just, under centuries of common law, under the judgment of Congress, under the SCA, negated any reasonable expectation of privacy.

An outside party can’t violate what you yourself destroyed, Snyder seemed to suggest. Snyder was emphatic in his description of Facebook as a sort of privacy anti-matter, going so far as to claim that “the social act of broadcasting your private information to 100 people negates, as a matter of law, any reasonable expectation of privacy.” You’d be hard-pressed to come up with a more elegant, concise description of Facebook than “the social act of broadcasting your private information” to people. So not only is it Facebook’s legal position that you’re not entitled to any expectation of privacy, but it’s your fault that the expectation went poof the moment you started using the site (or at least once you connected with 100 Facebook “friends”).

Judge Chhabria was skeptical of Snyder’s privacy nonexistence argument at times, which he rejected as treating personal privacy as a binary, “like either you have a full expectation of privacy, or you have no expectation of privacy at all,” the judge put it at one point. Chhabria continued with a relatable hypothetical:

If I share [information] with ten people, that doesn’t eliminate my expectation of privacy. It might diminish it, but it doesn’t eliminate it. And if I share something with ten people on the understanding that the entity that is helping me share it will not further disseminate it to a thousand companies, I don’t understand why I don’t have — why that’s not a violation of my expectation of privacy.

Snyder responded with an incredible metaphor for how Facebook sees your use of its services — legally, at least:

Let me give you a hypothetical of my own. I go into a classroom and invite a hundred friends. This courtroom. I invite a hundred friends, I rent out the courtroom, and I have a party. And I disclose — And I disclose something private about myself to a hundred people, friends and colleagues. Those friends then rent out a 100,000-person arena, and they rebroadcast those to 100,000 people. I have no cause of action because by going to a hundred people and saying my private truths, I have negated any reasonable expectation of privacy, because the case law is clear.

And there it is, in broad daylight: Using Facebook is a depressing party taking place in a courtroom, for some reason, that’s being simultaneously broadcasted to a 100,000-person arena on a sort of time delay. If you show up at the party, don’t be mad when your photo winds up on the Jumbotron. That is literally the company’s legal position.

Again and again, Snyder blames the targets of surveillance capitalism for their own surveillance:

This is why every parent says to their child, “Do not post it on Facebook if you don’t want to read about it tomorrow morning in the school newspaper,” or, as I tell my young associates if I were going to be giving them an orientation, “Do not put anything on social media that you don’t want to read in the Law Journal in the morning.” There is no expectation of privacy when you go on a social media platform, the purpose of which, when you are set to friends, is to share and communicate things with a large group of people, a hundred people.

At one point Chhabria asked, seemingly unable to believe Snyder’s argument himself, “If Facebook promises not to disseminate anything that you send to your hundred friends, and Facebook breaks that promise and disseminates your photographs to a thousand corporations, that would not be a serious privacy invasion?

Snyder didn’t blink: “Facebook does not consider that to be actionable, as a matter of law under California law.”

Facebook’s counsel did seem to concede one possibility for the existence of privacy on Facebook: someone who uses Facebook completely contrary to the way it’s designed and to the way it has always been marketed. “If you really want to be private,” Snyder proposed to the court, “there are people who have archival Facebook pages that are like their own private mausoleum. It’s only set to [be visible by] me, and it’s for the purpose of repository, you know, of your private information, and no one will ever see that.” So these are your possible valid legal statuses as a Facebook user: You’re either plugged into the 100,0000-person perpetual surveillance Coachella or living in a digital “mausoleum.” But if you ever decide to fling open the doors of your private data crypt and, say, share a little content on Facebook with friends, as the company has been pushing us for the past 13 years, Snyder says you’re out of luck:

Once you go to friends, the gig is over because you’ve just gone — taken a hundred people and pronounced your personal likes and dislikes. In fact, the very act of liking something and showing your friends that you like something is a non-private act. It’s the whole premise of Facebook and social media, is to render not private your likes, your dislikes, your expressions. When I tag someone in a photo, it’s to tell people, not keep private, that I’m sitting on a park bench with John Smith. So it’s the opposite of private when you do that.

Facebook’s stance that if one truly wants to keep something private, they should keep it far from Facebook is odd — odder, still, given the fact that the company publishes an extremely detailed privacy policy, perhaps only meant for those huddling in private mausoleums where such a principle still exists.

“Facebook was built to bring people closer together,” reads the start of the company’s “Privacy Principles.” “We help you connect with friends and family, discover local events and find groups to join.” Not mentioned is that if you do any of that, it’s Facebook’s official opinion that you’ve “negated” your claim to any privacy whatsoever. The list of principles reads like a bad joke after studying Snyder’s courtroom theorizing: “We design privacy into our products from the outset” seems hard to reconcile with “Once you go to friends, the gig is over.” It’s similarly hard to take “We give you control of your privacy” seriously after hearing, through Snyder, that because Facebook users “shared the information … you’ve lost control over the information and its subsequent disclosure.”",,,,,
Team of American Hackers and Emirati Spies Discussed Attacking The Intercept,"OPERATIVES AT A controversial cybersecurity firm working for the United Arab Emirates government discussed targeting The Intercept and breaching the computers of its employees, according to two sources, including a member of the hacking team who said they were present at a meeting to plan for such an attack.

The firm, DarkMatter, brought ex-National Security Agency hackers and other U.S. intelligence and military veterans together with Emirati analysts to compromise the computers of political dissidents at home and abroad, including American citizens, Reuters revealed in January. The news agency also reported that the FBI is investigating DarkMatter’s use of American hacking expertise and the possibility that it was wielded against Americans.

The campaign against dissidents and critics of the Emirati government, code-named Project Raven, began in Baltimore. A 2016 Intercept article by reporter Jenna McLaughlin revealed how the Maryland-based computer security firm CyberPoint assembled a team of Americans for a contract to hone UAE’s budding hacking and surveillance capabilities, leaving some recruits unsettled. Much of the CyberPoint team was later poached by DarkMatter, a firm with close ties to the Emirati government and headquartered just two floors from the Emirati equivalent of the NSA, the National Electronic Security Authority (which later became the Signals Intelligence Agency). One of McLaughlin’s sources described the episode as something of a “hostile takeover” by the UAE government. A subsequent story by McLaughlin  for Foreign Policy detailed how American spies at DarkMatter had been crucial in building the UAE’s intelligence apparatus. The NESA would go on to become Project Raven’s primary “client,” responsible for handing down groups and organizations to be targeted and compromised.",,,,,
Right-Wing Sting Group Project Veritas Is Breaking Facebook’s “Authentic Behavior” Rule. Now What?,"A MEMBER OF Project Veritas gave testimony in a federal court case indicating that the right-wing group, known for its undercover videos, violates Facebook policies designed to counter systematic deception by Russian troll farms and other groups. The deposition raises questions over whether Facebook will deter American operatives who use the platform to strategically deceive and damage political opponents as vigorously as it has Iranian and Russian propagandists. But is the company capable of doing so without just creating more problems?

Close observers of Veritas and Facebook, including one at a research lab that works with the social network, said the testimony shows the group is clearly violating policies against what Facebook refers to as “coordinated inauthentic behavior.” The company formally defined such behavior in a December 2018 video featuring its cybersecurity policy chief Nathaniel Gleicher, who said it “is when groups of pages or people work together to mislead others about who they are or what they’re doing.” The designation, Gleicher added, is applied by Facebook to a group not “because of the content they’re sharing” but rather only “because of their deceptive behavior.” That is, using Facebook to dupe people is all it takes to fit the company’s institutional definition of coordinated inauthentic behavior.

In practice, “coordinated inauthentic behavior” has become a sort of catchall label for untoward meddling on Facebook, snagging everyone from Burmese military officers to Russian meme spammers. But curbing such activity has become a very public crusade for Facebook in the wake of its prominent role as a platform for the spread of disinformation, propaganda, and outright hoaxes during the 2016 presidential campaign. This past January, Gleicher announced the removal of coordinated inauthentic behavior from Iran, which spread when operatives “coordinated with one another and used fake accounts to misrepresent themselves,” thus triggering a Facebook ban. Similarly, in a 2017 update on Facebook’s internal investigation into Russian online propaganda efforts, the company’s then-head of security Alex Stamos assured the world’s democracies the company was providing “technology improvements for detecting fake accounts,” including “changes to help us more efficiently detect and stop inauthentic accounts at the time they are being created.”

Throughout all of this, coordinated inauthentic behavior has remained more or less synonymous with “foreign actors” and “nation-states,” the cloak-and-dagger stuff of an increasingly militarized internet filled with enemies of the Western Democracy who seek to subvert it from abroad.

Project Veritas, a hybrid of an opposition research shop and a ranting YouTube channel, has taken pride in its ability to deceive since its creation in 2010. With conservative backers like Peter Thiel, the Koch brothers, and the Trump Foundation, the group and its founder James O’Keefe have worked relentlessly to target and malign individuals at institutions they deem leftist, whether it’s Planned Parenthood (reportedly targeted by O’Keefe posing as a young teen’s 23-year-old boyfriend), George Soros (the progressive philanthropist whose professional circle Veritas tried and spectacularly failed to infiltrate), or the Washington Post (whose reporter was offered a fake story on Alabama Senate candidate Roy Moore). O’Keefe has long attempted to position himself in the context of dogged, daring, traditional journalism, describing Veritas’s efforts as “investigative” reporting executed by “undercover journalists.” But his efforts are often executed by what the New Yorker has called “amateurish spies” — their efforts against the Post and Soros resembled a Three Stooges bit — and packaged with mendacious editing, duplicitous production, and outright lying, making Veritas’s audience as much a victim of its productions as the subjects. Debates over who or what is to be considered “real journalism” are almost always counterproductive and contrived, but Veritas stands out for the shamelessness with which it pursues nakedly partisan ends.

There is, of course, a proud tradition of undercover journalism executed unequivocally in the name of informing the public. Writers like Barbara Ehrenreich and Shane Bauer have taken jobs they were not otherwise interested in in order to reveal injustices in society’s margins, and some of the most damning details of the Cambridge Analytica scandal were exposed by a reporter with the UK’s Channel 4 posing as a foreign politician interested in the company’s services. This reporting involved lying, sure — or at least the withholding of true intent, and a willingness to let others deceive themselves — but only as a means to a truthful end. The distinction between these reporters and Veritas operatives may be that the end the latter group seeks, the final media product, is typically just another act of partisan misdirection that doesn’t withstand further scrutiny.

Neither Project Veritas nor Facebook commented for this story.

“Legend Building” by Project Veritas

Project Veritas has systematically deceived not just targets on the left and viewers on the right but Facebook users as well (their official page has over 200,000 followers) at a time when the company is publicly dedicated to fighting this sort of systemic duplicity. That’s a wrinkle that raises questions about Facebook’s commitment to rooting out coordinated inauthentic behavior closer to home — Thiel sits on the company’s board — not to mention Project Veritas’s presence on social media.",,,,,
China Bans The Intercept and Other News Sites in “Censorship Black Friday”,"THE CHINESE GOVERNMENT appears to have launched a major new internet crackdown, blocking the country’s citizens from accessing The Intercept’s website and those of at least seven other Western news organizations.

On Friday, people in China began reporting that they could not access the websites of The Intercept, The Guardian, the Washington Post, HuffPost, NBC News, the Christian Science Monitor, the Toronto Star, and Breitbart News.

It is unclear exactly when the censorship came into effect or the reasons for it. But Tuesday marked the 30th anniversary of the Tiananmen Square massacre, and Chinese authorities have reportedly increased levels of online censorship to coincide with the event.

Charlie Smith, co-founder of GreatFire.org, an organization that monitors Chinese government internet censorship, said that the apparent crackdown on Western news sites represented a significant new development and described it as a “censorship Black Friday.”

“This frenzied activity could indicate that the authorities are accelerating their push to sever the link between Chinese citizens and any news source that falls outside of the influence of The Party,” said Smith, referencing the ruling Communist Party regime.

For years, China has blocked several Western news organizations after they have published stories that reflect negatively on the government. The New York Times, Bloomberg, the Wall Street Journal, and Reuters have all previously been censored, rendering their websites inaccessible in the country.

China operates an internet censorship system known as the Great Firewall, which uses filtering equipment to stop people in the country from accessing content published on banned websites that are operated outside China’s borders.

It is possible to circumvent the censorship using tools such as a virtual private network, or VPN. However, use of technology that bypasses the Great Firewall is banned — and people in the country who sell access to these services have been jailed.",,,,,
This Chinese Artist Criticized Google and Xi Jinping. Now He’s Facing Government Harassment.,"THE MESSAGES ARRIVED suddenly and then he went quiet. “My identity is leaked,” he said. “I am worried about my safety.”

The Chinese dissident artist Badiucao had been busy preparing an exhibition in Hong Kong to celebrate Free Expression Week, a series of events organized by rights groups. His show was partly inspired by Google’s plan to build a censored search engine in China, and was set to include work that the artist had created skewering the U.S. tech giant for cooperating with the Communist Party regime’s suppression of internet freedom.

But just days before the exhibition was set to launch last year, at a high-profile event featuring members of Russian punk-activist group Pussy Riot, it was canceled by organizers. Badiucao had received threats from the Chinese government and soon went into hiding.

It was a nightmare scenario for the artist, one of China’s most prolific political satirists, who has never revealed his real name. Somehow, police in China had discovered who he was — and they were trying to track him down.",,,,,
Amazon Offered Job to Pentagon Official Involved With $10 Billion Contract It Sought,"IN A FEDERAL lawsuit, the tech giant Oracle has provided new details to support its accusation that Amazon secretly negotiated a job offer with a then-Department of Defense official who helped shape the procurement process for a massive federal contract for which Amazon was a key bidder.

Amazon Web Services and Microsoft are now the two finalists to win the highly contested $10 billion contract for what is known as the Joint Enterprise Defense Infrastructure, or JEDI. The deal, one of the largest federal contracts in U.S. history, would pay one company to provide cloud computing services in support of Defense Department operations around the world.

But the contract has been hotly contested since the department began soliciting proposals last year. Two of Amazon’s competitors, IBM and Oracle, filed complaints with the Government Accountability Office saying that the winner-take-all process unfairly favored Amazon, which is seen as an industry leader in cloud computing. When its claim was rejected, Oracle sued the government in the U.S. Court of Federal Claims.

Since the court battle began in 2018, Oracle has aggressively lodged conflict-of-interest accusations involving a former DOD official named Deap Ubhi, who left the department in 2017 to take a job at Amazon. In a court motion filed on Friday, Oracle alleged that while Ubhi worked on the preliminary research for the JEDI program in the late summer and fall of 2017, he was also engaged in a secret job negotiation with Amazon for months, complete with salary discussions, offers of signing bonuses, and lucrative stock options.

The motion further alleges that Ubhi did not recuse himself from the JEDI program until weeks after verbally accepting a job offer from Amazon and that he continued to receive information about Amazon’s competitors and participate in meetings about technical requirements, despite a government regulation that forbids such conflicts of interest.

“Neither Ubhi nor [Amazon Web Services] disclosed the employment discussions or job offer to DOD — not when the employment discussions started, not when the informal job offer occurred, not when the formal offer occurred, and not even when Ubhi accepted the offer,” Oracle’s motion reads.

As America’s technology companies have continued to outpace the Pentagon, the Defense Department has looked to recruit talent from Silicon Valley to help enhance its information technology.

Ubhi is a venture capitalist and technology entrepreneur who worked for Amazon before his time in government. He took a job working on a Defense Department initiative aimed at collaborating with Silicon Valley to modernize the Pentagon’s information technology systems. After working as part of a four-person team to help shape the Pentagon JEDI procurement process, he left the department and returned to Amazon in November 2017.

A spokesperson for Amazon Web Services declined to comment and declined to make Ubhi available for an interview, citing ongoing litigation. Elissa Smith, a spokesperson for the Department of Defense, also told The Intercept that “we don’t comment on pending litigation.”

In a previous court filing, U.S. government lawyers accused Oracle of a “broad fishing expedition primarily [intended] to find support for its claim that the solicitation at issue is tainted by alleged conflicts of interest.”

According to Oracle’s motion on Friday, Ubhi began job negotiations with Amazon in August 2017, while he was working on the early stages of the JEDI program. Oracle claims says that “deep discussions” about employment began in late September and that Ubhi “verbally committed” to take the job on October 4. But according to the filing, Ubhi did not recuse himself until October 31, 2017. Oracle alleges that he continued to influence the program in the meantime.

Under the Procurement Integrity Act, government officials who are “contacted by a [contract] bidder about non-federal employment” have two options: They must either report the contact and reject the offer of employment or promptly recuse themselves from any contract proceedings.

“Contracts should be awarded fairly based on merit,” Mandy Smithberger, director of the Center for Defense Information at the Project on Government Oversight, told The Intercept. “The Procurement Integrity Act seeks to ensure that job offers and other financial conflicts of interest don’t influence that process.”

Last year, a Defense Department review found that “there were four instances where [department] individuals with potential financial conflicts of interest” had worked on the JEDI program, according to court records, but the Pentagon concluded that this hadn’t unfairly impacted the contracting process. Two follow-up reviews — one by the GAO in November 2018 and another by the Defense Department in April 2019 — came to similar conclusions.

The second Pentagon review came after the department said that it had received “new information” about Ubhi and would investigate it. According to Oracle’s motion on Friday, the “new information” came from a “belated submission from [Amazon]” to the DOD’s contracting officer that finally acknowledged the monthslong employment talks.

According to Oracle, Ubhi provided a “false narrative” to the contracting officer at the time of his recusal, saying that he was stepping away from the project because Amazon had offered to acquire a company that Ubhi had a stake in. That was a pretext to mask the fact he had been negotiating for months to obtain a job at the company, Oracle’s filing said.

The filing also alleges that between Ubhi’s verbal commitment to accept Amazon’s offer and his recusal from JEDI, he continued to participate in Pentagon meetings about the project’s technical requirements and to receive submissions from Amazon competitors. It also alleges that Ubhi downloaded material from a JEDI project Google Drive to his own laptop.

In its filings, Oracle has argued that Ubhi was instrumental in persuading the Pentagon to seek services from a single vendor — a decision widely seen to improve Amazon’s chances. Oracle cites workplace messages on the platform Slack in which Ubhi tries to persuade his colleagues to come around to that view, but the company does not cite any messages suggesting what his reasons or motive may have been.",,,,,
Snowden Archive,,,,,,
Snowden Archive,,,,,,
Snowden Archive,,,,,,
Snowden Archive,,,,,,
"Thanks to Facebook, Your Cellphone Company Is Watching You More Closely Than Ever","AMONG THE MEGA-CORPORATIONS that surveil you, your cellphone carrier has always been one of the keenest monitors, in constant contact with the one small device you keep on you at almost every moment. A confidential Facebook document reviewed by The Intercept shows that the social network courts carriers, along with phone makers — some 100 different companies in 50 countries — by offering the use of even more surveillance data, pulled straight from your smartphone by Facebook itself.

Offered to select Facebook partners, the data includes not just technical information about Facebook members’ devices and use of Wi-Fi and cellular networks, but also their past locations, interests, and even their social groups. This data is sourced not just from the company’s main iOS and Android apps, but from Instagram and Messenger as well. The data has been used by Facebook partners to assess their standing against competitors, including customers lost to and won from them, but also for more controversial uses like racially targeted ads.

Some experts are particularly alarmed that Facebook has marketed the use of the information — and appears to have helped directly facilitate its use, along with other Facebook data — for the purpose of screening customers on the basis of likely creditworthiness. Such use could potentially run afoul of federal law, which tightly governs credit assessments.

Facebook said it does not provide creditworthiness services and that the data it provides to cellphone carriers and makers does not go beyond what it was already collecting for other uses.

Facebook’s cellphone partnerships are particularly worrisome because of the extensive surveillance powers already enjoyed by carriers like AT&T and T-Mobile: Just as your internet service provider is capable of watching the data that bounces between your home and the wider world, telecommunications companies have a privileged vantage point from which they can glean a great deal of information about how, when, and where you’re using your phone. AT&T, for example, states plainly in its privacy policy that it collects and stores information “about the websites you visit and the mobile applications you use on our networks.” Paired with carriers’ calling and texting oversight, that accounts for just about everything you’d do on your smartphone.

An Inside Look at “Actionable Insights”

You’d think that degree of continuous monitoring would be more than sufficient for a communications mammoth to operate its business — and perhaps for a while it was. But Facebook’s “Actionable Insights,” a corporate data-sharing program, suggests that even the incredible visibility telecoms have into your daily life isn’t enough — and Zuckerberg et al. can do them one better. Actionable Insights was announced last year in an innocuous, easy-to-miss post on Facebook’s engineering blog. The article, titled “Announcing tools to help partners improve connectivity,” strongly suggested that the program was primarily aimed at solving weak cellular data connections around the world. “To address this problem,” the post began, “we are building a diverse set of technologies, products, and partnerships designed to expand the boundaries of existing connectivity quality and performance, catalyze new market segments, and bring better access to the unconnected.” What sort of monster would stand against better access for the unconnected?

The blog post makes only a brief mention of Actionable Insights’ second, less altruistic purpose: “enabling better business decisions” through “analytics tools.” According to materials reviewed by The Intercept and a source directly familiar with the program, the real boon of Actionable Insights lies not in its ability to fix spotty connections, but to help chosen corporations use your personal data to buy more tightly targeted advertising.

The source, who discussed Actionable Insights on the condition of anonymity because they were not permitted to speak to the press, explained that Facebook has offered the service to carriers and phone makers ostensibly of free charge, with access to Actionable Insights granted as a sweetener for advertising relationships. According to the source, the underlying value of granting such gratis access to Actionable Insights in these cases isn’t simply to help better service cell customers with weak signals, but also to ensure that telecoms and phone makers keep buying  more and more carefully targeted Facebook ads. It’s exactly this sort of quasi-transactional data access that’s become a hallmark of Facebook’s business, allowing the company to plausibly deny that it ever sells your data while still leveraging it for revenue. Facebook may not be “selling” data through Actionable Insights in the most baldly literal sense of the word — there’s no briefcase filled with hard drives being swapped for one containing cash — but the relationship based on spending and monetization certainly fits the spirit of a sale. A Facebook spokesperson declined to answer whether the company charges for Actionable Insights access.

The confidential Facebook document provides an overview of Actionable Insights and espouses its benefits to potential corporate users. It shows how the program, ostensibly created to help improve underserved cellular customers, is pulling in far more data than how many bars you’re getting. According to one portion of the presentation, the Facebook mobile app harvests and packages eight different categories of information for use by over 100 different telecom companies in over 50 different countries around the world, including usage data from the phones of children as young as 13. These categories include use of video, demographics, location, use of Wi-Fi and cellular networks, personal interests, device information, and friend homophily, an academic term of art. A 2017 article on social media friendship from the Journal of the Society of Multivariate Experimental Psychology defined “homophily” in this context as “the tendency of nodes to form relations with those who are similar to themselves.” In other words, Facebook is using your phone to not only provide behavioral data about you to cellphone carriers, but about your friends as well.

From these eight categories alone, a third party could learn an extraordinary amount about patterns of users’ daily life, and although the document claims that the data collected through the program is “aggregated and anonymized,” academic studies have found time and again that so-called anonymized user data can be easily de-anonymized. Today, such claims of anonymization and aggregation are essentially boilerplate from companies who wager you’ll be comfortable with them possessing a mammoth trove of personal observations and behavioral predictions about your past and future if the underlying data is sufficiently neutered and grouped with your neighbor’s.

A Facebook spokesperson told The Intercept that Actionable Insights doesn’t collect any data from user devices that wasn’t already being collected anyway. Rather, this spokesperson said Actionable Insights repackages the data in novel ways useful to third-party advertisers in the telecom and smartphone industries.

Material reviewed by The Intercept show demographic information presented in a dashboard-style view, with maps showing customer locations at the county and city level. A Facebook spokesperson said they “didn’t think it goes more specific than zip code.” But armed with location data beamed straight from your phone, Facebook could technically provide customer location accurate to a range of several meters, indoors or out.

Targeting By Race and Likely Creditworthiness

Despite Facebook’s repeated assurances that user information is completely anonymized and aggregated, the Actionable Insights materials undermine this claim. One Actionable Insights case study from the overview document promotes how an unnamed North American cellular carrier had previously used its Actionable Insights access to target a specific, unnamed racial group. Facebook’s targeting of “multicultural affinity groups,” as the company formerly referred to race, was discontinued in 2017 after the targeting practice was widely criticized as potentially discriminatory.

Another case study described how Actionable Insights can be used to single out individual customers on the basis of creditworthiness. In this example, Facebook explained how one of its advertising clients, based outside the U.S., wanted to exclude individuals from future promotional offers on the basis of their credit. Using data provided through Actionable Insights, a Data Science Strategist, a role for which Facebook continues to hire, was able to generate profiles of customers with desirable and undesirable credit standings. The advertising client then used these profiles to target or exclude Facebook users who resembled these profiles.",,,,,
Google Dragonfly,"AMONG THE MEGA-CORPORATIONS that surveil you, your cellphone carrier has always been one of the keenest monitors, in constant contact with the one small device you keep on you at almost every moment. A confidential Facebook document reviewed by The Intercept shows that the social network courts carriers, along with phone makers — some 100 different companies in 50 countries — by offering the use of even more surveillance data, pulled straight from your smartphone by Facebook itself.

Offered to select Facebook partners, the data includes not just technical information about Facebook members’ devices and use of Wi-Fi and cellular networks, but also their past locations, interests, and even their social groups. This data is sourced not just from the company’s main iOS and Android apps, but from Instagram and Messenger as well. The data has been used by Facebook partners to assess their standing against competitors, including customers lost to and won from them, but also for more controversial uses like racially targeted ads.

Some experts are particularly alarmed that Facebook has marketed the use of the information — and appears to have helped directly facilitate its use, along with other Facebook data — for the purpose of screening customers on the basis of likely creditworthiness. Such use could potentially run afoul of federal law, which tightly governs credit assessments.

Facebook said it does not provide creditworthiness services and that the data it provides to cellphone carriers and makers does not go beyond what it was already collecting for other uses.

Facebook’s cellphone partnerships are particularly worrisome because of the extensive surveillance powers already enjoyed by carriers like AT&T and T-Mobile: Just as your internet service provider is capable of watching the data that bounces between your home and the wider world, telecommunications companies have a privileged vantage point from which they can glean a great deal of information about how, when, and where you’re using your phone. AT&T, for example, states plainly in its privacy policy that it collects and stores information “about the websites you visit and the mobile applications you use on our networks.” Paired with carriers’ calling and texting oversight, that accounts for just about everything you’d do on your smartphone.

An Inside Look at “Actionable Insights”

You’d think that degree of continuous monitoring would be more than sufficient for a communications mammoth to operate its business — and perhaps for a while it was. But Facebook’s “Actionable Insights,” a corporate data-sharing program, suggests that even the incredible visibility telecoms have into your daily life isn’t enough — and Zuckerberg et al. can do them one better. Actionable Insights was announced last year in an innocuous, easy-to-miss post on Facebook’s engineering blog. The article, titled “Announcing tools to help partners improve connectivity,” strongly suggested that the program was primarily aimed at solving weak cellular data connections around the world. “To address this problem,” the post began, “we are building a diverse set of technologies, products, and partnerships designed to expand the boundaries of existing connectivity quality and performance, catalyze new market segments, and bring better access to the unconnected.” What sort of monster would stand against better access for the unconnected?

The blog post makes only a brief mention of Actionable Insights’ second, less altruistic purpose: “enabling better business decisions” through “analytics tools.” According to materials reviewed by The Intercept and a source directly familiar with the program, the real boon of Actionable Insights lies not in its ability to fix spotty connections, but to help chosen corporations use your personal data to buy more tightly targeted advertising.

The source, who discussed Actionable Insights on the condition of anonymity because they were not permitted to speak to the press, explained that Facebook has offered the service to carriers and phone makers ostensibly of free charge, with access to Actionable Insights granted as a sweetener for advertising relationships. According to the source, the underlying value of granting such gratis access to Actionable Insights in these cases isn’t simply to help better service cell customers with weak signals, but also to ensure that telecoms and phone makers keep buying  more and more carefully targeted Facebook ads. It’s exactly this sort of quasi-transactional data access that’s become a hallmark of Facebook’s business, allowing the company to plausibly deny that it ever sells your data while still leveraging it for revenue. Facebook may not be “selling” data through Actionable Insights in the most baldly literal sense of the word — there’s no briefcase filled with hard drives being swapped for one containing cash — but the relationship based on spending and monetization certainly fits the spirit of a sale. A Facebook spokesperson declined to answer whether the company charges for Actionable Insights access.

The confidential Facebook document provides an overview of Actionable Insights and espouses its benefits to potential corporate users. It shows how the program, ostensibly created to help improve underserved cellular customers, is pulling in far more data than how many bars you’re getting. According to one portion of the presentation, the Facebook mobile app harvests and packages eight different categories of information for use by over 100 different telecom companies in over 50 different countries around the world, including usage data from the phones of children as young as 13. These categories include use of video, demographics, location, use of Wi-Fi and cellular networks, personal interests, device information, and friend homophily, an academic term of art. A 2017 article on social media friendship from the Journal of the Society of Multivariate Experimental Psychology defined “homophily” in this context as “the tendency of nodes to form relations with those who are similar to themselves.” In other words, Facebook is using your phone to not only provide behavioral data about you to cellphone carriers, but about your friends as well.

From these eight categories alone, a third party could learn an extraordinary amount about patterns of users’ daily life, and although the document claims that the data collected through the program is “aggregated and anonymized,” academic studies have found time and again that so-called anonymized user data can be easily de-anonymized. Today, such claims of anonymization and aggregation are essentially boilerplate from companies who wager you’ll be comfortable with them possessing a mammoth trove of personal observations and behavioral predictions about your past and future if the underlying data is sufficiently neutered and grouped with your neighbor’s.

A Facebook spokesperson told The Intercept that Actionable Insights doesn’t collect any data from user devices that wasn’t already being collected anyway. Rather, this spokesperson said Actionable Insights repackages the data in novel ways useful to third-party advertisers in the telecom and smartphone industries.

Material reviewed by The Intercept show demographic information presented in a dashboard-style view, with maps showing customer locations at the county and city level. A Facebook spokesperson said they “didn’t think it goes more specific than zip code.” But armed with location data beamed straight from your phone, Facebook could technically provide customer location accurate to a range of several meters, indoors or out.

Targeting By Race and Likely Creditworthiness

Despite Facebook’s repeated assurances that user information is completely anonymized and aggregated, the Actionable Insights materials undermine this claim. One Actionable Insights case study from the overview document promotes how an unnamed North American cellular carrier had previously used its Actionable Insights access to target a specific, unnamed racial group. Facebook’s targeting of “multicultural affinity groups,” as the company formerly referred to race, was discontinued in 2017 after the targeting practice was widely criticized as potentially discriminatory.

Another case study described how Actionable Insights can be used to single out individual customers on the basis of creditworthiness. In this example, Facebook explained how one of its advertising clients, based outside the U.S., wanted to exclude individuals from future promotional offers on the basis of their credit. Using data provided through Actionable Insights, a Data Science Strategist, a role for which Facebook continues to hire, was able to generate profiles of customers with desirable and undesirable credit standings. The advertising client then used these profiles to target or exclude Facebook users who resembled these profiles.",,,,,
Drone Wars,"IMAGINE YOU’RE HIKING through the woods near a border. Suddenly, you hear a mechanical buzzing, like a gigantic bee. Two quadcopters have spotted you and swoop in for a closer look. Antennae on both drones and on a nearby autonomous ground vehicle pick up the radio frequencies coming from the cell phone in your pocket. They send the signals to a central server, which triangulates your exact location and feeds it back to the drones. The robots close in.

Cameras and other sensors on the machines recognize you as human and try to ascertain your intentions. Are you a threat? Are you illegally crossing a border? Do you have a gun? Are you engaging in acts of terrorism or organized crime? The machines send video feeds to their human operator, a border guard in an office miles away, who checks the videos and decides that you are not a risk. The border guard pushes a button, and the robots disengage and continue on their patrol.

This is not science fiction. The European Union is financing a project to develop drones piloted by artificial intelligence and designed to autonomously patrol Europe’s borders. The drones will operate in swarms, coordinating and corroborating information among fleets of quadcopters, small fixed-wing airplanes, ground vehicles, submarines, and boats. Developers of the project, known as Roborder, say the robots will be able to identify humans and independently decide whether they represent a threat. If they determine that you may have committed a crime, they will notify border police.

President Donald Trump has used the specter of criminals crossing the southern border to stir nationalist political sentiment and energize his base. In Europe, two years after the height of the migration crisis that brought more than a million people to the continent, mostly from the Middle East and Africa, immigration remains a hot-button issue, even as the number of new arrivals has dropped. Political parties across the European Union are winning elections on anti-immigrant platforms and enacting increasingly restrictive border policies. Tech ethicists and privacy advocates worry that Roborder and projects like it outsource too much law enforcement work to nonhuman actors and could easily be weaponized against people in border areas.",,,,,
"Privacy Experts, Senators Demand Investigation of Amazon’s Child Data Collection Practices","IMAGINE YOU’RE HIKING through the woods near a border. Suddenly, you hear a mechanical buzzing, like a gigantic bee. Two quadcopters have spotted you and swoop in for a closer look. Antennae on both drones and on a nearby autonomous ground vehicle pick up the radio frequencies coming from the cell phone in your pocket. They send the signals to a central server, which triangulates your exact location and feeds it back to the drones. The robots close in.

Cameras and other sensors on the machines recognize you as human and try to ascertain your intentions. Are you a threat? Are you illegally crossing a border? Do you have a gun? Are you engaging in acts of terrorism or organized crime? The machines send video feeds to their human operator, a border guard in an office miles away, who checks the videos and decides that you are not a risk. The border guard pushes a button, and the robots disengage and continue on their patrol.

This is not science fiction. The European Union is financing a project to develop drones piloted by artificial intelligence and designed to autonomously patrol Europe’s borders. The drones will operate in swarms, coordinating and corroborating information among fleets of quadcopters, small fixed-wing airplanes, ground vehicles, submarines, and boats. Developers of the project, known as Roborder, say the robots will be able to identify humans and independently decide whether they represent a threat. If they determine that you may have committed a crime, they will notify border police.

President Donald Trump has used the specter of criminals crossing the southern border to stir nationalist political sentiment and energize his base. In Europe, two years after the height of the migration crisis that brought more than a million people to the continent, mostly from the Middle East and Africa, immigration remains a hot-button issue, even as the number of new arrivals has dropped. Political parties across the European Union are winning elections on anti-immigrant platforms and enacting increasingly restrictive border policies. Tech ethicists and privacy advocates worry that Roborder and projects like it outsource too much law enforcement work to nonhuman actors and could easily be weaponized against people in border areas.",,,,,
The War on Immigrants,"PALANTIR, THE CIA-FUNDED data analysis company founded by billionaire Trump adviser Peter Thiel, provided software at the center of a 2017 operation targeting unaccompanied children and their families, newly released Homeland Security documents show.

The documents undercut prior statements from Palantir, in which the company tried to draw a clean line between the wing of ICE devoted strictly to deportations and the enforcement of immigration laws, and its $38 million contract with Homeland Security Investigations, or HSI, a component of ICE with a far broader criminal enforcement mandate. Asked about the contract renewal by the New York Times, a Palantir spokesperson stated:

“There are two major divisions of ICE with two distinct mandates: Homeland Security Investigations, or H.S.I., is responsible for cross-border criminal investigations. The other major directorate, Enforcement and Removal Operations, or E.R.O., is responsible for interior civil immigration enforcement, including deportation and detention of undocumented immigrants. We do not work for E.R.O.”

Documents obtained through Freedom of Information Act litigation and provided to The Intercept show that this claim, that Palantir software is strictly involved in criminal investigations as opposed to deportations, is false. The discrepancy between the private intelligence firm’s public assertion and the reality conveyed in the newly-released documents was first identified by Mijente, an advocacy organization that has closely tracked Palantir’s murky role in immigration enforcement. Far from detached support in “cross-border criminal investigations,” the materials released this week confirm the role Palantir technology played in facilitating hundreds of arrests, only a small fraction of which led to criminal prosecutions.",,,,,
"Avoid Surveillance With Helm, a Home Server Anyone Can Use to Keep Emails Truly Private","DURING A GROUP DINNER in a small town in Norway in 2015, at an international conference for investigative journalists, a Ukrainian reporter told me that he used both Gmail and Mail.ru, Russia’s most popular email provider. “Every time I write an email,” he said, “I have to decide if I want Obama to read it, or if I want Putin to read it.”

It may be hyperbolic to suggest that world leaders personally comb through individual email accounts, but the reporter’s point stands: When you use services like Gmail, Mail.ru, Facebook, Dropbox, Slack, or any other site that stores your data, they will hand your private information to governments when compelled to do so and in some cases, merely when asked. Last year, the Supreme Court ruled that the government usually needs a warrant to access private data held by third-party companies. But even with new legal protection, email remains all too easy for governments to quietly obtain. Many companies, like Facebook, have shared personal information even more widely, with private entities. When your personal data is stored on a company’s servers, as with the email in your Gmail account, there are no technical barriers to the host company sharing it when it sees fit.

Google provided private information to government agencies around the world more than 60,000 times in 2017, often turning over data from multiple Google accounts at once, according to its transparency report. And that doesn’t include over 100,000 Google accounts from which the company gave data in response to secret orders from the Foreign Intelligence Surveillance Court, a U.S. national security tribunal whose meetings and decisions are kept from the public. Mail.ru doesn’t provide a transparency report, but the situation is no doubt much worse in Russia: All Russian internet companies are required to retain data they collect about their users and to hand it to FSB, a Russian spy agency, if asked.",,,,,
New Bernie Sanders App Democratizes Organizing — and Panics People Unfamiliar With Organizing,"THE BERNIE SANDERS campaign kicked off its massive volunteer program this weekend by holding nearly 5,000 house parties across the country and unveiling a new organizing app that gives campaign supporters a way to share political information on friends, family, and neighbors. 

Sanders’s strategy to emerge from the crowded primary field revolves around energizing and empowering his army of supporters, and giving them easy-to-use tools in the hopes of expanding the electoral map in both the primary and general elections. More than 60,000 people attended the events, which took place in every state and more than 30 countries outside the U.S., according to the campaign.

Sanders, along with campaign manager Faiz Shakir and campaign co-chair Nina Turner, addressed supporters through a pre-recorded broadcast that was streamed at the parties. “So let’s do it, let’s run a historic grassroots campaign,” Sanders told supporters. “And when we do that, the 1 percent can spend all of the money that they want. We’re gonna beat them.”

The campaign’s new organizing tool, called BERN, helps volunteers track potential supporters and voters, allowing them to log the name and background of anyone they talk to, from friends and family members to a stranger on the street. The app will also help volunteers know how to participate in the Democratic primary or caucus in their state and register voters.

On friend-to-friend mode, supporters are asked to add the name, city, and state of everyone they know, information that is then matched to their voter record. The app also asks about the person’s level of support, union membership, and other candidates they might vote for.

Some critics have called the app invasive, arguing that the database of personal information could open non-supporters up to harassment. Though much of the information the app requests is publicly available, critics say that having the data neatly compiled — while not giving people a way to opt out of it — presents safety concerns.

The skepticism appears rooted in (hostility to Sanders and) a basic lack of familiarity with how campaigns work. Voter rolls are public, and the Democratic Party has long been aggregating additional information about voters to aid with fundraising and turnout operations, data that all major campaigns have access to. The difference is that the Sanders app democratizes the process with the goal of expanding the electorate, while the party operations are aimed at identifying existing supporters so they can be motivated to vote. The party data is generally available to campaign volunteers, but because Sanders lowers the bar to volunteering, more people will now have access to the data. The goal, though, is to get more people to vote for Sanders, not to attack Sanders opponents.

To that end, they’ll be relying heavily on supporters.“We don’t think, in the national office, that we have all of the answers,” Sanders said. “Trust me, we don’t. Every person out there knows your own community better than we do. Can you put on a concert, can you have a potluck event? Whatever it may be, bring people together. Develop a sense of community, reach out to people who might feel uncomfortable about being involved in politics.”

Sanders has a list of 1.1 million people who’ve pledged to volunteer so far, meaning roughly 6 percent showed up to a house party over the weekend. Sanders told them that the goal is to have volunteers engaging on social media in addition to the “old-fashioned stuff,” like knocking on doors and handing out literature. Unlike the typical political campaign, where volunteers work under the supervision of paid campaign staff, Sanders volunteers will be given the tools to help grow the movement at an exponential scale, free of the restraints of traditional top-down campaigns.

“And remember,” Sanders said. “It’s not Bernie! It’s us! Don’t forget that: Us! Us! Us!”

Sanders supporters, with and without previous organizing experience, gathered this weekend in libraries, living rooms, restaurants, and classrooms. They wore Bernie shirts, made Bernie signs, Bernie cookies, and Bernie cakes. Some groups even received a surprise phone call from the candidate himself.

In Oakland, Bay Area Muslims for Bernie held its party at a local Palestinian street food restaurant. A group of around 25 people, which included supporters from Egypt, Iran, Morocco, Yemen, Afghanistan, and around the United States, joined the organizing kickoff. “We even had refugees attend who cannot vote but still wanted to support and promote Bernie’s message,” Reyhaneh Rajabzadeh told The Intercept in a message.",,,,,
Silicon Valley-Funded Privacy Think Tanks Fight in D.C. to Unravel State-Level Consumer Privacy Protections,"AFTER YEARS OF ignoring the issue, lawmakers on Capitol Hill are suddenly engaged in a furious fight over enacting national legislation to establish basic online privacy rights for consumers. As with the crafting of much legislation dealing with complicated issues, legislators are relying on experts to help codify the consumer protections.

In a twist that is all too familiar in Washington, D.C., however, many of the groups that have positioned themselves as expert voices on consumer privacy are pushing for a bill that hews closely to tech industry interests. Lawmakers who are famously ignorant on technology issues are hearing largely from an army of industry lobbyists and experts funded by social media companies, online platforms, data brokers, advertisers, and telecommunication giants — the very same corporate interests that profit from the collection and sale of internet data.

Take the Center for Democracy and Technology, one of the most prominent privacy-centered Beltway think tanks. The group is considered to be well-respected among congressional staffers, routinely testifies before committees on privacy legislation, and is a prime mover in the national online privacy bill discussion.

Late last year, the organization circulated draft federal privacy legislation that would nullify major state-level regulations. In March, when the Senate Judiciary Committee held its first hearing of the session on how to formulate a federal consumer privacy standard, the center’s Privacy and Data Project Director Michelle Richardson testified.

The Center for Democracy and Technology is also awash in corporate money from the tech sector. Amazon, Verizon, and Google are among the corporate donors that each provide over $200,000 to the group. AT&T, Uber, and Twitter are also major donors.

Last Wednesday, the group hosted its annual gala, known as “Tech Prom,” which brought together lobbyists and government affairs officials from leading Silicon Valley and telecom firms. Facebook, Google, Amazon, and Microsoft purchased tables at the event and served as sponsors, a privilege that came in exchange for a $35,000 donation to the center.",,,,,
Cameras Linked to Chinese Government Stir Alarm in U.K. Parliament,"IT IS A Chinese state-owned company that is implicated in disturbing human rights violations. But that has not stopped Hikvision from gaining a major foothold in the United Kingdom. Through a network of corporate partners, the Hangzhou-based security firm has supplied its surveillance cameras for use on the British parliamentary estate, as well as to police, hospitals, schools, and universities throughout the country, according to sources and procurement records.

Hikvision, whose technology the U.S. government recently banned federal agencies from purchasing, is generating millions of dollars in annual revenue selling its technology to British companies and organizations. At the same time, it has been helping to establish an oppressive surveillance state in the Xinjiang region of China, where the Uighur ethnic minorities have been held in secret internment camps.

British politicians are raising concerns about the technology — and are calling for an embargo on further purchases of it — on the grounds that Hikvision is complicit in human rights abuses and also represents a national security risk, as it is feared that Chinese intelligence agencies could potentially tap into camera feeds in sensitive locations. Some of the company’s cameras record audio and are connected to the internet, meaning that they can be monitored from anywhere in the world.

In January, the cameras were scheduled to be installed inside London’s Portcullis House, according to Adm. Lord Alan West, a member of the U.K. Parliament’s second chamber, the House of Lords. Portcullis House is an office building in Westminster used by more than 200 members of Parliament and 400 of their staff to carry out their daily work, which routinely involves discussion of confidential national security, economic, and foreign policy issues.

West told The Intercept that someone who was “concerned that this was happening” tipped him off about a contract that would equip the building with Hikvision surveillance equipment. He said he subsequently complained about the matter to authorities within the parliamentary estate.

“It seems to me to be extremely worrying — it’s rather like being able to get a Mata Hari into each office,” he said, referring to the Dutch exotic dancer who was accused of spying for Germany during World War I. “Are we sure we are happy with Chinese CCTV in members of Parliament’s offices, listening to what they say to their constituents, listening to what ministers say, filming the documents on their desks?”

A Parliament spokesperson denied the existence of a contract involving Hikvision and said that there was no plan to “install any additional cameras at Portcullis House this year.”

A source familiar with security on parts of the parliamentary estate, which, in addition to Portcullis House, consists of the Palace of Westminster, the Norman Shaw buildings, and Big Ben, told The Intercept that Hikvision’s equipment had “absolutely” been used there in the past. The source said they could not confirm whether any Hikvision cameras were currently active, as there are hundreds of cameras fitted both in and around all parliamentary and government buildings in the area.",,,,,
"Facebook’s Ad Algorithm Is a Race and Gender Stereotyping Machine, New Study Suggests","HOW EXACTLY FACEBOOK decides who sees what is one of the great pieces of forbidden knowledge in the information age, hidden away behind nondisclosure agreements, trade secrecy law, and a general culture of opacity. New research from experts at Northeastern University, the University of Southern California, and the public-interest advocacy group Upturn doesn’t reveal how Facebook’s targeting algorithms work, but does show an alarming outcome: They appear to deliver certain ads, including for housing and employment, in a way that aligns with race and gender stereotypes — even when advertisers ask for the ads to be exposed a broad, inclusive audience.

There are two basic steps to advertising on Facebook. The first is taken by advertisers when they choose certain segments of the Facebook population to target: Canadian women who enjoy badminton and Weezer, lacrosse dads over 40 with an interest in white genocide, and so forth. The second is taken by Facebook, when it makes an ad show up on certain peoples’ screens, reconciling the advertiser’s targeting preferences with the flow of people through Facebook’s apps and webpages in a given period of time. Advertisers can see which audiences ended up viewing the ad, but are never permitted to know the underlying logic of how those precise audiences were selected.

The new research focuses on the second step of advertising on Facebook, the process of ad delivery, rather than on ad targeting. Essentially, the researchers created ads without any demographic target at all and watched where Facebook placed them. The results, said the researchers, were disturbing:

Critically, we observe significant skew in delivery along gender and racial lines for “real” ads for employment and housing opportunities despite neutral targeting parameters. Our results demonstrate previously unknown mechanisms that can lead to potentially discriminatory ad delivery, even when advertisers set their targeting parameters to be highly inclusive.

Rather than targeting a demographic niche, the researchers requested only that their ads reach Facebook users in the United States, leaving matters of ethnicity and gender entirely up to Facebook’s black box. As Facebook itself tells potential advertisers, “We try to show people the ads that are most pertinent to them.” What exactly does the company’s ad-targeting black box, left to its own devices, consider pertinent? Are Facebook’s ad-serving algorithms as prone to bias like so many others? The answer will not surprise you.

For one portion of the study, researchers ran ads for a wide variety of job listings in North Carolina, from janitors to nurses to lawyers, without any further demographic targeting options. With all other things being equal, the study found that “Facebook delivered our ads for jobs in the lumber industry to an audience that was 72% white and 90% men, supermarket cashier positions to an audience of 85% women, and jobs with taxi companies to a 75% black audience even though the target audience we specified was identical for all ads.” Ad displays for “artificial intelligence developer” listings also skewed white, while listings for secretarial work overwhelmingly found their way to female Facebook users.

Although Facebook doesn’t permit advertisers to view the racial composition of an ad’s viewers, the researchers said they were able to confidently infer these numbers by cross-referencing the indicators Facebook does provide, particularly regions where users live, which in some states can be cross-referenced with race data held in voter registration records.

In the case of housing ads — an area Facebook has already shown in the past has potential for discriminatory abuse — the results were also heavily skewed along racial lines. “In our experiments,” the researchers wrote, “Facebook delivered our broadly targeted ads for houses for sale to audiences of 75% white users, when ads for rentals were shown to a more demographically balanced audience.” In other cases, the study found that “Facebook delivered some of our housing ads to audiences of over 85% white users while they delivered other ads to over 65% Black users (depending on the content of the ad) even though the ads were targeted identically.”

Facebook appeared to algorithmically reinforce stereotypes even in the case of simple, rather boring stock photos, indicating that not only does Facebook automatically scan and classify images on the site as being more “relevant” to men or women, but changes who sees the ad based on whether it includes a picture of, say, a football or a flower. The research took a selection of stereotypically gendered images — a military scene and an MMA fight on the stereotypically male side, a rose as stereotypically female — and altered them so that they would be invisible to the human eye (marking the images as transparent “alpha” channels, in technical terms). They then used these invisible pictures in ads run without any gender-based targeting, yet found Facebook, presumably after analyzing the images with software, made retrograde, gender-based decisions on how to deliver them: Ads with stereotypical macho images were shown mostly to men, even though the men had no idea what they were looking at. The study concluded that “Facebook has an automated image classification mechanism in place that is used to steer different ads towards different subsets of the user population.” In other words, the bias was on Facebook’s end, not in the eye of the beholder.",,,,,
Lyft and Other Gig Economy Giants Cash In With IPOs Before Labor Laws Catch Up With Them,"HOW EXACTLY FACEBOOK decides who sees what is one of the great pieces of forbidden knowledge in the information age, hidden away behind nondisclosure agreements, trade secrecy law, and a general culture of opacity. New research from experts at Northeastern University, the University of Southern California, and the public-interest advocacy group Upturn doesn’t reveal how Facebook’s targeting algorithms work, but does show an alarming outcome: They appear to deliver certain ads, including for housing and employment, in a way that aligns with race and gender stereotypes — even when advertisers ask for the ads to be exposed a broad, inclusive audience.

There are two basic steps to advertising on Facebook. The first is taken by advertisers when they choose certain segments of the Facebook population to target: Canadian women who enjoy badminton and Weezer, lacrosse dads over 40 with an interest in white genocide, and so forth. The second is taken by Facebook, when it makes an ad show up on certain peoples’ screens, reconciling the advertiser’s targeting preferences with the flow of people through Facebook’s apps and webpages in a given period of time. Advertisers can see which audiences ended up viewing the ad, but are never permitted to know the underlying logic of how those precise audiences were selected.

The new research focuses on the second step of advertising on Facebook, the process of ad delivery, rather than on ad targeting. Essentially, the researchers created ads without any demographic target at all and watched where Facebook placed them. The results, said the researchers, were disturbing:

Critically, we observe significant skew in delivery along gender and racial lines for “real” ads for employment and housing opportunities despite neutral targeting parameters. Our results demonstrate previously unknown mechanisms that can lead to potentially discriminatory ad delivery, even when advertisers set their targeting parameters to be highly inclusive.

Rather than targeting a demographic niche, the researchers requested only that their ads reach Facebook users in the United States, leaving matters of ethnicity and gender entirely up to Facebook’s black box. As Facebook itself tells potential advertisers, “We try to show people the ads that are most pertinent to them.” What exactly does the company’s ad-targeting black box, left to its own devices, consider pertinent? Are Facebook’s ad-serving algorithms as prone to bias like so many others? The answer will not surprise you.

For one portion of the study, researchers ran ads for a wide variety of job listings in North Carolina, from janitors to nurses to lawyers, without any further demographic targeting options. With all other things being equal, the study found that “Facebook delivered our ads for jobs in the lumber industry to an audience that was 72% white and 90% men, supermarket cashier positions to an audience of 85% women, and jobs with taxi companies to a 75% black audience even though the target audience we specified was identical for all ads.” Ad displays for “artificial intelligence developer” listings also skewed white, while listings for secretarial work overwhelmingly found their way to female Facebook users.

Although Facebook doesn’t permit advertisers to view the racial composition of an ad’s viewers, the researchers said they were able to confidently infer these numbers by cross-referencing the indicators Facebook does provide, particularly regions where users live, which in some states can be cross-referenced with race data held in voter registration records.

In the case of housing ads — an area Facebook has already shown in the past has potential for discriminatory abuse — the results were also heavily skewed along racial lines. “In our experiments,” the researchers wrote, “Facebook delivered our broadly targeted ads for houses for sale to audiences of 75% white users, when ads for rentals were shown to a more demographically balanced audience.” In other cases, the study found that “Facebook delivered some of our housing ads to audiences of over 85% white users while they delivered other ads to over 65% Black users (depending on the content of the ad) even though the ads were targeted identically.”

Facebook appeared to algorithmically reinforce stereotypes even in the case of simple, rather boring stock photos, indicating that not only does Facebook automatically scan and classify images on the site as being more “relevant” to men or women, but changes who sees the ad based on whether it includes a picture of, say, a football or a flower. The research took a selection of stereotypically gendered images — a military scene and an MMA fight on the stereotypically male side, a rose as stereotypically female — and altered them so that they would be invisible to the human eye (marking the images as transparent “alpha” channels, in technical terms). They then used these invisible pictures in ads run without any gender-based targeting, yet found Facebook, presumably after analyzing the images with software, made retrograde, gender-based decisions on how to deliver them: Ads with stereotypical macho images were shown mostly to men, even though the men had no idea what they were looking at. The study concluded that “Facebook has an automated image classification mechanism in place that is used to steer different ads towards different subsets of the user population.” In other words, the bias was on Facebook’s end, not in the eye of the beholder.",,,,,
How to Think About Breaking Up Big Tech,"SEN. ELIZABETH WARREN’S plan to break up tech giants Amazon, Google, Facebook, and Apple has given concentrated corporate power its most prominent political platform since the 1912 presidential election — and we’re still nearly a year away from the first round of primary voting. This tracks with the rising awareness of the corrosiveness of monopoly power generally and those tech giants specifically.

Whether such policy boldness means anything in a brand-obsessed political landscape will be determined when ballots are cast. But it is undeniably driving a policy discussion that the next Democratic presidential nominee, no matter who it is, will likely take up. In that context, the debate over Warren’s plan is critical, as it prefigures the trajectory of each and every challenge to corporate dominance.

First, many critiques will come from those with a direct stake in the outcome — in this case, Big Tech-funded individuals or organizations, which are so ubiquitous as to create an echo chamber. Second, the critiques will highlight the “radical” nature of the changes, setting them at odds with American history, even though Warren’s central proposal — to structurally separate business lines in an effort to eliminate anti-competitive conduct and foster competition — has a century-old pedigree. And third, we’ll be assured that the cure is worse than the disease, that Warren’s ideas would destroy everything from online shopping to the smartphone, a perspective that relies on deliberate misinterpretation.

This roadmap for discrediting policy solutions that confront power should be easy enough to spot by now, and will be employed long into the future. So it’s worth breaking down how it works.

The Manufacturing of Dissent

“The issue is not the size and current market dominance of these [tech] companies,” wrote the American Enterprise Institute’s Michael Strain for Bloomberg, in response to the Warren plan. “If anything, politicians should be celebrating these companies as crown jewels of the U.S. economy.”

Strain’s employer, AEI, is funded in part by Google, according to the company’s transparency page. This is not noted in Strain’s Bloomberg op-ed. But AEI and its writers have done several critical pieces about Warren’s proposal, as well a California privacy regulation that also imposes stricter rules on Big Tech. All of these opinion articles indirectly benefit one of AEI’s donors.

The episode points to a significant trend of writers and scholars opining on the Warren plan while conflicted by the overwhelming amounts of Big Tech cash that have infested Washington. Google’s list of organizations to whom it has donated is massive, and combined with Facebook and Amazon’s dominance of Washington, it’s hard to find anyone with a critical eye toward Big Tech regulation who doesn’t have something to disclose.

Rich Lowry of National Review unleashed a pack of industry talking points to explain how Big Tech “helps create a strong American society.” National Review takes Google money. Here’s a similar sentiment dragging the Warren plan on the pages of National Review, from a senior fellow at the Competitive Enterprise Institute, which also takes Google money. The American Action Forum seems to dislike the Warren plan; the group, well, takes Google money.

Geoffrey Manne and Alec Stapp condemn Warren for “wanting to turn the Internet into a sewer.” Manne’s organization, the International Center for Law and Economics, has taken a boatload of Google money; as of 2015, he had contributed to at least eight white papers commissioned or funded by Google that endorsed Google’s policy positions, in addition to being a frequent pro-Google commentator in news articles and congressional testimony. Stapp, before hooking up with Manne at ICLE, worked at the Mercatus Center at George Mason University, another recipient of Google funds. A former Manne co-author, Joshua Wright, worked at George Mason University and has been periodically on and off the Google payroll in between government work.

Manne and Stapp’s piece got the pile-on treatment on Twitter from representatives of the Google-funded Cato Institute and Niskanen Center; Stapp previously worked at Niskanen. Several venture capitalists who currently rely on Big Tech for exit strategies for their companies also gave the thumbs-up to the piece.

The Computer and Communications Industry Association, a trade group that includes Amazon, Facebook, and Google among its members, uses a subsidiary named Springboard to hurl critiques at regulatory tech policies. In addition to the aforementioned articles from AEI and National Review, Springboard points to the opinions of a partner at Andreessen Horowitz, an early investor in Facebook, and the CCIA’s own vice president for Law an Policy — which amounts to CCIA linking to itself as outside confirmation of its beliefs.

These linkages are virtually endless and show an incestuous network of academics, think-tankers, advocacy organizations, and trade groups, all of which happen to agree on every issue important to Big Tech. The money supports extending the prominence and megaphone of these organizations, and with nearly unlimited pocketbooks, it creates the impression of a tsunami of support for the industry.

A “Radical” Idea That’s Been Around for Over a Century

The core of Warren’s plan, which for now is just a proposal on Medium rather than legislation, involves what is known as “structural separation.” Companies with over $25 billion in annual global revenue that operate platforms — connectors between people, people and advertisers, or people and merchants — would not be allowed to both own the platform and also participate as a seller on that platform. The classic example would be Amazon’s marketplace, where Amazon also operates its own line of Amazon Basics, competing with its third-party sellers. Google’s ad exchange also competes on Google with ad tech companies, and would need to be spun off. The same would go for Google’s local search, which routinely deprioritizes recommendation sites like Yelp.

The idea is that these entities get preferential treatment from the platform they own, giving Basics, Google ad tech, and Google Search an unfair advantage and extending the platform’s dominance. Only the biggest companies would have to structurally separate; smaller platforms would still have to meet a standard of fair, reasonable, and nondiscriminatory treatment for participants on the platform and its users.

This forced divestiture of tech platforms’ other business lines has been described as radical. Manne and Stapp claim it will turn the internet into your sewer service — mainly because Warren uses the word “utility” to describe regulated platforms.

Jeff Bezos didn’t come up with the idea of owning a marketplace and using it to sell your own stuff at an unfair advantage against rivals. Reading Railroad, for example, became the largest company in the world by owning the rails that carried anthracite coal, as well as the coal mines along the route. Rival coal producers that wanted to use the lines got less favorable rates, fell behind, and got swallowed up by Reading Railroad.

Congress put a stop to it in 1906 by adopting the Hepburn Act, which prevented the railroads from carrying products that they owned. This forced the Reading Railroad to divest the P&R Coal and Iron Company, the subsidiary that owned the coal mines. Warren is merely following a long history of structural separation that began when Teddy Roosevelt was president.

Theater owners were not allowed to also produce and distribute films after the Supreme Court’s Paramount decision in 1948. Television networks were prevented from owning the programming they ran in prime time, under the Financial Interest and Syndication, or “fin-syn,” rules imposed by the Federal Communications Commission in 1970. In telecom, AT&T was heavily circumscribed and restricted to common-carrier telephone service, banning the company from capitalizing on innovations from Bell Labs and forcing compulsory licensing of those patents in 1956, which created the modern electronics industry. Banks were structurally separated between investment and deposit-taking commercial lines after the Glass-Steagall reforms. Rep. David Cicilline, D-R.I., the chair of the House Judiciary’s antitrust subcommittee, has analogized a structural separation in tech as a Glass-Steagall type of rule.

These structural separations have widespread goals: diversity, financial stability, decentralization of power, and innovation. “We owe the internet to structural separation,” said Harold Feld, a senior vice president with Public Knowledge, referring to the Carterfone decisions, where the FCC allowed people to connect their own devices, like a modem, to the telephone network. “Clearly this has a long and successful history in telecom.”

Some of these restrictions, like those on banks or television stations, have been dismantled. And there are cases of companies selling products in a store while also owning the store: Kirkland products at Costco are ubiquitous, for example. But as Lina Khan, scholar and staffer for Cicilline’s antitrust subcommittee, has pointed out, the key question is whether the platform, be it brick and mortar or digital, is creating a bottleneck by privileging its own products over rivals. And there’s a lot of evidence that Amazon in particular does just that, reacting to high-selling products by creating a generic version, and down-ranking the competitor in its search. Because half of all e-commerce is sold on Amazon, competitors have few alternatives but to sell in what feels like a rigged marketplace.

India has already instituted a Warren-like rule to prevent e-commerce platforms from selling their own products on the platform. “We should go back and understand the wisdom of that kind of separation,” said Peter Carstensen, a professor emeritus at the University of Wisconsin Law School. “We would never want the interstate highway system to be owned by Walmart. It simplifies the market functions if you separate them out.”

Another benefit to structural separation is the relative ease of regulation. Instead of well-paid economists fighting it out over what constitutes anti-competitive conduct or restraint of trade, large companies simply can’t compete with rivals on their own platform, because of the threat of market power.

The Warren plan sets a rather arbitrary number of $25 billion in annual revenue as the dividing line for that power, a kind of substitute for the technocratic determination. This has angered critics: Andy Kessler at the Wall Street Journal denied that antitrust law has anything to do with bigness.

The idea that John Sherman, author of the Sherman Antitrust Act, was not concerned with bigness would come as news to Sherman, who once said, “If we will not endure a king as a political power, we should not endure a king over the production, transportation, and sale of any of the necessaries of life.” Warren’s campaign sees the $25 billion figure as a clean way to assist regulators with pinpointing market dominance. “It has the benefit of a clear rule,” said one senior campaign adviser, who was not authorized to speak on the record. “We should presume if a company with over $25 billion in revenue is operating a marketplace, it has power and leverage.”

While agnostic on the specific dividing number, Feld gave Warren’s team credit “for trying to come up with something that makes sense.” Others are not as thrilled about it. But their arguments often misconstrue the Warren plan.

Assuming the Worst

Ben Thompson, a former Apple and Microsoft analyst who writes about the business of technology, had one of the sharpest critiques of the Warren proposal, and it starts with denying Warren’s claim on the history of technology. Warren has credited the Microsoft trial for creating space for the modern tech giants to emerge, something Thompson mocks. “Bing was not even launched until 2009, eight years after the Microsoft case was settled. MSN Search, its predecessor, did launch in 1998, but with licensed search results from Inktomi and AltaVista; Microsoft didn’t launch its own web crawler until 2005.”

This view neglects the politics of the U.S. trial against Microsoft, which put a dominant company under pressure and wary of extending that dominance into the then-emerging web services arena. As Gary Reback, who represented Netscape against Microsoft in the 1990s, has often said, including to me in a 2017 interview, “The trial is the remedy.” By exposing Microsoft’s machinations to the nation, it made the company gun-shy to choke off competition, Reback argues.

“The only way to get to Google was the Microsoft browser,” he said. “Microsoft could have put up a big red sign saying this site is unsafe. It could have killed Google in the cradle, but didn’t. The reason why, and this is from Microsoft people, is they had this public trial. It wasn’t worth it as a company.”

Feld concurred that Microsoft’s behavior changed after the public spotlight of the trial, and the kind of aggressive actions to shut down competitors largely stopped. You can apply this to IBM’s antitrust issues in the 1970s and ’80s opening space for Apple, and AOL’s forced interoperability of Instant Messenger in 2001 giving room to social media. “Big companies are sensitive to this stuff; after they’ve been burned, they do generally play it safe,” Feld said, noting that big cable hasn’t had such a spotlight and they managed to crush TiVo swiftly and completely. So while Thompson focuses on specific Microsoft business decisions, he ignores the political context.

Thompson also warns that applying the structural separation standard to Apple, as Warren confirmed in an interview at South by Southwest, would lead to smartphones shipped without any applications. “Was Apple breaking the law when they shipped the first iPhone with only first-party apps?” Thompson asks. “At what point did delivering an acceptable consumer experience out-of-the-box cross the line into abusing a dominant position? This argument may make sense in theory but it makes zero sense in reality.”

This argument also has zero bearing on what Warren’s talking about. Whether Apple is unfairly tying or bundling its own apps onto its phones at purchase is a question for existing antitrust laws — it was the question in the Microsoft case, in fact. “The ordinary rules apply in that case,” said the senior Warren adviser. “The key thing we’re talking about is the marketplace.”

Contrary to what critics have claimed, Apple would not have to divest from the App Store completely under Warren’s plan, nor would the security benefits of Apple managing what goes onto its phone wither away. Apple would merely be disallowed from selling its own apps next to competing ones. This would hardly destroy Apple, largely a phone and hardware manufacturer and not primarily an app-maker. It would allow competition on the platform.

Apple does have a legitimate antitrust problem with the App Store, as Thompson acknowledges. Spotify has complained to the European Union that Apple takes a 30 percent cut from all revenues from its iPhone app, while preventing it from emailing users directly or allowing upgrades. This indirectly benefits Apple Music, Spotify says. Apple has accused Spotify of using “misleading rhetoric” in its complaint.

Spotify wants changes to Apple’s conduct on the App Store — which is not only fair game for traditional antitrust that can identify anti-competitive impositions of market power, but is also part of Warren’s plan, which mandates fair and nondiscriminatory treatment to marketplace participants. And it shows how Warren is highlighting a consumer welfare issue: If Spotify has to absorb a 30 percent transfer of revenues to Apple for use of its iPhone customers, it likely has to raise prices, and it cannot offer services like upgrades directly.",,,,,
Google Dragonfly,"SEN. ELIZABETH WARREN’S plan to break up tech giants Amazon, Google, Facebook, and Apple has given concentrated corporate power its most prominent political platform since the 1912 presidential election — and we’re still nearly a year away from the first round of primary voting. This tracks with the rising awareness of the corrosiveness of monopoly power generally and those tech giants specifically.

Whether such policy boldness means anything in a brand-obsessed political landscape will be determined when ballots are cast. But it is undeniably driving a policy discussion that the next Democratic presidential nominee, no matter who it is, will likely take up. In that context, the debate over Warren’s plan is critical, as it prefigures the trajectory of each and every challenge to corporate dominance.

First, many critiques will come from those with a direct stake in the outcome — in this case, Big Tech-funded individuals or organizations, which are so ubiquitous as to create an echo chamber. Second, the critiques will highlight the “radical” nature of the changes, setting them at odds with American history, even though Warren’s central proposal — to structurally separate business lines in an effort to eliminate anti-competitive conduct and foster competition — has a century-old pedigree. And third, we’ll be assured that the cure is worse than the disease, that Warren’s ideas would destroy everything from online shopping to the smartphone, a perspective that relies on deliberate misinterpretation.

This roadmap for discrediting policy solutions that confront power should be easy enough to spot by now, and will be employed long into the future. So it’s worth breaking down how it works.

The Manufacturing of Dissent

“The issue is not the size and current market dominance of these [tech] companies,” wrote the American Enterprise Institute’s Michael Strain for Bloomberg, in response to the Warren plan. “If anything, politicians should be celebrating these companies as crown jewels of the U.S. economy.”

Strain’s employer, AEI, is funded in part by Google, according to the company’s transparency page. This is not noted in Strain’s Bloomberg op-ed. But AEI and its writers have done several critical pieces about Warren’s proposal, as well a California privacy regulation that also imposes stricter rules on Big Tech. All of these opinion articles indirectly benefit one of AEI’s donors.

The episode points to a significant trend of writers and scholars opining on the Warren plan while conflicted by the overwhelming amounts of Big Tech cash that have infested Washington. Google’s list of organizations to whom it has donated is massive, and combined with Facebook and Amazon’s dominance of Washington, it’s hard to find anyone with a critical eye toward Big Tech regulation who doesn’t have something to disclose.

Rich Lowry of National Review unleashed a pack of industry talking points to explain how Big Tech “helps create a strong American society.” National Review takes Google money. Here’s a similar sentiment dragging the Warren plan on the pages of National Review, from a senior fellow at the Competitive Enterprise Institute, which also takes Google money. The American Action Forum seems to dislike the Warren plan; the group, well, takes Google money.

Geoffrey Manne and Alec Stapp condemn Warren for “wanting to turn the Internet into a sewer.” Manne’s organization, the International Center for Law and Economics, has taken a boatload of Google money; as of 2015, he had contributed to at least eight white papers commissioned or funded by Google that endorsed Google’s policy positions, in addition to being a frequent pro-Google commentator in news articles and congressional testimony. Stapp, before hooking up with Manne at ICLE, worked at the Mercatus Center at George Mason University, another recipient of Google funds. A former Manne co-author, Joshua Wright, worked at George Mason University and has been periodically on and off the Google payroll in between government work.

Manne and Stapp’s piece got the pile-on treatment on Twitter from representatives of the Google-funded Cato Institute and Niskanen Center; Stapp previously worked at Niskanen. Several venture capitalists who currently rely on Big Tech for exit strategies for their companies also gave the thumbs-up to the piece.

The Computer and Communications Industry Association, a trade group that includes Amazon, Facebook, and Google among its members, uses a subsidiary named Springboard to hurl critiques at regulatory tech policies. In addition to the aforementioned articles from AEI and National Review, Springboard points to the opinions of a partner at Andreessen Horowitz, an early investor in Facebook, and the CCIA’s own vice president for Law an Policy — which amounts to CCIA linking to itself as outside confirmation of its beliefs.

These linkages are virtually endless and show an incestuous network of academics, think-tankers, advocacy organizations, and trade groups, all of which happen to agree on every issue important to Big Tech. The money supports extending the prominence and megaphone of these organizations, and with nearly unlimited pocketbooks, it creates the impression of a tsunami of support for the industry.

A “Radical” Idea That’s Been Around for Over a Century

The core of Warren’s plan, which for now is just a proposal on Medium rather than legislation, involves what is known as “structural separation.” Companies with over $25 billion in annual global revenue that operate platforms — connectors between people, people and advertisers, or people and merchants — would not be allowed to both own the platform and also participate as a seller on that platform. The classic example would be Amazon’s marketplace, where Amazon also operates its own line of Amazon Basics, competing with its third-party sellers. Google’s ad exchange also competes on Google with ad tech companies, and would need to be spun off. The same would go for Google’s local search, which routinely deprioritizes recommendation sites like Yelp.

The idea is that these entities get preferential treatment from the platform they own, giving Basics, Google ad tech, and Google Search an unfair advantage and extending the platform’s dominance. Only the biggest companies would have to structurally separate; smaller platforms would still have to meet a standard of fair, reasonable, and nondiscriminatory treatment for participants on the platform and its users.

This forced divestiture of tech platforms’ other business lines has been described as radical. Manne and Stapp claim it will turn the internet into your sewer service — mainly because Warren uses the word “utility” to describe regulated platforms.

Jeff Bezos didn’t come up with the idea of owning a marketplace and using it to sell your own stuff at an unfair advantage against rivals. Reading Railroad, for example, became the largest company in the world by owning the rails that carried anthracite coal, as well as the coal mines along the route. Rival coal producers that wanted to use the lines got less favorable rates, fell behind, and got swallowed up by Reading Railroad.

Congress put a stop to it in 1906 by adopting the Hepburn Act, which prevented the railroads from carrying products that they owned. This forced the Reading Railroad to divest the P&R Coal and Iron Company, the subsidiary that owned the coal mines. Warren is merely following a long history of structural separation that began when Teddy Roosevelt was president.

Theater owners were not allowed to also produce and distribute films after the Supreme Court’s Paramount decision in 1948. Television networks were prevented from owning the programming they ran in prime time, under the Financial Interest and Syndication, or “fin-syn,” rules imposed by the Federal Communications Commission in 1970. In telecom, AT&T was heavily circumscribed and restricted to common-carrier telephone service, banning the company from capitalizing on innovations from Bell Labs and forcing compulsory licensing of those patents in 1956, which created the modern electronics industry. Banks were structurally separated between investment and deposit-taking commercial lines after the Glass-Steagall reforms. Rep. David Cicilline, D-R.I., the chair of the House Judiciary’s antitrust subcommittee, has analogized a structural separation in tech as a Glass-Steagall type of rule.

These structural separations have widespread goals: diversity, financial stability, decentralization of power, and innovation. “We owe the internet to structural separation,” said Harold Feld, a senior vice president with Public Knowledge, referring to the Carterfone decisions, where the FCC allowed people to connect their own devices, like a modem, to the telephone network. “Clearly this has a long and successful history in telecom.”

Some of these restrictions, like those on banks or television stations, have been dismantled. And there are cases of companies selling products in a store while also owning the store: Kirkland products at Costco are ubiquitous, for example. But as Lina Khan, scholar and staffer for Cicilline’s antitrust subcommittee, has pointed out, the key question is whether the platform, be it brick and mortar or digital, is creating a bottleneck by privileging its own products over rivals. And there’s a lot of evidence that Amazon in particular does just that, reacting to high-selling products by creating a generic version, and down-ranking the competitor in its search. Because half of all e-commerce is sold on Amazon, competitors have few alternatives but to sell in what feels like a rigged marketplace.

India has already instituted a Warren-like rule to prevent e-commerce platforms from selling their own products on the platform. “We should go back and understand the wisdom of that kind of separation,” said Peter Carstensen, a professor emeritus at the University of Wisconsin Law School. “We would never want the interstate highway system to be owned by Walmart. It simplifies the market functions if you separate them out.”

Another benefit to structural separation is the relative ease of regulation. Instead of well-paid economists fighting it out over what constitutes anti-competitive conduct or restraint of trade, large companies simply can’t compete with rivals on their own platform, because of the threat of market power.

The Warren plan sets a rather arbitrary number of $25 billion in annual revenue as the dividing line for that power, a kind of substitute for the technocratic determination. This has angered critics: Andy Kessler at the Wall Street Journal denied that antitrust law has anything to do with bigness.

The idea that John Sherman, author of the Sherman Antitrust Act, was not concerned with bigness would come as news to Sherman, who once said, “If we will not endure a king as a political power, we should not endure a king over the production, transportation, and sale of any of the necessaries of life.” Warren’s campaign sees the $25 billion figure as a clean way to assist regulators with pinpointing market dominance. “It has the benefit of a clear rule,” said one senior campaign adviser, who was not authorized to speak on the record. “We should presume if a company with over $25 billion in revenue is operating a marketplace, it has power and leverage.”

While agnostic on the specific dividing number, Feld gave Warren’s team credit “for trying to come up with something that makes sense.” Others are not as thrilled about it. But their arguments often misconstrue the Warren plan.

Assuming the Worst

Ben Thompson, a former Apple and Microsoft analyst who writes about the business of technology, had one of the sharpest critiques of the Warren proposal, and it starts with denying Warren’s claim on the history of technology. Warren has credited the Microsoft trial for creating space for the modern tech giants to emerge, something Thompson mocks. “Bing was not even launched until 2009, eight years after the Microsoft case was settled. MSN Search, its predecessor, did launch in 1998, but with licensed search results from Inktomi and AltaVista; Microsoft didn’t launch its own web crawler until 2005.”

This view neglects the politics of the U.S. trial against Microsoft, which put a dominant company under pressure and wary of extending that dominance into the then-emerging web services arena. As Gary Reback, who represented Netscape against Microsoft in the 1990s, has often said, including to me in a 2017 interview, “The trial is the remedy.” By exposing Microsoft’s machinations to the nation, it made the company gun-shy to choke off competition, Reback argues.

“The only way to get to Google was the Microsoft browser,” he said. “Microsoft could have put up a big red sign saying this site is unsafe. It could have killed Google in the cradle, but didn’t. The reason why, and this is from Microsoft people, is they had this public trial. It wasn’t worth it as a company.”

Feld concurred that Microsoft’s behavior changed after the public spotlight of the trial, and the kind of aggressive actions to shut down competitors largely stopped. You can apply this to IBM’s antitrust issues in the 1970s and ’80s opening space for Apple, and AOL’s forced interoperability of Instant Messenger in 2001 giving room to social media. “Big companies are sensitive to this stuff; after they’ve been burned, they do generally play it safe,” Feld said, noting that big cable hasn’t had such a spotlight and they managed to crush TiVo swiftly and completely. So while Thompson focuses on specific Microsoft business decisions, he ignores the political context.

Thompson also warns that applying the structural separation standard to Apple, as Warren confirmed in an interview at South by Southwest, would lead to smartphones shipped without any applications. “Was Apple breaking the law when they shipped the first iPhone with only first-party apps?” Thompson asks. “At what point did delivering an acceptable consumer experience out-of-the-box cross the line into abusing a dominant position? This argument may make sense in theory but it makes zero sense in reality.”

This argument also has zero bearing on what Warren’s talking about. Whether Apple is unfairly tying or bundling its own apps onto its phones at purchase is a question for existing antitrust laws — it was the question in the Microsoft case, in fact. “The ordinary rules apply in that case,” said the senior Warren adviser. “The key thing we’re talking about is the marketplace.”

Contrary to what critics have claimed, Apple would not have to divest from the App Store completely under Warren’s plan, nor would the security benefits of Apple managing what goes onto its phone wither away. Apple would merely be disallowed from selling its own apps next to competing ones. This would hardly destroy Apple, largely a phone and hardware manufacturer and not primarily an app-maker. It would allow competition on the platform.

Apple does have a legitimate antitrust problem with the App Store, as Thompson acknowledges. Spotify has complained to the European Union that Apple takes a 30 percent cut from all revenues from its iPhone app, while preventing it from emailing users directly or allowing upgrades. This indirectly benefits Apple Music, Spotify says. Apple has accused Spotify of using “misleading rhetoric” in its complaint.

Spotify wants changes to Apple’s conduct on the App Store — which is not only fair game for traditional antitrust that can identify anti-competitive impositions of market power, but is also part of Warren’s plan, which mandates fair and nondiscriminatory treatment to marketplace participants. And it shows how Warren is highlighting a consumer welfare issue: If Spotify has to absorb a 30 percent transfer of revenues to Apple for use of its iPhone customers, it likely has to raise prices, and it cannot offer services like upgrades directly.",,,,,
Pentagon Says All of Google’s Work on Drones Is Exempt From the Freedom of Information Act,"IN SEPTEMBER 2017, Aileen Black wrote an email to her colleagues at Google. Black, who led sales to the U.S. government, worried that details of the company’s work to help the military guide lethal drones would become public through the Freedom of Information Act. “We will call tomorrow to reinforce the need to keep Google under the radar,” Black wrote.

According to a Pentagon memo signed last year, however, no one at Google needed worry: All 5,000 pages of documents about Google’s work on the drone effort, known as Project Maven, are barred from public disclosure, because they constitute “critical infrastructure security information.”

One government transparency advocate said the memo is part of a recent wave of federal decisions that  keep sensitive documents secret on that same basis — thus allowing agencies to quickly deny document requests.",,,,,
Inside the Video Surveillance Program IBM Built for Philippine Strongman Rodrigo Duterte,In partnership with,,,,,
Defense Tech Startup Founded by Trump’s Most Prominent Silicon Valley Supporters Wins Secretive Military AI Contract,In partnership with,,,,,
Voices,,,,,,
Voices,,,,,,
Voices,,,,,,
Google Dragonfly,"GOOGLE EMPLOYEES HAVE carried out their own investigation into the company’s plan to launch a censored search engine for China and say they are concerned that development of the project remains ongoing, The Intercept can reveal.

Late last year, bosses moved engineers away from working on the controversial project, known as Dragonfly, and said that there were no current plans to launch it. However, a group of employees at the company was unsatisfied with the lack of information from leadership on the issue — and took matters into their own hands.

The group has identified ongoing work on a batch of code that is associated with the China search engine, according to three Google sources. The development has stoked anger inside Google offices, where many of the company’s 88,000 workforce previously protested against plans to launch the search engine, which was designed to censor broad categories of information associated with human rights, democracy, religion, and peaceful protest.",,,,,
Protests for Black Lives,"AFTER YEARS of backlash over controversial government work, Google technology will be used to aid the Trump administration’s efforts to fortify the U.S.-Mexico border, according to documents related to a federal contract.

In August, Customs and Border Protection accepted a proposal to use Google Cloud technology to facilitate the use of artificial intelligence deployed by the CBP Innovation Team, known as INVNT. Among other projects, INVNT is working on technologies for a new “virtual” wall along the southern border that combines surveillance towers and drones, blanketing an area with sensors to detect unauthorized entry into the country.

In 2018, Google faced internal turmoil over a contract with the Pentagon to deploy AI-enhanced drone image recognition solutions; the capability sparked employee concern that Google was becoming embroiled in work that could be used for lethal purposes and other human rights concerns. In response to the controversy, Google ended its involvement with the initiative, known as Project Maven, and established a new set of AI principles to govern future government contracts.",,,,,
Online Lenders Are Preying on Desperate Borrowers and Could Trigger a New Consumer Financial Crisis,"THE RISE OF the internet-connected home security camera has generally been a boon to police, as owners of these devices can (and frequently do) share footage with cops at the touch of a button. But according to a leaked FBI bulletin, law enforcement has discovered an ironic downside to ubiquitous privatized surveillance: The cameras are alerting residents when police show up to conduct searches.

A November 2019 “technical analysis bulletin” from the FBI provides an overview of “opportunities and challenges” for police from networked security systems like Amazon’s Ring and other “internet of things,” or IoT, devices. Marked unclassified but “law enforcement sensitive” and for official use only, the document was included as part of the BlueLeaks cache of material hacked from the websites of fusion centers and other law enforcement entities.",,,,,
The Coronavirus Crisis,"SURVEILLANCE FIRMS around the world are licking their lips at a once-in-a-lifetime opportunity to cash in on the coronavirus by repositioning one of their most invasive products: the tracking bracelet.

Body monitors are associated with criminality and guilt in the popular imagination, the accessories of Wall Street crooks under house arrest and menace-to-society parolees. Unlike smartphones, de facto tracking devices in their own right, strapped-on trackers are expressly designed to be attached to the body and exist solely to report the user’s whereabouts and interactions to one or more third parties; they don’t play podcasts or tell you how many steps you took that day to sweeten the surveillance.

But a climate of perpetual bio-anxiety has paved the way for broader acceptance of carceral technologies, with a wave of companies trying to sell tracking accessories to business owners eager to reopen under the aegis of responsible social distancing and to governments hoping to keep a closer eye on people under quarantine.",,,,,
"Zoom Meetings Aren’t End-to-End Encrypted, Despite Misleading Marketing",LEIA EM PORTUGUÊS ,,,,,
The Coronavirus Crisis,,,,,,
Election Insecurity,LEIA EM PORTUGUÊS ,,,,,
Year in Review 2019,"AS SEVEN University of Puerto Rico students prepare to face trial in February for participating in a nonviolent protest more than two years ago, documents released to their defense attorneys reveal that Facebook granted the island’s Justice Department access to a trove of private information from student news publications. The department’s sweeping search warrant was part of a hunt for crimes committed by members of the youth anti-austerity movement, and it has raised fears among civil liberties advocates of a return to a period of Puerto Rico’s history when police routinely targeted citizens for surveillance on the basis of their political interests.

It was April 2017, and for weeks, University of Puerto Rico students had been holding a school-wide strike protesting austerity policies that were poised to defund public services across the island to satisfy the government’s creditors. When the university’s governing board gathered on April 27 to discuss $241 million in budget cuts, the students demanded to be let in. The board refused, locking the doors to the building where the meeting was being held. But the students stormed in anyway, pushing past security.

The action unfolded in real time on Facebook, as three student media outlets, Diálogo UPR, Pulso Estudiantil UPR, and Centro de Comunicación Estudiantil, livestreamed the protest. The students surrounded the board members and shut down the meeting, demanding that the board sign a commitment to rejecting the budget cuts. The action, one of many that took place on campus and in the streets, was over within half an hour. A glass door, some furniture, and a lamp were allegedly broken or damaged. No one was injured, and no one was arrested. But the secretary of Puerto Rico’s Justice Department, now-Gov. Wanda Vázquez, pledged to investigate the incident and arrest lawbreakers.

Two weeks later, students who had assumed leadership roles in the wider strike received citations ordering them to appear in court. When they showed up, they were handcuffed, paraded before media crews, and charged with a host of crimes related to the boardroom protest, the most severe of which — rioting and burglary — were later dropped. The remaining charges, including violating the right to assemble, aggravated restriction of freedom, and violence or intimidation against a public authority, each carry between six months and three years in prison. The seven students go to trial on February 7.

How exactly Vázquez’s Justice Department determined which students to charge out of the dozens who participated in the protest has remained a mystery to defense attorneys. The lawyers’ suspicion: that the case isn’t about crimes committed in the boardroom that day, but rather an attempt to penalize the political activity of some of the most active student organizers. The seven facing trial were members of the student strikers’ negotiating committee as well as political organizations critical of the government.",,,,,
Filmmakers Sue to Shield Visitors to U.S. From Social Media Vetting,,,,,,
An American Citizen Was Detained While Trying to Pay a Customs Fee on a Gift for His Daughter,"SHUTTERSTOCK, THE WELL-KNOWN online purveyor of stock images and photographs, is the latest U.S. company to willingly support China’s censorship regime, blocking searches that might offend the country’s authoritarian government, The Intercept has learned.

The publicly traded company built a $639 million-per-year business on the strength of its vast — sometimes comically vast — catalog of images depicting virtually anything a blogger or advertiser could imagine. The company now does business in more than 150 countries. But in China, there is now a very small, very significant gap in Shutterstock’s offerings. In early September, Shutterstock engineers were given a new goal: The creation of a search blacklist that would wipe from query results images associated with keywords forbidden by the Chinese government. Under the new system, which The Intercept is told went into effect last month, anyone with a mainland Chinese IP address searching Shutterstock for “President Xi,” “Chairman Mao,” “Taiwan flag,” “dictator,” “yellow umbrella,” or “Chinese flag” will receive no results at all. Variations of these terms, including “umbrella movement” — the precursor to the mass pro-democracy protests currently gripping Hong Kong — are also banned.

Shutterstock’s decision to silently aid China’s censorship agenda comes at a time of heightened scrutiny into the relationship between corporate America and President Xi Jinping’s authoritarian regime. Household names like Apple, Blizzard Entertainment, the NBA, and Google have all garnered harsh criticism for letting the policy directives of the Communist Party of China, and the gilded promise of a billion customers, dictate company strategy. Deciding to censor is a particularly stark inversion of values for Shutterstock, which markets itself as an enabler of creative expression.

The photo company’s relationship with China dates back to at least 2014, when it struck a distribution deal with ZCool, a Chinese social network and portfolio site for visual artists. Last year Shutterstock announced a $15 million investment in ZCool, noting that owing to the partnership, “Shutterstock’s content now powers large technology platforms in China such as Tencent Social Ads,” an online advertising subsidiary of the tremendously popular Chinese internet conglomerate Tencent.

Shutterstock’s censorship feature appears to have been immediately controversial within the company, prompting more than 180 Shutterstock workers to sign a petition against the search blacklist and accuse the company of trading its values for access to the lucrative Chinese market. Chinese internet users already struggle to discuss even the tamest of taboo subjects; now, it seemed, the situation would get a little worse, with the aid of yet another willing American company.

“Yes, we’re a creative photo and video marketplace, but we are also an editorial news hub,” one Shutterstock employee told The Intercept. “Want to write a story about the protests in Hong Kong? They never existed. Want to write about Taiwan? It never existed. Xi Jinping is NOT a dictator because he specifically said so. This is dark shit.”

The text of the petition, provided to The Intercept, can be read in full below.

Shutterstock’s founder and CEO Jon Oringer replied to the petition several days later; those hoping for a change of heart were to be disappointed. Shutterstock’s pro-censorship compromise with the Chinese government was justified, Oringer argued, because to refuse to do business in China rather than help the country’s government expand its information control scheme would be the real act of craven corporate turpitude: “Do we make the majority of our content available to China’s 1.3 billion citizens or do we take away their ability to access it entirely? We ultimately believe, consistent with our brand promise, it is more valuable for storytellers to have access to our collection to creatively and impactfully tell their stories.” Shutterstock with a bespoke censorship feature was “more empowering” and “will better serve the people of China than the alternative,” Oringer continued.

Oringer’s company-wide response is also reproduced below.

Following Oringer’s letter and the implementation of the search term blacklist, some employees fear the use of censorship at the company will grow: “He offered no consolation in terms of what our actions will be when China requests to add an X number more search terms to the censorship list,” the Shutterstock staffer told The Intercept, “or if another country comes to us with a similar request. We are devastated.”",,,,,
"Before Being Hacked, Border Surveillance Firm Lobbied to Downplay Security and Privacy Concerns About Its Technology","FEW PEOPLE HAD ever heard of Perceptics, a Tennessee-based subcontractor that sells license plate readers to U.S. Customs and Border Protection, before last month, when news emerged that the company had been hacked and that sensitive data — including images of license plates and drivers — had been released on the dark web.

The hack is just the sort of privacy breach that civil liberties advocates have long warned could come from massive government data collection, especially when it is contracted out to private firms. And it comes at a time when the CBP is under scrutiny for monitoring activists and journalists at the U.S.-Mexico border and airports.

Yet while photos of faces and license plates of some 100,000 U.S. drivers are now freely available online, the CEO of Perceptics, John Dalton, claimed in an email a few years ago that “CBP has none of the privacy concerns at the border that all agencies have inland.”

Writing to one of his company’s lobbyists in 2013, Dalton suggested that the border agency offered Perceptics an opportunity to make greater use of license plate images, stating, “Data mining and looking at traffic patterns/abnormalities are strong analytics for CBP, and could be for others.” Dalton appeared to be referring to the CBP’s relatively unfettered powers of search and seizure within 100 miles of the border. In contrast, for agencies other than CBP, “there is much concern with ACLU state level lawsuits and elsewhere around privacy issues, so this is a live challenge,” he wrote.",,,,,
"In Court, Facebook Blames Users for Destroying Their Own Right to Privacy","JUST MONTHS BEFORE millions of its internal documents were stolen and dumped on the internet, the Tennessee-based surveillance company Perceptics was preparing to pitch New York’s transit authority on how it could help enforce impending “congestion pricing” rules, according to leaked documents reviewed by The Intercept. The pitch, as outlined in the files, went well beyond mere toll enforcement and into profiling New Yorkers’ travel patterns and companions, creating what experts describe as major privacy risks.

Congestion pricing, on the face of it, doesn’t seem like it would present a privacy risk — it’s a traffic policy, after all, not some new NYPD initiative. The plan is to essentially tax the cars that clog Manhattan’s streets and route the proceeds to public transportation, providing both a deterrent against and palliative for traffic. There won’t be any congestion pricing toll booths: The fee will be assessed automatically and electronically, potentially by photographing the license plates of passing cars and sending the plate owner a bill in the mail. This requires cameras running around the clock, dutifully recording every car that comes and goes. And this, Perceptics claims, is where the company truly shines.

According to an internal presentation released by the Perceptics hacker and reviewed by The Intercept, the company pitched New York’s Metropolitan Transportation Authority, or MTA, in February of this year on how Perceptics’ car-scanning camera arrays, already deployed and honed in areas like the Mexican border and an assortment of U.S. military installations, could help the MTA track down drivers. It’s unknown how the plan was received by the MTA, which administers public transit, bridges, and tolls for New York City and some of its surrounding suburbs, but leaked Perceptics emails show that the company shipped camera hardware to the MTA’s Bridges and Tunnels division for a live demonstration.

Perceptics did not respond to a request for comment. An MTA spokesperson told The Intercept that “all details are still to be determined” regarding congestion pricing enforcement.

The presentation document, titled “Smart Imaging Solutions for New York City Congestion Pricing,” makes clear that Perceptics wants to “produce vehicle-specific profiles” using cameras and “unique machine learning algorithms,” allowing the city to immediately recognize and build travel histories of every car in the congestion zone. Law enforcement and surveillance experts said the system described goes far beyond what would ever be necessary to mail scofflaws traffic tickets. Instead, it is an entirely new sort of surveillance apparatus that tracks deeply personal information like “customer travel patterns and travel consistency,” the number of passengers in the car, or “likely trip purpose,” and associates this information with a unique fingerprint of every vehicle that passes by Perceptics’ cameras.

Allie Bohm, a policy counsel with the New York Civil Liberties Union, described the Perceptics plan as an “incredibly privacy-invasive proposal” that “raises all sorts of associational and First Amendment concerns.” Bohm expressed particular alarm about the possibility of a congestion pricing enforcement system eventually feeding data into the NYPD’s existing surveillance regime. “The NYPD has fancied itself an intelligence agency for a very long time,” said Bohm. “These are folks who are pioneering some really, at best, questionable, and, at worst, alarming programs of surveillance and of drawing conclusions from innocuous behavior.”

The MTA will not deploy congestion pricing before 2021 and has yet to select a tolling vendor. But whether Perceptics wins a contract or not, its idea to bring to the heart of Manhattan military-grade surveillance technology — already provided to Saudi Special Forces and the Jordanian army, according to a Perceptics document — is an example of how something as innocuous-sounding as congestion pricing can turn into a surveillance sprawl.",,,,,
China Bans The Intercept and Other News Sites in “Censorship Black Friday”,"A MEMBER OF Project Veritas gave testimony in a federal court case indicating that the right-wing group, known for its undercover videos, violates Facebook policies designed to counter systematic deception by Russian troll farms and other groups. The deposition raises questions over whether Facebook will deter American operatives who use the platform to strategically deceive and damage political opponents as vigorously as it has Iranian and Russian propagandists. But is the company capable of doing so without just creating more problems?

Close observers of Veritas and Facebook, including one at a research lab that works with the social network, said the testimony shows the group is clearly violating policies against what Facebook refers to as “coordinated inauthentic behavior.” The company formally defined such behavior in a December 2018 video featuring its cybersecurity policy chief Nathaniel Gleicher, who said it “is when groups of pages or people work together to mislead others about who they are or what they’re doing.” The designation, Gleicher added, is applied by Facebook to a group not “because of the content they’re sharing” but rather only “because of their deceptive behavior.” That is, using Facebook to dupe people is all it takes to fit the company’s institutional definition of coordinated inauthentic behavior.

In practice, “coordinated inauthentic behavior” has become a sort of catchall label for untoward meddling on Facebook, snagging everyone from Burmese military officers to Russian meme spammers. But curbing such activity has become a very public crusade for Facebook in the wake of its prominent role as a platform for the spread of disinformation, propaganda, and outright hoaxes during the 2016 presidential campaign. This past January, Gleicher announced the removal of coordinated inauthentic behavior from Iran, which spread when operatives “coordinated with one another and used fake accounts to misrepresent themselves,” thus triggering a Facebook ban. Similarly, in a 2017 update on Facebook’s internal investigation into Russian online propaganda efforts, the company’s then-head of security Alex Stamos assured the world’s democracies the company was providing “technology improvements for detecting fake accounts,” including “changes to help us more efficiently detect and stop inauthentic accounts at the time they are being created.”

Throughout all of this, coordinated inauthentic behavior has remained more or less synonymous with “foreign actors” and “nation-states,” the cloak-and-dagger stuff of an increasingly militarized internet filled with enemies of the Western Democracy who seek to subvert it from abroad.

Project Veritas, a hybrid of an opposition research shop and a ranting YouTube channel, has taken pride in its ability to deceive since its creation in 2010. With conservative backers like Peter Thiel, the Koch brothers, and the Trump Foundation, the group and its founder James O’Keefe have worked relentlessly to target and malign individuals at institutions they deem leftist, whether it’s Planned Parenthood (reportedly targeted by O’Keefe posing as a young teen’s 23-year-old boyfriend), George Soros (the progressive philanthropist whose professional circle Veritas tried and spectacularly failed to infiltrate), or the Washington Post (whose reporter was offered a fake story on Alabama Senate candidate Roy Moore). O’Keefe has long attempted to position himself in the context of dogged, daring, traditional journalism, describing Veritas’s efforts as “investigative” reporting executed by “undercover journalists.” But his efforts are often executed by what the New Yorker has called “amateurish spies” — their efforts against the Post and Soros resembled a Three Stooges bit — and packaged with mendacious editing, duplicitous production, and outright lying, making Veritas’s audience as much a victim of its productions as the subjects. Debates over who or what is to be considered “real journalism” are almost always counterproductive and contrived, but Veritas stands out for the shamelessness with which it pursues nakedly partisan ends.

There is, of course, a proud tradition of undercover journalism executed unequivocally in the name of informing the public. Writers like Barbara Ehrenreich and Shane Bauer have taken jobs they were not otherwise interested in in order to reveal injustices in society’s margins, and some of the most damning details of the Cambridge Analytica scandal were exposed by a reporter with the UK’s Channel 4 posing as a foreign politician interested in the company’s services. This reporting involved lying, sure — or at least the withholding of true intent, and a willingness to let others deceive themselves — but only as a means to a truthful end. The distinction between these reporters and Veritas operatives may be that the end the latter group seeks, the final media product, is typically just another act of partisan misdirection that doesn’t withstand further scrutiny.

Neither Project Veritas nor Facebook commented for this story.

“Legend Building” by Project Veritas

Project Veritas has systematically deceived not just targets on the left and viewers on the right but Facebook users as well (their official page has over 200,000 followers) at a time when the company is publicly dedicated to fighting this sort of systemic duplicity. That’s a wrinkle that raises questions about Facebook’s commitment to rooting out coordinated inauthentic behavior closer to home — Thiel sits on the company’s board — not to mention Project Veritas’s presence on social media.",,,,,
Snowden Archive,"IN A FEDERAL lawsuit, the tech giant Oracle has provided new details to support its accusation that Amazon secretly negotiated a job offer with a then-Department of Defense official who helped shape the procurement process for a massive federal contract for which Amazon was a key bidder.

Amazon Web Services and Microsoft are now the two finalists to win the highly contested $10 billion contract for what is known as the Joint Enterprise Defense Infrastructure, or JEDI. The deal, one of the largest federal contracts in U.S. history, would pay one company to provide cloud computing services in support of Defense Department operations around the world.

But the contract has been hotly contested since the department began soliciting proposals last year. Two of Amazon’s competitors, IBM and Oracle, filed complaints with the Government Accountability Office saying that the winner-take-all process unfairly favored Amazon, which is seen as an industry leader in cloud computing. When its claim was rejected, Oracle sued the government in the U.S. Court of Federal Claims.

Since the court battle began in 2018, Oracle has aggressively lodged conflict-of-interest accusations involving a former DOD official named Deap Ubhi, who left the department in 2017 to take a job at Amazon. In a court motion filed on Friday, Oracle alleged that while Ubhi worked on the preliminary research for the JEDI program in the late summer and fall of 2017, he was also engaged in a secret job negotiation with Amazon for months, complete with salary discussions, offers of signing bonuses, and lucrative stock options.

The motion further alleges that Ubhi did not recuse himself from the JEDI program until weeks after verbally accepting a job offer from Amazon and that he continued to receive information about Amazon’s competitors and participate in meetings about technical requirements, despite a government regulation that forbids such conflicts of interest.

“Neither Ubhi nor [Amazon Web Services] disclosed the employment discussions or job offer to DOD — not when the employment discussions started, not when the informal job offer occurred, not when the formal offer occurred, and not even when Ubhi accepted the offer,” Oracle’s motion reads.

As America’s technology companies have continued to outpace the Pentagon, the Defense Department has looked to recruit talent from Silicon Valley to help enhance its information technology.

Ubhi is a venture capitalist and technology entrepreneur who worked for Amazon before his time in government. He took a job working on a Defense Department initiative aimed at collaborating with Silicon Valley to modernize the Pentagon’s information technology systems. After working as part of a four-person team to help shape the Pentagon JEDI procurement process, he left the department and returned to Amazon in November 2017.

A spokesperson for Amazon Web Services declined to comment and declined to make Ubhi available for an interview, citing ongoing litigation. Elissa Smith, a spokesperson for the Department of Defense, also told The Intercept that “we don’t comment on pending litigation.”

In a previous court filing, U.S. government lawyers accused Oracle of a “broad fishing expedition primarily [intended] to find support for its claim that the solicitation at issue is tainted by alleged conflicts of interest.”

According to Oracle’s motion on Friday, Ubhi began job negotiations with Amazon in August 2017, while he was working on the early stages of the JEDI program. Oracle claims says that “deep discussions” about employment began in late September and that Ubhi “verbally committed” to take the job on October 4. But according to the filing, Ubhi did not recuse himself until October 31, 2017. Oracle alleges that he continued to influence the program in the meantime.

Under the Procurement Integrity Act, government officials who are “contacted by a [contract] bidder about non-federal employment” have two options: They must either report the contact and reject the offer of employment or promptly recuse themselves from any contract proceedings.

“Contracts should be awarded fairly based on merit,” Mandy Smithberger, director of the Center for Defense Information at the Project on Government Oversight, told The Intercept. “The Procurement Integrity Act seeks to ensure that job offers and other financial conflicts of interest don’t influence that process.”

Last year, a Defense Department review found that “there were four instances where [department] individuals with potential financial conflicts of interest” had worked on the JEDI program, according to court records, but the Pentagon concluded that this hadn’t unfairly impacted the contracting process. Two follow-up reviews — one by the GAO in November 2018 and another by the Defense Department in April 2019 — came to similar conclusions.

The second Pentagon review came after the department said that it had received “new information” about Ubhi and would investigate it. According to Oracle’s motion on Friday, the “new information” came from a “belated submission from [Amazon]” to the DOD’s contracting officer that finally acknowledged the monthslong employment talks.

According to Oracle, Ubhi provided a “false narrative” to the contracting officer at the time of his recusal, saying that he was stepping away from the project because Amazon had offered to acquire a company that Ubhi had a stake in. That was a pretext to mask the fact he had been negotiating for months to obtain a job at the company, Oracle’s filing said.

The filing also alleges that between Ubhi’s verbal commitment to accept Amazon’s offer and his recusal from JEDI, he continued to participate in Pentagon meetings about the project’s technical requirements and to receive submissions from Amazon competitors. It also alleges that Ubhi downloaded material from a JEDI project Google Drive to his own laptop.

In its filings, Oracle has argued that Ubhi was instrumental in persuading the Pentagon to seek services from a single vendor — a decision widely seen to improve Amazon’s chances. Oracle cites workplace messages on the platform Slack in which Ubhi tries to persuade his colleagues to come around to that view, but the company does not cite any messages suggesting what his reasons or motive may have been.",,,,,
Snowden Archive,In partnership with,,,,,
Snowden Archive,,,,,,
Google Dragonfly,"FORMER GOOGLE CEO Eric Schmidt has defended the company’s plan to build a censored version of its search engine in China.

In an interview with the BBC on Monday, Schmidt said that he wasn’t involved in decisions to build the censored search platform, code-named Dragonfly. But he insisted that there were “many benefits” to working with China and said he was an advocate of operating in the country because he believed that it could “help change China to be more open.”

As The Intercept first revealed in August, Google developed a prototype of the censored search engine that was designed to remove content that China’s ruling Communist Party regime deems sensitive. The search engine would have blacklisted thousands of words and phrases, including terms such as “human rights,” “student protest,” and “Nobel Prize” in Mandarin.

The revelations prompted a wave of protests inside and outside of Google, with employees, activists, and prominent lawmakers demanding an end to the project. Google subsequently stated that it had ceased work on Dragonfly and moved employees to new projects.",,,,,
"Privacy Experts, Senators Demand Investigation of Amazon’s Child Data Collection Practices","LAST YEAR, A coalition of privacy advocates and child psychologists warned against putting an Amazon Alexa speaker anywhere near your child on the fairly reasonable grounds that developing minds shouldn’t befriend always-on surveillance devices, no matter how cute the packaging. Now, a group of privacy researchers, attorneys, and U.S. senators are calling on the Federal Trade Commission to investigate Amazon’s alleged violations of COPPA, a law protecting the littlest users of all.

COPPA, the Children’s Online Privacy Protection Act, regulates how companies can collect and use data on users who might have trouble spelling “privacy,” let alone understand it enough to consent to relinquishing it. COPPA is the reason why so many sites, like Facebook, simply don’t allow children under 13 to sign up. Amazon, on the other hand, decided to court children for its data collection business, releasing the Amazon Echo Dot Kids Edition, an always-listening “smart speaker” that retains all of the functions of its adult counterpart, but tucks them inside a candy-colored shell. The kiddo speaker also adds child-specific features, like the ability to have Amazon’s virtual assistant Alexa read your child a story in her disembodied robo-voice, or play child-geared content from sources like Cartoon Network and Nickelodeon.

A new complaint drafted by the Campaign for a Commercial-Free Childhood, the consumer privacy group Center for Digital Democracy, and Georgetown University’s Institute for Public Representation says that Amazon is committing a litany of COPPA violations through the Echo Dot Kids Edition, and calls on the FTC to investigate.

Amazon’s COPPA violations, according to the complaint, include failure to provide parental notice and obtain parental consent for online services related to the kids’ Echo Dot, failure to tell parents that they have a right to review personal information submitted by their child, and failure to provide parents a way to delete such information or opt out of its collection.

Across 96 pages, the complaint gets more specific, offering examples of how Amazon dodges, obscures, and otherwise neglects its duties to parents. Given that the attorneys who drafted the complaint were confused by Amazon’s byzantine policies, it’s hard to imagine average parents faring much better:

Even if parents were for some reason motivated to seek out the website version of the Children’s Privacy Disclosure, the hyperlinked Privacy Notice is long, confusingly written, and contains a lot of unrelated material. It is unclear what, if any, parts apply to the Echo Dot Kids Edition, and some of the information seems to contradict the Children’s Privacy Disclosure. For example, the Privacy Notice discloses that Amazon collects “search term and search result information from some searches conducted through the Web search features offered by our subsidiary, Alexa Internet,” but it does not say whether it does so when a child is using the Echo Dot Kids Edition.

Perhaps most troubling is what the complaint says about Amazon’s treatment of child voice recordings, which aren’t supposed to be stored indefinitely, per recent FTC guidance: “The answer is clear: No, the company can’t keep it. Under Section 312.10 of COPPA, you’re allowed to retain children’s personal information ‘for only as long as is reasonably necessary to fulfill the purpose for which the information was collected.'”

But Amazon takes a different approach, the complaint explains: “In response to a Congressional inquiry about how long it keeps recordings and other information collected from children, however, Amazon responded: ‘Voice recordings are retained for the parent’s review until the parent deletes them.'” In other words, Amazon is keeping a child’s Amazon queries stored indefinitely, not “for only as long as is reasonably necessary.”",,,,,
Lyft and Other Gig Economy Giants Cash In With IPOs Before Labor Laws Catch Up With Them,,,,,,
Google Dragonfly,"GOOGLE EXECUTIVES ARE carrying out a secret internal assessment of work on a censored search engine for China, The Intercept has learned.

A small group of top managers at the internet giant are conducting a “performance review” of the controversial effort to build the search platform, known as Dragonfly, which was designed to blacklist information about human rights, democracy, religion, and peaceful protest.

Performance reviews at Google are undertaken annually to evaluate employees’ output and development. They are usually carried out in an open, peer review-style process: Workers grade each other’s projects and the results are then assessed by management, who can reward employees with promotion if they are deemed ready to progress at the company.

In the case of Dragonfly, however, the peer review aspect has been removed, subverting the normal procedure. In a move described as highly unusual by two Google sources, executives set up a separate group of closed “review committees,” comprised of senior managers who had all previously been briefed about the China search engine.",,,,,
Google Dragonfly,,,,,,
Trump and Brexit Proved This Book Prophetic — What Calamity Will Befall Us Next?,"ACROSS THE WORLD, the reputation of elites and their institutions is in free fall. A flood of online information has given the public unprecedented access to elite individuals in politics, media, academia, science, business, and an array of other fields. Thanks to tools like social media, the activist public has greater proximity to its supposed mandarin class than ever before. What this newfound intimacy has revealed has not always been flattering. Many of those who had been held up as elites in their fields have, upon closer examination by the public, been revealed as mediocre, incompetent, buffoonish, and, in some cases, possibly unhinged. At the same time, the public, for all its passion, has also revealed itself to be vulnerable to conspiracy theories, disinformation, and outbreaks of hysteria.",,,,,
Drone Wars,"FOLLOWING MONTHS OF protests from its employees, Google announced last summer that it would not renew its contract with the military on Project Maven, an initiative to use artificial intelligence to improve the targeting and surveillance capabilities of drones on the battlefield.

In an email sent this week by Kent Walker, Google’s senior vice president for global affairs, the Silicon Valley giant appeared to hedge on its commitment to fully cut ties with the drone initiative.",,,,,
Naomi Klein and Shoshana Zuboff on the Rise of Surveillance Capitalism,,,,,,
Amazon Pullout Shows What Anti-Capitalist Organizing and Leftist Politicians Can Do,,,,,,
Amazon’s Home Surveillance Chief Declared War on “Dirtbag Criminals” as Company Got Closer to Police,"ON MARCH 17, 2016, Ring CEO Jamie Siminoff emailed out a company-wide declaration of war. The message, under the subject line “Going to war,” made two things clear to the home surveillance company’s hundreds of employees: Everyone was getting free camouflage-print T-shirts (“They look awesome,” assured Siminoff), and the company’s new mission was to use consumer electronics to fight crime. “We are going to war with anyone that wants to harm a neighborhood,” Siminoff wrote — and indeed Ring made it easier for police and worried neighbors to get their hands on footage from Ring home cameras. Internal documents and video reviewed by The Intercept show why this merging of private tech business and public law enforcement has troubling privacy implications.

This first declaration of startup militancy — which Siminoff would later refer to as “Ring War I” or simply “RW1” — would be followed by more, equally clumsy attempts at corporate galvanization, some aimed at competitors or lackluster customer support. But the RW1 email is striking in how baldly it lays out the priorities and values of Ring, a company now owned by Amazon and facing strident criticism over its mishandling of customer data, as previously reported by The Intercept and The Information.

Ring and Siminoff, who still leads the company, haven’t been shy about their focus on crime-fighting. In fact, Ring’s emphasis not only on personal peace of mind, but also active crime-fighting has been instrumental in differentiating its cloud-connected doorbell and household surveillance gear from those made by its competitors. Ring products come with access to a social app called Neighbors that allows customers to not just to keep tabs on their own property, but also to share information about suspicious-looking individuals and alleged criminality with the rest of the block. In other words, Ring’s cameras aren’t just for keeping tabs on your own stoop or garage — they work to create a private-sector security bubble around entire residential areas, a neighborhood watch for the era of the so-called smart home.",,,,,
"Jeff Bezos Protests the Invasion of His Privacy, as Amazon Builds a Sprawling Surveillance State for Everyone Else",,,,,,
Drone Wars,,,,,,
“A Fundamentally Illegitimate Choice”: Shoshana Zuboff on the Age of Surveillance Capitalism,"SHOSHANA ZUBOFF’S “The Age of Surveillance Capitalism” is already drawing comparisons to seminal socioeconomic investigations like Rachel Carson’s “Silent Spring” and Karl Marx’s “Capital.” Zuboff’s book deserves these comparisons and more: Like the former, it’s an alarming exposé about how business interests have poisoned our world, and like the latter, it provides a framework to understand and combat that poison. But “The Age of Surveillance Capitalism,” named for the now-popular term Zuboff herself coined five years ago, is also a masterwork of horror. It’s hard to recall a book that left me as haunted as Zuboff’s, with its descriptions of the gothic algorithmic daemons that follow us at nearly every instant of every hour of every day to suck us dry of metadata. Even those who’ve made an effort to track the technology that tracks us over the last decade or so will be chilled to their core by Zuboff, unable to look at their surroundings the same way.",,,,,
New Site Exposes How Apple Censors Apps in China,"A NEW WEBSITE exposes the extent to which Apple cooperates with Chinese government internet censorship, blocking access to Western news sources, information about human rights and religious freedoms, and privacy-enhancing apps that would circumvent the country’s pervasive online surveillance regime.

The new site, AppleCensorship.com, allows users to check which apps are not accessible to people in China through Apple’s app store, indicating those that have been banned. It was created by researchers at GreatFire.org, an organization that monitors Chinese government internet censorship.

In late 2017, Apple admitted to U.S. senators that it had removed from its app store in China more than 600 “virtual private network” apps that allow users to evade censorship and online spying. But the company never disclosed which specific apps it removed — nor did it reveal other services it had pulled from its app store at the behest of China’s authoritarian government.

In addition to the hundreds of VPN apps, Apple is currently preventing its users in China from downloading apps from news organizations, including the New York Times, Radio Free Asia, Tibetan News, and Voice of Tibet. It is also blocking censorship circumvention tools like Tor and Psiphon; Google’s search app and Google Earth; an app called Bitter Winter, which provides information about human rights and religious freedoms in China; and an app operated by the Central Tibetan Authority, which provides information about Tibetan human rights and social issues.

Some bans – such as those of certain VPN apps and the Times – have received media coverage in the past, but many never generate news headlines. Charlie Smith, a co-founder of GreatFire.org, told The Intercept that the group was motivated to launch the website because “Apple provides little transparency into what it censors in its app store. Most developers find out their app has been censored after they see a drop in China traffic and try to figure out if there is a problem. We wanted to bring transparency to what they are censoring.”",,,,,
Google’s Sidewalk Labs Plans to Package and Sell Location Data on Millions of Cellphones,LEIA EM PORTUGUÊS ,,,,,
Snowden Archive,LEIA EM PORTUGUÊS ,,,,,
Google Dragonfly,"GOOGLE IS FACING a new campaign of global protests over its plan to launch a censored version of its search engine in China.

On Friday, a coalition of Chinese, Tibetan, Uighur, and human rights groups organized demonstrations outside Google’s offices in the U.S., U.K., Canada, India, Mexico, Chile, Argentina, Sweden, Switzerland, and Denmark.",,,,,
"For Owners of Amazon’s Ring Security Cameras, Strangers May Have Been Watching Too","THE “SMART HOME” of the 21st century isn’t just supposed to be a monument to convenience, we’re told, but also to protection, a Tony Stark-like bubble of vigilant algorithms and internet-connected sensors working ceaselessly to watch over us. But for some who’ve welcomed in Amazon’s Ring security cameras, there have been more than just algorithms watching through the lens, according to sources alarmed by Ring’s dismal privacy practices.

Ring has a history of lax, sloppy oversight when it comes to deciding who has access to some of the most precious, intimate data belonging to any person: a live, high-definition feed from around — and perhaps inside — their house. The company has marketed its line of miniature cameras, designed to be mounted as doorbells, in garages, and on bookshelves, not only as a means of keeping tabs on your home while you’re away, but of creating a sort of privatized neighborhood watch, a constellation of overlapping camera feeds that will help police detect and apprehend burglars (and worse) as they approach. “Our mission to reduce crime in neighborhoods has been at the core of everything we do at Ring,” founder and CEO Jamie Siminoff wrote last spring to commemorate the company’s reported $1 billion acquisition payday from Amazon, a company with its own recent history of troubling facial recognition practices. The marketing is working; Ring is a consumer hit and a press darling.

Despite its mission to keep people and their property secure, the company’s treatment of customer video feeds has been anything but, people familiar with the company’s practices told The Intercept. Beginning in 2016, according to one source, Ring provided its Ukraine-based research and development team virtually unfettered access to a folder on Amazon’s S3 cloud storage service that contained every video created by every Ring camera around the world. This would amount to an enormous list of highly sensitive files that could be easily browsed and viewed. Downloading and sharing these customer video files would have required little more than a click. The Information, which has aggressively covered Ring’s security lapses, reported on these practices last month.

At the time the Ukrainian access was provided, the video files were left unencrypted, the source said, because of Ring leadership’s “sense that encryption would make the company less valuable,” owing to the expense of implementing encryption and lost revenue opportunities due to restricted access. The Ukraine team was also provided with a corresponding database that linked each specific video file to corresponding specific Ring customers.",,,,,
Year in Review 2018,,,,,,
Google Dragonfly,LEIA EM PORTUGUÊS ,,,,,
Google Dragonfly,"GOOGLE CEO SUNDAR PICHAI came under fire from lawmakers on Tuesday over the company’s secretive plan to launch a censored search engine in China.

During a hearing held by the House Judiciary Committee, Pichai faced sustained questions over the China plan, known as Dragonfly, which would blacklist broad categories of information about democracy, human rights, and peaceful protest.

The hearing began with an opening statement from Rep. Kevin McCarthy, R-Calif., who said launching a censored search engine in China would “strengthen China’s system of surveillance and repression.” McCarthy questioned whether it was the role of American companies to be “instruments of freedom or instruments of control.”

Pichai read prepared remarks, stating “even as we expand into new markets, we never forget our American roots.” He added: “I lead this company without political bias and work to ensure that our products continue to operate that way. To do otherwise would go against our core principles and our business interests.”",,,,,
Google Dragonfly,"GOOGLE IS FACING a renewed wave of criticism from human rights groups over its controversial plan to launch a censored search engine in China.

A coalition of more than 60 leading groups from countries across the world have joined forces to blast the internet giant for failing to address concerns about the secretive China project, known as Dragonfly. They come from countries including China, the United States, the United Kingdom, Argentina, Bolivia, Chile, France, Kazakhstan, Mexico, Norway, Pakistan, Palestine, Romania, Syria, Tibet, and Vietnam.

A prototype for the censored search engine was designed to blacklist broad categories of information about human rights, democracy, and peaceful protest. It would link Chinese users’ searches to their personal cellphone number and store people’s search records inside the data centers of a Chinese company in Beijing or Shanghai, which would be accessible to China’s authoritarian Communist Party government.

If the plan proceeds, “there is a real risk that Google would directly assist the Chinese government in arresting or imprisoning people simply for expressing their views online, making the company complicit in human rights violations,” the human rights groups wrote in a letter that will be sent to Google’s leadership on Tuesday.

The letter highlights mounting anger and frustration within the human rights community that Google has rebuffed concerns about Dragonfly, concerns that have been widely raised both inside and outside the company since The Intercept first revealed the plan in August. The groups say in their 900-word missive that Google’s China strategy is “reckless,” piling pressure on CEO Sundar Pichai, who is due to appear Tuesday before the House Judiciary Committee, where he will likely face questions on Dragonfly.",,,,,
Artificial Intelligence Experts Issue Urgent Warning Against Facial Scanning With a “Dangerous History”,"GOOGLE IS FACING a renewed wave of criticism from human rights groups over its controversial plan to launch a censored search engine in China.

A coalition of more than 60 leading groups from countries across the world have joined forces to blast the internet giant for failing to address concerns about the secretive China project, known as Dragonfly. They come from countries including China, the United States, the United Kingdom, Argentina, Bolivia, Chile, France, Kazakhstan, Mexico, Norway, Pakistan, Palestine, Romania, Syria, Tibet, and Vietnam.

A prototype for the censored search engine was designed to blacklist broad categories of information about human rights, democracy, and peaceful protest. It would link Chinese users’ searches to their personal cellphone number and store people’s search records inside the data centers of a Chinese company in Beijing or Shanghai, which would be accessible to China’s authoritarian Communist Party government.

If the plan proceeds, “there is a real risk that Google would directly assist the Chinese government in arresting or imprisoning people simply for expressing their views online, making the company complicit in human rights violations,” the human rights groups wrote in a letter that will be sent to Google’s leadership on Tuesday.

The letter highlights mounting anger and frustration within the human rights community that Google has rebuffed concerns about Dragonfly, concerns that have been widely raised both inside and outside the company since The Intercept first revealed the plan in August. The groups say in their 900-word missive that Google’s China strategy is “reckless,” piling pressure on CEO Sundar Pichai, who is due to appear Tuesday before the House Judiciary Committee, where he will likely face questions on Dragonfly.",,,,,
Here’s Facebook’s Former “Privacy Sherpa” Discussing How to Harm Your Facebook Privacy,LEIA EM PORTUGUÊS ,,,,,
Imprisoned Hacktivist Jeremy Hammond Bumped a Guard With a Door — and Got Thrown in Solitary Confinement,"LAST MONTH, A famed hacker who has been serving a 10-year prison sentence since 2012 was accused by a guard at a federal detention center of “minor assault,” landing the so-called hacktivist in solitary confinement, according to advocates. The guard at Michigan’s Federal Correctional Institute-Milan made the accusation against Jeremy Hammond — the activist associated with hacking groups Anonymous and LulzSec and best know for hacking private intelligence firm Stratfor and leaking documents to WikiLeaks — on either November 19 or 20. Hammond has been held in solitary confinement ever since, according to the Jeremy Hammond Support Network.

The guard claims that Hammond hit him with a door, “stood his ground,” and pushed his shoulder into the guard. The head of Hammond’s support network said the prison guard’s account is an overblown. “Jeremy says that he was exiting his unit through a door that has no windows and could not see the guard on the other side, and as he’s exiting, bumped the guard with the door,” Grace North told The Intercept. “The guard immediately grabbed Jeremy and threw him up against the wall and dragged him down to solitary, with no handcuffs, without calling for backup, which is against prison protocol, and Jeremy has been there ever since.”

North’s version of events also portrays the guard as overly aggressive: After the guard was hit with the door, North said, he asked Hammond if he “wanted to go.”",,,,,
Homeland Security Will Let Computers Predict Who Might Be a Terrorist on Your Plane — Just Don’t Ask How It Works,"LAST MONTH, A famed hacker who has been serving a 10-year prison sentence since 2012 was accused by a guard at a federal detention center of “minor assault,” landing the so-called hacktivist in solitary confinement, according to advocates. The guard at Michigan’s Federal Correctional Institute-Milan made the accusation against Jeremy Hammond — the activist associated with hacking groups Anonymous and LulzSec and best know for hacking private intelligence firm Stratfor and leaking documents to WikiLeaks — on either November 19 or 20. Hammond has been held in solitary confinement ever since, according to the Jeremy Hammond Support Network.

The guard claims that Hammond hit him with a door, “stood his ground,” and pushed his shoulder into the guard. The head of Hammond’s support network said the prison guard’s account is an overblown. “Jeremy says that he was exiting his unit through a door that has no windows and could not see the guard on the other side, and as he’s exiting, bumped the guard with the door,” Grace North told The Intercept. “The guard immediately grabbed Jeremy and threw him up against the wall and dragged him down to solitary, with no handcuffs, without calling for backup, which is against prison protocol, and Jeremy has been there ever since.”

North’s version of events also portrays the guard as overly aggressive: After the guard was hit with the door, North said, he asked Hammond if he “wanted to go.”",,,,,
Google Dragonfly,,,,,,
Google Dragonfly,"THE SECRECY SURROUNDING the work was unheard of at Google. It was not unusual for planned new products to be closely guarded ahead of launch. But this time was different. The objective, code-named Dragonfly, was to build a search engine for China that would censor broad categories of information about human rights, democracy, and peaceful protest.

In February 2017, during one of the first group meetings about Dragonfly at Google’s Mountain View headquarters in California, some of those present were left stunned by what they heard. Senior executives disclosed that the search system’s infrastructure would be reliant upon a Chinese partner company with data centers likely in Beijing or Shanghai.

Locating core parts of the search system on the Chinese mainland meant that people’s search records would be easily accessible to China’s authoritarian government, which has broad surveillance powers that it routinely deploys to target activists, journalists, and political opponents.

Yonatan Zunger, then a 14-year veteran of Google and one of the leading engineers at the company, was among a small group who had been asked to work on Dragonfly. He was present at some of the early meetings and said he pointed out to executives managing the project that Chinese people could be at risk of interrogation or detention if they were found to have used Google to seek out information banned by the government.

Scott Beaumont, Google’s head of operations in China and one of the key architects of Dragonfly, did not view Zunger’s concerns as significant enough to merit a change of course, according to four people who worked on the project. Beaumont and other executives then shut out members of the company’s security and privacy team from key meetings about the search engine, the four people said, and tried to sideline a privacy review of the plan that sought to address potential human rights abuses.

Zunger — who left his position at Google last year — is one of the four people who spoke to The Intercept for this story. He is the first person with direct involvement in Dragonfly to go on the record about the project. The other three who spoke to The Intercept are still employed by Google and agreed to share information on the condition of anonymity because they were not authorized to talk to the media. Their accounts provide extraordinary insight into how Google bosses worked to suppress employee criticism of the censored search engine and reveal deep fractures inside the company over the China plan dating back almost two years.

Google’s leadership considered Dragonfly so sensitive that they would often communicate only verbally about it and would not take written notes during high-level meetings to reduce the paper trail, two sources said. Only a few hundred of Google’s 88,000 workforce were briefed about the censorship plan. Some engineers and other staff who were informed about the project were told that they risked losing their jobs if they dared to discuss it with colleagues who were themselves not working on Dragonfly.

“They [leadership] were determined to prevent leaks about Dragonfly from spreading through the company,” said a current Google employee with knowledge of the project. “Their biggest fear was that internal opposition would slow our operations.”",,,,,
Google Dragonfly,LEIA EM PORTUGUÊS ,,,,,
Google Dragonfly,"AMNESTY INTERNATIONAL HAS announced a new protest campaign calling on Google to cancel its controversial plan to launch a censored search engine in China.

The human rights group on Monday launched a petition against the search engine and said that on Tuesday, it will stage demonstrations outside Google offices in the United States, the United Kingdom, Australia, Canada, Germany, Hong Kong, the Netherlands, and Spain. Google’s plan for China would “irreparably damage internet users’ trust in the tech company,” Amnesty said in statement, and “would set a dangerous precedent for tech companies enabling rights abuses by governments.”

As The Intercept first reported in August, Google secretly developed the censored search engine as part of a project code-named Dragonfly. It was designed to blacklist words and phrases such as “human rights,” “Nobel Prize,” and “student protest.” The search platform would link Chinese users’ search records to their cellphone numbers and share people’s search histories with a Chinese partner company. The search records would in turn be accessible to China’s authoritarian government, which has broad surveillance and data-seizing powers that it routinely uses to identify and arrest activists and critics.

“This is a watershed moment for Google,” said Joe Westby, Amnesty International’s researcher on technology and human rights. “As the world’s No. 1 search engine, it should be fighting for an internet where information is freely accessible to everyone, not backing the Chinese government’s dystopian alternative.”",,,,,
"New Law Could Give U.K. Unconstitutional Access to Americans’ Personal Data, Human Rights Groups Warn","NINE HUMAN RIGHTS and civil liberties organizations sent a letter to the U.S. Justice Department today objecting to a potential agreement between the United States and the United Kingdom that would give British law enforcement broad access to data held by U.S. technology companies.

The possible agreement stems from the Clarifying Lawful Overseas Use of Data Act, or CLOUD Act, for which Justice Department officials have lobbied since 2016 and which President Donald Trump signed into law in March.

In addition to requiring American tech companies to provide data on U.S. citizens when served with a warrant, the CLOUD Act allows for so-called executive agreements between the president and foreign governments. These agreements, the first of which would be with the United Kingdom, would empower foreign law enforcement agencies to order U.S. tech companies to produce data about individual users without a warrant, so long as the search target is not a U.S. citizen or resident.

The Electronic Frontier Foundation, one of the organizations that signed the letter of protest, has described a possible scenario for how a U.K. police service might obtain data under the CLOUD Act: “London investigators want the private Slack messages of a Londoner they suspect of bank fraud. The London police could go directly to Slack, a U.S. company, to request and collect those messages. The London police would receive no prior judicial review for this request. The London police could avoid notifying U.S. law enforcement about this request. The London police would not need a probable cause warrant for this collection.”

But this form of international data-sharing could put Americans’ privacy at risk and expose citizens to potential Fourth Amendment abuses, critics say.

While the CLOUD Act requires that foreign police services not “intentionally target a United States person or a person located in the United States,” the law does not stop foreign police agencies from receiving communications of U.S. citizens or residents. Using the Electronic Frontier Foundation’s example of a Londoner communicating on Slack, any communications between the targeted British citizen and Americans would also be turned over to London police.

“The phrase ‘intentionally target’ creates a large loophole; people in the U.S. and U.S. persons overseas could easily get caught in the dragnet,” said Sarah St.Vincent, an investigator with Human Rights Watch, another signatory to the Justice Department letter. Although such so-called minimization procedures are ostensibly in place to prevent foreign governments from ensnaring U.S. users, St.Vincent told The Intercept that she rejects the notion that they “should be reassuring to anyone,” as “procedures are not laws,” but rather safeguards. “I don’t see any mechanism in here to ensure that those are strictly applied and inspected,” St.Vincent added.

The CLOUD Act also leaves open the possibility that a foreign police agency could obtain, without a warrant, incriminating communications from a U.S. citizen, which could then be shared with U.S. law enforcement. Data obtained in this way could not be used as evidence in a U.S. court, because its collection would violate Fourth Amendment protections. But local, state, or federal law enforcement agencies could reacquire the communications after obtaining a warrant — a controversial law enforcement practice known as “parallel construction.”

Federal law enforcement agencies, including the FBI and the Drug Enforcement Administration, already use parallel construction to launder information acquired from the warrantless wiretapping programs exposed by National Security Agency whistleblower Edward Snowden. In November 2017, The Intercept reported how the FBI used parallel construction to enter information first obtained through the government’s mass surveillance programs into evidence in terrorism trials. In these cases, prosecutors did not disclose to the courts that investigators had obtained the evidence from warrantless surveillance and then re-obtained it using legitimate warrants.

A Human Rights Watch report released in January documented how the DEA set up a unit called the Special Operations Division to receive raw intelligence from the NSA and disseminate leads to field agents. Agents on the ground were instructed to conceal the source of their information and find other ways to justify searches and broader investigations.

“The CLOUD Act would specifically allow the U.K. authorities to pass data belonging to U.S. persons back to the U.S. authorities if it ‘relates to significant harm, or the threat thereof, to the United States or United States persons’ — quite a significant loophole,” St.Vincent said. “The U.S. authorities can’t deliberately set up this end run around the Fourth Amendment themselves, but they’re free to sit back and receive whatever the U.K. sees fit to share.”

DESPITE THE ACT’S worrying implications for user privacy, the American tech vanguard has embraced it. In February, Google, Apple, Facebook, Microsoft, and Oath (formerly Yahoo) wrote to four U.S. senators detailing their support for the legislation, claiming that CLOUD “reflects a growing consensus in favor of protecting Internet users,” and “would be notable progress to protect consumers’ rights and would reduce conflicts of law.” In September, Reuters reported that Apple was building an “online tool” that would allow police around the world to more easily request the company’s user data.

Only after the CLOUD Act was passed did Microsoft, one of the law’s early boosters, address questions of personal privacy and offer assurances that the framework would not be abused. In a September blog post, Microsoft president and top lawyer Brad Smith announced “six principles that have driven, and will continue to drive, our advocacy as governments reform their laws and negotiate international agreements,” including a “universal right” for users to be notified if their data is accessed, and the ability to “challenge unlawful and inappropriate demands for user data.” Even so, Smith’s post states unequivocally that Microsoft believes the “passage of the CLOUD Act created the foundation for a new generation of international agreements that allows governments to engage with each other to create lasting rules to protect privacy.” Other tech firms have simply remained silent.",,,,,
The Dangerous Junk Science of Vocal Risk Assessment,"IS IT POSSIBLE to tell whether someone is a criminal just from looking at their face or listening to the sound of their voice? The idea may seem ludicrous, like something out of science fiction — Big Brother in “1984” detects any unconscious look “that carried with it the suggestion of abnormality” — and yet, some companies have recently begun to answer this question in the affirmative. AC Global Risk, a startup founded in 2016, claims to be able to determine your level of “risk” as an employee or an asylum-seeker based not on what you say, but how you say it.

The California-based company offers an automated screening system known as a Remote Risk Assessment, or RRA. Here’s how it works: Clients of AC Global Risk help develop automated, yes-or-no interview questions. The group of people selected for a given screening then answer these simple questions in their native language during a 10-minute interview that can be conducted over the phone. The RRA then measures the characteristics of their voice to produce an evaluation report that scores each individual on a spectrum from low to high risk. CEO Alex Martin has said that the company’s proprietary risk analysis can “forever change for the better how human risk is measured.”

AC Global Risk, which boasts the consulting firm of Robert Gates, Condoleezza Rice, and Stephen Hadley on its advisory board, has advertised contracts with the U.S. Special Operations Command in Afghanistan, the Ugandan Wildlife Authority, and the security teams at Palantir, Apple, Facebook, and Google, among others. The extensive use of risk screening in these and other markets, Martin has said, has proven that it is “highly accurate, scalable, cost-effective, and capable of high throughput.” AC Global Risk claims that its RRA system can simultaneously process hundreds of individuals anywhere in the world. Now, in response to President Donald Trump’s calls for the “extreme vetting” of immigrants, the company has pitched itself as the ultimate solution for “the monumental refugee crisis the U.S. and other countries are currently experiencing.”

It’s a proposal that would seem to appeal to the U.S. Department of Homeland Security. The DHS has already funded research to develop similar AI technology for the border. The program, known as the Automated Virtual Agent for Truth Assessments in Real-Time, or AVATAR, used artificial intelligence to measure changes in the voice, posture, and facial gestures of travelers in order to flag those who appeared untruthful or seemed to pose a potential risk. In 2012 it was tested by volunteers at the U.S.-Mexico border. The European Union has also funded research into technology that would reduce “the workload and subjective errors caused by human agents.”

Some of the leading experts in vocal analytics, algorithmic bias, and machine learning find the trend toward digital polygraph tests troubling, pointing to the faulty methodology of companies like AC Global Risk. “There is some information in dynamic changes in the voice and they’re detecting it. This is perfectly plausible,” explained Alex Todorov, a Princeton University psychologist who studies the science of social perception and first impressions. “But the question is, How unambiguous is this information at detecting the category of people they’ve defined as risky? There is always ambiguity in these kinds of signals.”

Over the past year, the American Civil Liberties Union and others have reported that Border Patrol agents have been seizing people from Greyhound buses based on their appearance or accent. Because Customs and Border Protection agents already use information about how someone speaks or looks as a pretext to search individuals in the 100-mile border zone, or to deny individuals entry to the U.S., experts fear that vocal emotion detection software could make such biases routine, pervasive, and seemingly “objective.”

AC Global Risk declined to respond to repeated requests for comment for this article. The company also did not respond to a list of detailed questions about how the technology works. In public appearances, however, Martin has claimed that the company’s proprietary analytical processes can determine someone’s risk level with greater than 97 percent accuracy. (AVATAR, meanwhile, claims an accuracy rate of between 60 and 70 percent.) Several leading audiovisual experts who reviewed AC Global Risk’s publicly available materials for The Intercept used the word “bullshit” or “bogus” to describe the company’s claims. “From an ethical point of view, it’s very dubious and shady to give the impression that recognizing deception from only the voice can be done with any accuracy,” said Björn Schuller, a professor at the University of Augsburg who has led the field’s major academic challenge event to advance the state of the art in vocal emotion detection. “Anyone who says they can do this should themselves be seen as a risk.”",,,,,
Is It Easier to Imagine the End of the World Than the End of the Internet?,LEIA EM PORTUGUÊS ,,,,,
Inside the Wild West World of Gift Card Bitcoin Brokering,"IN THE VIDEO game aisle of a Walmart Supercenter, Eric, 43, is refreshing his phone. The Superman logo on his T-shirt has been reworked into a hammer and sickle. He’s waiting to hear back from a stranger based, as far as he knows, in Kenya. “He just offered to pay $400,” Eric says. “I don’t feel 100 percent on him, but I don’t have anything real to base it on.”

Eric is a currency broker. But he doesn’t work on Wall Street, or at the Chicago Mercantile Exchange, or with any financial institution. He’s one of the thousands of Americans who have built a career out of the bitcoin phenomenon, whether out of necessity or a sense of entrepreneurship. It’s enabled Eric to stop toiling as an information technology engineer for software companies and set his own hours. “Never in my life had I thought I’d work for myself,” Eric explains.

His operation mainly consists of a phone and a couple of apps. But it also requires daily visits to his version of the trading floor: Walmart. Eric visits big box stores so often that he knows the self-checkout machines (his preferred method of payment) better than the clerks who work there. He goes to Walmart to buy gift cards, which serve as a medium of exchange and a means of protection from being duped by his clients. But the whole scheme relies on exploiting Walmart’s rather lax standard on gift card purchases. Eric believes, through his up-close experience, that these lax standards have been facilitating rampant gift card fraud, which has risen to epidemic levels as of late.

Eric will end up netting $12 on this transaction, but he did it at a discount, to make sure he had a customer. He wanted to make sure he could demonstrate to a reporter precisely how it’s done, on the condition that his real name not be used. The goal, he said, was to expose vulnerabilities in Walmart’s gift card policy, so that the company would take action. On Tuesday, Walmart did just that, sort of, announcing new rules in the way it treats such cards, upending a world that Eric offered The Intercept an invitation to explore.

The new policy will make it difficult for Eric to make ends meet, but he’s glad it happened. “I’m a socialist in a capitalist world,” he explains.

ERIC BECAME FASCINATED with bitcoin while using it for offshore gambling sites. That led him to his trading business, which he’s operated for over three years.

Here’s how it works: Eric sells bitcoin to buyers all over the world through a peer-to-peer marketplace called Paxful, charging a premium for the cryptocurrency. When Eric started his business a couple of years ago, he could charge a 100 percent markup — selling $300 in bitcoin for $600 — because buyers expected the cryptocurrency’s price to elevate, and had few options to obtain it. Nowadays, with more volatility and more competition among traders, that has dropped to around 30 percent. Paxful takes a small slice of each transaction on their service, usually about 1 percent.

In exchange for the bitcoin, the buyers typically swap gift cards, which are less traceable than dollars or yuan and, thanks to globalization, broadly useful all over the world. No physical card changes hands; Eric will get the number from the gift card and load it into an app called GiftMe, which generates a barcode that can be used at a checkout counter.

Sometimes the transaction stops there: Eric can use a gift card to buy essentials. But repeated trading requires an endless stream of bitcoin, more than he could mine or purchase on his own. So he has to use the gift cards to acquire more bitcoin, making his money on the spread between what he’s charged to buy it and what he charges to sell it.

As an intermediate step, Eric uses the gift cards he receives to buy other gift cards. This is important for a couple of reasons. First, certain gift cards are desirable to resellers overseas. Cards for electronics are especially attractive — iTunes, PlayStation, and Steam in particular. Those can be sold to customers in Brazil, Pakistan, and elsewhere. Even particular denominations are seen as attractive, because they can be more easily sold on the street. “If I take all these $10 cards, they won’t have any in stock for a month,” Eric says, rummaging through the gift card displays, explaining why he’s willing to travel 45 minutes to Walmarts in his area, just looking for the right cards.

Buying new gift cards also performs a kind of asset protection function for Eric. Scams are commonplace in the gift card trading world. Eric tries to engage in due diligence with his buyers, checking their prior transactions on Paxful. (If there are disputes about transactions, Paxful will help settle them with a court-like process.) He delays the release of bitcoin to his clients until he spends every last cent physically in a store, to ensure that the transaction is legitimate. But exchanging gift cards for gift cards adds to his security. “It’s so I have a card that no one but me and whoever I’m selling it to has seen,” he says. “I do try to avoid getting burned, but also try to avoid being part of burning someone else.”

Armed with fresh cards, Eric then sells them to accumulate more bitcoin. Again, the cards don’t actually change hands; Eric sends the codes through WhatsApp or another messaging system. The margin between what Eric charges for bitcoin and what others charge him represents his profit. Eric, because of how long he’s been in the business, has become adept at finding the best spreads, whereas his customers just want their bitcoin. On his trade with the Kenyan for the $400 gift card, he charged a 28 percent markup, and flipped the cards for bitcoin at a 25 percent markup. He walked away with a 3 percent margin, or $12.

If Eric can replicate that, he can make a living wage; some days, he’ll sell as much as $12,000 in bitcoin, which can translate to $300 or $400. Eric estimates that thousands of people exist in this informal economy, whether selling gift cards on the street, to pawn shops, or through online exchanges. Illicitly acquired gift cards have even been used to pay for opioids.

Technically speaking, reselling gift cards violates the terms of service. Everything else Eric does merely involves trading one legal thing of value for another. But he is very open about the nature of the world he traffics in. “I might sound to you like a scammer,” he says. “Don’t worry, I won’t take it the wrong way.”

The prevalence of illicit activity with gift cards, which invites a crackdown, has posed a threat to his career, with the only saving grace being the relative indifference at Walmart.

WALMART WAS NOT originally Eric’s favorite store to carry out his business. “I was on a first-name basis with everybody at Best Buy and Target for a long time,” he says. But over the summer, he went to ring up an order at a self-checkout counter at Target, and discovered that the company no longer allowed people to buy gift cards with other gift cards. “It changed overnight. The people at the stores were blindsided.” Days later, the same thing happened with Best Buy.

The companies, which do a lot of business in gift cards, had good reason to restrict purchases. A Federal Trade Commission bulletin in May warned Americans of an epidemic of gift card fraud. Specifically, the FTC highlighted callers claiming to be with the IRS or a family member and asking for payments in gift cards. Unsuspecting victims then buy gift cards and hand over the codes. Scammers can use them to either buy goods and services, or flip them in the resale market while simultaneously draining them of funds, making money twice on the same card.

This is just one way gift cards can lead to fraud. “Another way would be hacking accounts: People get the account numbers and take the balance off them,” said Joyce Carter, a vice president with Member Access Pacific, which manages gift and other card programs for businesses and credit unions. This can be done manually, by stealing cards at stores or memorizing card numbers at the sale display, or through more sophisticated means, like computer-aided phishing for card numbers or counterfeiting. There is rich variety in the scams.

Buying gift cards with other gift cards launders fraudulent or illegally obtained card codes into new, legitimate ones. It’s a common method for scam artists. “That type of fraud is happening a lot,” said Carter. According to the National Retail Federation, organized retail crime, which includes but is not limited to gift card fraud, costs retailers $726,351 for every $1 billion in sales.

Though retailers have traditionally not been on the hook for gift card fraud, that liability has shifted somewhat with the advent of chip readers at retail outlets. In particular, merchants that allow customers to swipe cards instead of reading them with chips face chargebacks from issuers on counterfeit transactions. Because of these new rules, retailers started to require that all gift card purchases be made in cash.

In a statement, Target spokesperson Danielle Schumann said the company “takes a comprehensive approach to preventing gift card scams that includes partnerships with law enforcement, technology enhancements and team member training.” That includes barring gift card purchases with other gift cards, as laid out on the Target website. Best Buy did not respond to inquiries, but their website notes that gift card purchases are limited to $500, and Eric’s experience indicates that they no longer let customers make gift-card-for-gift-card swaps.

Eric claimed to me that Walmart, prior to this week, had no restrictions on purchasing gift cards with gift cards. And indeed, I watched him pull it off.

After Eric got the $400 Walmart gift card code from the bitcoin buyer in Kenya, he pasted it into the GiftMe app, generating a bar code. He picked up seven $10 PlayStation cards, and a handful of $20 and $30 cards from PlayStation and Steam. We went to pay at the counter, and the sales clerk methodically scanned and activated the stack of gift cards. Eric was able to pay with the $400 Walmart gift card he’d purchased seconds earlier from someone halfway around the world. He didn’t have to show ID or the physical card. “You have a nice day,” Eric said to the clerk upon leaving.

Eric paid for the gift card used for his purchases. But it could just as easily have been a counterfeit, or a clone, or a stolen card, laundered through Walmart’s transaction into something legitimate. Back in the parking lot, Eric told me, “I walk out of Walmart all the time thinking that someone like me, with less scruples, could be walking out, too, without getting hassled.”

When I asked Carter about Walmart’s practices, she responded that the retailer should be more mindful of fraud. “If I’m buying more than five or six gift cards, [Walmart] might want to think about security,” she said.

Though Walmart has relatively more liability for gift card shenanigans, Carter said the burden remains disproportionately placed on consumer victims, and in particular the issuers that allow their card to be sold at Walmart. “They’re the ones taking the most risk. Most of the time the retailer doesn’t have anything to lose when it comes to fraud.”

Eric’s other interactions with Walmart left him skeptical that the company has much interest in preventing gift card fraud. Recently, a scammer tried to sell him two $1,000 Walmart gift cards, and when he checked them, he saw they were already being spent down online. “These were online orders that hadn’t shipped yet; Walmart could stop the orders to stop the rip-off,” he said. “They had no interest. I got all the way to a supervisor, and he said, ‘We don’t involve ourselves in a consumer’s personal business.’ But it’s fraud! They’re being used to facilitate fraud.”

In other words, Eric says, Walmart views gift cards as cash, and it doesn’t go around wondering whether purchases at their stores are made with stolen dollars. This is true of most retailers. “To them, revenue is revenue,” Eric said. “They very specifically don’t give a fuck about crimes involving their store if they’re not directly liable or directly hurt.” It can also be difficult to solve those crimes, putting a Walmart employee in the position of adjudicating which owner of the $1,000 gift card has the legal right to use it.

In October, Walmart spokesperson Randy Hargrove said in a statement to The Intercept, “We take this issue seriously and have measures designed to help guard against these types of crimes. Like many retailers, we are looking at this issue, the controls we have in place, and we are continuously working to enhance our gift card program to better serve and protect customers.”

It turns out that Walmart was more involved in reforming its practices than I knew. After a year-long investigation by the attorneys general of Pennsylvania and New York, Walmart, Best Buy, and Target announced new nationwide policies to deal with gift cards. Reuters reported that the changes would lead to “prohibiting the redemption of store-branded gift cards for other gift cards” — exactly what Eric wanted to happen.

That’s not quite right. As Pennsylvania Attorney General Josh Shapiro detailed in a press release, the main changes included limits to the monetary value that gift cards are sold for, and how much money can be loaded onto a gift card. As for trading gift cards for gift cards, there are restrictions on the purchase of iTunes, Steam, or Google Play gift cards, some of the main ones sold into the black market.",,,,,
Google and Facebook Ended Mandatory Arbitration for Sexual Harassment Claims. Will Workers Outside the Tech Industry Benefit?,In partnership with,,,,,
Amazon’s Accent Recognition Technology Could Tell the Government Where You’re From,"AT THE BEGINNING of October, Amazon was quietly issued a patent that would allow its virtual assistant Alexa to decipher a user’s physical characteristics and emotional state based on their voice. Characteristics, or “voice features,” like language accent, ethnic origin, emotion, gender, age, and background noise would be immediately extracted and tagged to the user’s data file to help deliver more targeted advertising.

The algorithm would also consider a customer’s physical location — based on their IP address, primary shipping address, and browser settings — to help determine their accent. Should Amazon’s patent become a reality, or if accent detection is already possible, it would introduce questions of surveillance and privacy violations, as well as possible discriminatory advertising, experts said.

The civil rights issues raised by the patent are similar to those around facial recognition, another technology Amazon has used as an anchor of its artificial intelligence strategy, and one that it controversially marketed to law enforcement. Like facial recognition, voice analysis underlines how existing laws and privacy safeguards simply aren’t capable of protecting users from new categories of data collection — or government spying, for that matter. Unlike facial recognition, voice analysis relies not on cameras in public spaces, but microphones inside smart speakers in our homes. It also raises its own thorny issues around advertising that targets or excludes certain groups of people based on derived characteristics like nationality, native language, and so on (the sort of controversy that Facebook has stumbled into again and again).",,,,,
Google’s “Smart City of Surveillance” Faces New Resistance in Toronto,"AT THE BEGINNING of October, Amazon was quietly issued a patent that would allow its virtual assistant Alexa to decipher a user’s physical characteristics and emotional state based on their voice. Characteristics, or “voice features,” like language accent, ethnic origin, emotion, gender, age, and background noise would be immediately extracted and tagged to the user’s data file to help deliver more targeted advertising.

The algorithm would also consider a customer’s physical location — based on their IP address, primary shipping address, and browser settings — to help determine their accent. Should Amazon’s patent become a reality, or if accent detection is already possible, it would introduce questions of surveillance and privacy violations, as well as possible discriminatory advertising, experts said.

The civil rights issues raised by the patent are similar to those around facial recognition, another technology Amazon has used as an anchor of its artificial intelligence strategy, and one that it controversially marketed to law enforcement. Like facial recognition, voice analysis underlines how existing laws and privacy safeguards simply aren’t capable of protecting users from new categories of data collection — or government spying, for that matter. Unlike facial recognition, voice analysis relies not on cameras in public spaces, but microphones inside smart speakers in our homes. It also raises its own thorny issues around advertising that targets or excludes certain groups of people based on derived characteristics like nationality, native language, and so on (the sort of controversy that Facebook has stumbled into again and again).",,,,,
Election Insecurity,"SO MUCH ATTENTION in the midterm elections this year has focused on the gubernatorial race in Georgia between Republican Brian Kemp and Democrat Stacey Abrams that the race for secretary of state, the office Kemp is vacating, has gone largely ignored.

It’s arguably the more important race, since this is the office that will control the state’s voter registration database and any purges made to the voter roll going forward. Equally important, it’s the office that will be responsible for programming all of the state’s currently paperless voting machines that can’t be audited, though Georgia will be looking to replace these machines with an undetermined model next year. Both of these factors could make Georgia a hotbed for voter suppression tactics and vote-counting integrity in the 2020 presidential elections, experts said.",,,,,
Facebook Allowed Advertisers to Target Users Interested in “White Genocide” — Even in Wake of Pittsburgh Massacre,"APPARENTLY FUELED BY anti-Semitism and the bogus narrative that outside forces are scheming to exterminate the white race, Robert Bowers murdered 11 Jewish congregants as they gathered inside their Pittsburgh synagogue, federal prosecutors allege. But despite long-running international efforts to debunk the idea of a “white genocide,” Facebook was still selling advertisers the ability to market to those with an interest in that myth just days after the bloodshed.

Earlier this week, The Intercept was able to select “white genocide conspiracy theory” as a pre-defined “detailed targeting” criterion on the social network to promote two articles to an interest group that Facebook pegged at 168,000 users large and defined as “people who have expressed an interest or like pages related to White genocide conspiracy theory.” The paid promotion was approved by Facebook’s advertising wing. After we contacted the company for comment, Facebook promptly deleted the targeting category, apologized, and said it should have never existed in the first place.

Our reporting technique was the same as one used by the investigative news outlet ProPublica to report, just over one year ago, that in addition to soccer dads and Ariana Grande fans, “the world’s largest social network enabled advertisers to direct their pitches to the news feeds of almost 2,300 people who expressed interest in the topics of ‘Jew hater,’ ‘How to burn jews,’ or, ‘History of “why jews ruin the world.”’” The report exposed how little Facebook was doing to vet marketers, who pay the company to leverage personal information and inclinations in order to gain users’ attention — and who provide the foundation for its entire business model. At the time, ProPublica noted that Facebook “said it would explore ways to fix the problem, such as limiting the number of categories available or scrutinizing them before they are displayed to buyers.” Rob Leathern, a Facebook product manager, assured the public, “We know we have more work to do, so we’re also building new guardrails in our product and review processes to prevent other issues like this from happening in the future.”

Leathern’s “new guardrails” don’t seem to have prevented Facebook from manually approving our ad buy the same day it was submitted, despite its explicit labeling as “White Supremacy – Test.”",,,,,
Google Dragonfly,"GOOGLE CEO SUNDAR PICHAI has refused to answer a list of questions from U.S. lawmakers about the company’s secretive plan for a censored search engine in China.

In a letter newly obtained by The Intercept, Pichai told a bipartisan group of six senators that Google could have “broad benefits inside and outside of China,” but said he could not share details about the censored search engine because it “remains unclear” whether the company “would or could release a search service” in the country.

Pichai’s letter contradicts the company’s search engine chief, Ben Gomes, who informed staff during a private meeting that the company was aiming to release the platform in China between January and April 2019. Gomes told employees working on the Chinese search engine that they should get it ready to be “brought off the shelf and quickly deployed.”

According to sources and confidential Google documents, the search engine for China, codenamed Dragonfly, was designed to comply with the strict censorship regime imposed by China’s ruling Communist Party. It would restrict people’s access to broad categories of information, blacklisting phrases like “human rights,” “student protest,” and “Nobel Prize.”

The Chinese platform was designed to link people’s searches to their phone number, track their location, and then share that data with a Chinese partner company. This would make it easy to track individual users’ searches, raising concerns that any person in China using Google to seek out information banned by the government could be at risk of interrogation or detention if security agencies were to obtain copies of their search records.",,,,,
Making a Killing,"WHILE THE WORLD is grappling with the apparent grisly murder of Saudi dissident and Washington Post journalist Jamal Khashoggi, the Saudi government decided to announce a new band of influential Western allies, some plucked from the uppermost echelon of Silicon Valley, who would serve on an advisory board for Neom, the Saudi government’s improbable, exorbitant plan to build a “mega city” in the desert.

But almost as soon as his participation was revealed, Sam Altman, head of famed venture capital firm Y Combinator, announced that he is “suspending” his role with Neom, while two others on the star-studded list denied that they were participating.

Altman, along with legendary tech investor Marc Andreessen, notorious Uber founder (and ousted ex-CEO) Travis Kalanick, IDEO CEO Tim Brown, and Dan Doctoroff of Sidewalk Labs, a subsidiary of Google-owner Alphabet, were among those listed as members of the new board. Given that the United States itself is now forced into a momentarily uncomfortable spot given its longtime affection for and deep political ties to the Saudis, this was a less than ideal time for Americans to come out as friends of the kingdom.",,,,,
Government Report: “An Entire Generation” of American Weapons Is Wide Open to Hackers,"A NEW REPORT from the U.S. Government Accountability Office brings both good and bad news. For governments around the world that might like to sabotage America’s military technology, the good news is that this would be all too easy to do: Testers at the Department of Defense “routinely found mission-critical cyber vulnerabilities in nearly all weapon systems that were under development” over a five-year period, the report said. For Americans, the bad news is that up until very recently, no one seemed to care enough to fix these security holes.

In 1991, the report noted, the U.S. National Research Council warned that “system disruptions will increase” as the use of computers and networks grows and as adversaries attack them. The Pentagon more or less ignored this and at least five subsequent warnings on the subject, according to the GAO, and hasn’t made a serious effort to safeguard the vast patchwork of software that controls planes, ships, missiles, and other advanced ordnance against hackers.

The sweeping report drew on nearly 30 years of published research, including recent assessments of the cybersecurity of specific weapon systems, as well as interviews with personnel from the Department of Defense, the National Security Agency, and weapons-testing bodies. It covered a broad span of American weapons, examining systems at all of the service branches and in space.

The report found that “mission-critical cyber vulnerabilities” cropped up routinely during weapons development and that test teams “easily” took over real systems without detection “using relatively simple tools and techniques,” exploiting “basic issues such as poor password management and unencrypted communications.” Testers could also download and delete data, in one cases exfiltrating 100 gigabytes of material, and could tap into operators’ terminals, in one instance popping up computer dialogs asking the operators “to insert two quarters to continue.” But a malicious attacker could pull off much worse than jokes about quarters, warns the GAO: “In one case, the test team took control of the operators’ terminals. They could see, in real-time, what the operators were seeing on their screens and could manipulate the system.”

Posing as surrogates for, say, Russian or Chinese military hackers, testers sometimes found easy victories. “In some cases,” the GAO found, “simply scanning a system caused parts of the system to shut down,” while one “test team was able to guess an administrator password in nine seconds.” The testers found embarrassing, elementary screw-ups of the sort that would get a middle school computer lab administrator in trouble, to say nothing of someone safeguarding lethal weapon systems. For example, “multiple weapon systems used commercial or open source software, but did not change the default password when the software was installed, which allowed test teams to look up the password on the Internet.”",,,,,
Google Dragonfly,"“WE HAVE TO be focused on what we want to enable,” said Ben Gomes, Google’s search engine chief. “And then when the opening happens, we are ready for it.”

It was Wednesday, July 18, and Gomes was addressing a team of Google employees who were working on a secretive project to develop a censored search engine for China, which would blacklist phrases like “human rights,” “student protest,” and “Nobel Prize.”

“You have taken on something extremely important to the company,” Gomes declared, according to a transcript of his comments obtained by The Intercept. “I have to admit it has been a difficult journey. But I do think a very important and worthwhile one. And I wish ourselves the best of luck in actually reaching our destination as soon as possible.”

Gomes joked about the unpredictability of President Donald Trump and groaned about the ongoing trade war between the U.S. and China, which has slowed down Google’s negotiations with Communist Party officials in Beijing, whose approval Google requires to launch the censored search engine.",,,,,
How an Algorithm Kicks Small Businesses Out of the Food Stamps Program on Dubious Fraud Charges,"“WE HAVE TO be focused on what we want to enable,” said Ben Gomes, Google’s search engine chief. “And then when the opening happens, we are ready for it.”

It was Wednesday, July 18, and Gomes was addressing a team of Google employees who were working on a secretive project to develop a censored search engine for China, which would blacklist phrases like “human rights,” “student protest,” and “Nobel Prize.”

“You have taken on something extremely important to the company,” Gomes declared, according to a transcript of his comments obtained by The Intercept. “I have to admit it has been a difficult journey. But I do think a very important and worthwhile one. And I wish ourselves the best of luck in actually reaching our destination as soon as possible.”

Gomes joked about the unpredictability of President Donald Trump and groaned about the ongoing trade war between the U.S. and China, which has slowed down Google’s negotiations with Communist Party officials in Beijing, whose approval Google requires to launch the censored search engine.",,,,,
Big Tech Is Appealing to Congress to Help Get Around California’s New Online Privacy Law,"AFTER CALIFORNIA PASSED the most sweeping online privacy law in the nation this summer, big tech went back to the state legislature to weaken it. While that effort fizzled before the end of the state’s legislative session, a more insidious strategy emerged this week: going around California and appealing to Congress.

Alastair Mactaggart, who led the California effort, told The Intercept that a Wednesday hearing in Congress left him concerned that Congress might pre-empt the state legislation at the behest of giant tech firms.

“Tech has had zero regulation,” Mactaggart said in an interview. “For them it’s been this Wild West of being able to monetize information any which way. They will pull out all the stops to try to get back to where they were.”

Mactaggart, a Bay Area real estate developer, became an unlikely activist when he bankrolled a ballot measure that, among other things, would require tech companies to reveal what personal information they collected on users, allow users to opt out of the sale of their data to third parties, and impose fines for data breaches. Tech firms fought it vigorously, but were hampered by a series of scandals like Facebook’s release of data to Cambridge Analytica, and widespread popular support for some limits on persistent surveillance.

Tech firms, fearing being locked into a policy they could only change at the ballot, encouraged the state legislature to get involved. The California House and Senate passed a law substantially similar to the initiative, with unanimous support in both chambers. Gov. Jerry Brown signed it in June.

The law doesn’t take effect until January 2020, and big tech’s hope was to water it down before that date. Industry representatives went to Congress this week after failing to get California lawmakers to narrow the definition of “selling” data, which would have rendered some of the protections of the law moot.

The Senate Commerce Committee held a hearing on Wednesday where leaders of six tech and telecom companies — Amazon, Google, Apple, Twitter, AT&T, and Charter Communications — endorsed a federal consumer privacy standard. In their conception, this would pre-empt any state data protection laws.

It’s an eerie echo of the federal pre-emption that Wall Street banks received and used to great effect during the run-up to the housing bubble. In 2002, Georgia passed an anti-predatory lending law, and both the Office of Thrift Supervision and the Office of the Comptroller of the Currency ruled that banks they regulated simply did not have to comply with it. This created a chilling effect, as states declined to crack down on the rampant fraud in the mortgage industry. And the financial crisis was the result.

At the hearing, the companies criticized the California statute, in particular its definition of “personal information,” which they consider overbroad. Amazon vice president Andrew DeVore called the statute “confusing and difficult to comply with,” adding that it “may actually undermine important privacy-protective practices.” Alone among the witnesses, Apple’s Bud Tribble did say that while federal legislation should pre-empt state law, it must also “meet the bar of protecting consumers meaningfully.” However, he did not elaborate on what that protection should entail.",,,,,
Google Executive Declines to Say If China Censors Its Citizens,"EIGHT YEARS AGO, when Google announced that it would pull out of China, the company released a statement explaining that the Chinese government had been “crystal clear” that “self-censorship is a non-negotiable legal requirement” for operating in the country.

But now that the firm is considering a relaunch in China with a new search platform, an initiative codenamed Project Dragonfly, Google is hedging on whether they believe the Chinese government censors its citizens.

Keith Enright, Google’s chief privacy officer, discussed the China project under questioning from several senators during a commerce committee hearing on Wednesday.

“In your opinion, does China engage in censoring its citizens?” asked Sen. Ted Cruz, R-Texas, during the hearing.

“As the privacy representative of Google,” said Enright, “I am not sure I have an informed opinion on that question.”",,,,,
The Government Wants Airlines to Delay Your Flight So They Can Scan Your Face,"OMNIPRESENT FACIAL RECOGNITION has become a golden goose for law enforcement agencies around the world. In the United States, few are as eager as the Department of Homeland Security. American airports are currently being used as laboratories for a new tool that would automatically scan your face — and confirm your identity with U.S. Customs and Border Protection — as you prepare to board a flight, despite the near-unanimous objections from privacy advocates and civil libertarians, who call such scans invasive and pointless.

According to a new report on the Biometric Entry-Exit Program by DHS itself, we can add another objection: Your flight could be late.

Although the new report, published by Homeland Security’s Office of the Inspector General, is overwhelmingly supportive in its evaluation of airport-based biometric surveillance — the practice of a computer detecting your face and pairing it with everything else in the system — the agency notes some hurdles from a recent test code-named “Sprint 8.” Among them, the report notes with palpable frustration, was that airlines insist on letting their passengers depart on time, rather than subjecting them to a Homeland Security surveillance prototype plagued by technical issues and slowdowns:

Demanding flight departure schedules posed other operational problems that significantly hampered biometric matching of passengers during the pilot in 2017. Typically, when incoming flights arrived behind schedule, the time allotted for boarding departing flights was reduced. In these cases, CBP allowed airlines to bypass biometric processing in order to save time. As such, passengers could proceed with presenting their boarding passes to gate agents without being photographed and biometrically matched by CBP first. We observed this scenario at the Atlanta Hartsfield-Jackson International Airport when an airline suspended the biometric matching process early to avoid a flight delay. This resulted in approximately 120 passengers boarding the flight without biometric confirmation.",,,,,
Google Dragonfly,"A SCIENTIST WHO quit Google over its plan to build a censored search engine in China has told U.S. senators that some company employees may have “actively subverted” an internal privacy review of the system.

Jack Poulson resigned from Google in August after The Intercept reported that a group of the internet giant’s staffers was secretly working on a search engine for China that would remove content about subjects such as human rights, democracy, peaceful protest, and religion. “I view our intent to capitulate to censorship and surveillance demands in exchange for access to the Chinese market as a forfeiture of our values and governmental negotiating position across the globe,” Poulson told his bosses.

Now, Poulson has sent a letter to members of the Senate Committee on Commerce, Science, and Transportation ahead of a hearing on Wednesday at which Keith Enright, Google’s chief privacy officer, is scheduled to appear. Despite a major internal and external backlash over a period of almost two months, Google has so far refused to publicly address questions about its China censorship plan, code-named Dragonfly. The appearance of Enright on Capitol Hill is likely to be the first time a representative of the company is forced to provide answers about the project.

In his letter to the senators, Poulson said that there has been “a pattern of unethical and unaccountable decision making from company leadership” at Google. He called on the lawmakers to pressure Enright to respond to concerns raised by 14 leading human rights groups, who said in late August that Dragonfly could result in Google “directly contributing to, or [becoming] complicit in, human rights violations.”",,,,,
United Nations Accidentally Exposed Passwords and Sensitive Information to the Whole Internet,"THE UNITED NATIONS accidentally published passwords, internal documents, and technical details about websites when it misconfigured popular project management service Trello, issue tracking app Jira, and office suite Google Docs.

The mistakes made sensitive material available online to anyone with the proper link, rather than only to specific users who should have access. Affected data included credentials for a U.N. file server, the video conferencing system at the U.N.’s language school, and a web development environment for the U.N.’s Office for the Coordination of Humanitarian Affairs. Security researcher Kushagra Pathak discovered the accidental leak and notified the U.N. about what he found a little over a month ago. As of today, much of the material appears to have been taken down.

In an online chat, Pathak said he found the sensitive information by running searches on Google. The searches, in turn, produced public Trello pages, some of which contained links to the public Google Docs and Jira pages.

Trello projects are organized into “boards” that contain lists of tasks called “cards.” Boards can be public or private. After finding one public Trello board run by the U.N., Pathak found additional public U.N. boards by using “tricks like by checking if the users of one Trello board are also active on some other boards and so on.” One U.N. Trello board contained links to an issue tracker hosted on Jira, which itself contained even more sensitive information. Pathak also discovered links to documents hosted on Google Docs and Google Drive that were configured to be accessible to anyone who knew their web addresses. Some of these documents contained passwords.",,,,,
Facebook Brushed Off the U.N. Five Separate Times Over Calls for Murder of Human Rights Worker,"FACEBOOK’S TOTAL INABILITY to keep itself from being a convenient tool for genocidal incitement in Myanmar has been well-covered, now a case study in how a company with such immense global power can so completely fail to use it for good. But a new report released this week by the United Nations fact-finding mission in Myanmar, where calls for the slaughter of Muslims have enjoyed all the convenience of a modern Facebook signal boost, makes clear just how unprepared the company was for its role in an ethnic massacre.

In a recent New Yorker profile of Facebook founder and CEO Mark Zuckerberg, he responds to his company’s role in the crisis — which the U.N. has described as “determining” — with all the urgency and guilt of a botched restaurant order: “I think, fundamentally, we’ve been slow at the same thing in a number of areas, because it’s actually the same problem. But, yeah, I think the situation in Myanmar is terrible.” Zuckerberg added that the company needs to “move from what is fundamentally a reactive model” when it comes to blocking content that’s fueled what the U.N. described last year as a “textbook example of ethnic cleansing.”

The new report reveals just how broken this “reactive model” truly is.

According to the 479-page document, and as flagged in a broader Guardian story this week, “the Mission itself experienced a slow and ineffective response from Facebook when it used the standard reporting mechanism to alert the company to a post targeting a human rights defender for his alleged cooperation with the Mission.” What follows is the most clear-cut imaginable violation of Facebook’s rules, followed by the most abject failure to enforce them when it mattered most:

The post described the individual as a “national traitor”, consistently adding the adjective “Muslim”. It was shared and re-posted over 1,000 times. Numerous comments to the post explicitly called for the person to be killed, in unequivocal terms: “Beggar-dog species. As long as we are feeling sorry for them, our country is not at peace. These dogs need to be completely removed.” “If this animal is still around, find him and kill him. There needs to be government officials in NGOs.” “Wherever they are, Muslim animals don’t know to be faithful to the country.” “He is a Muslim. Muslims are dogs and need to be shot.” “Don’t leave him alive. Remove his whole race. Time is ticking.” The Mission reported this post to Facebook on four occasions; in each instance the response received was that the post was examined but “doesn’t go against one of [Facebook’s] specific Community Standards”. The Mission subsequently sent a message to an official Facebook email account about the matter but did not receive a response. The post was finally removed several weeks later but only through the support of a contact at Facebook, not through the official channel. Several months later, however, the Mission found at least 16 re-posts of the original post still circulating on Facebook. In the weeks and months after the post went online, the human rights defender received multiple death threats from Facebook users, warnings from neighbours, friends, taxi drivers and other contacts that they had seen his photo and the posts on Facebook, and strong suggestions that the post was an early warning. His family members were also threatened. The Mission has seen many similar cases where individuals, usually human rights defenders or journalists, become the target of an online hate campaign that incites or threatens violence.",,,,,
Google Dragonfly,"GOOGLE BOSSES HAVE forced employees to delete a confidential memo circulating inside the company that revealed explosive details about a plan to launch a censored search engine in China, The Intercept has learned.

The memo, authored by a Google engineer who was asked to work on the project, disclosed that the search system, codenamed Dragonfly, would require users to log in to perform searches, track their location — and share the resulting history with a Chinese partner who would have “unilateral access” to the data.

The memo was shared earlier this month among a group of Google employees who have been organizing internal protests over the censored search system, which has been designed to remove content that China’s authoritarian Communist Party regime views as sensitive, such as information about democracy, human rights, and peaceful protest.

According to three sources familiar with the incident, Google leadership discovered the memo and were furious that secret details about the China censorship were being passed between employees who were not supposed to have any knowledge about it. Subsequently, Google human resources personnel emailed employees who were believed to have accessed or saved copies of the memo and ordered them to immediately delete it from their computers. Emails demanding deletion of the memo contained “pixel trackers” that notified human resource managers when their messages had been read, recipients determined.",,,,,
Google Dragonfly,"GOOGLE BUILT A prototype of a censored search engine for China that links users’ searches to their personal phone numbers, thus making it easier for the Chinese government to monitor people’s queries, The Intercept can reveal.

The search engine, codenamed Dragonfly, was designed for Android devices, and would remove content deemed sensitive by China’s ruling Communist Party regime, such as information about political dissidents, free speech, democracy, human rights, and peaceful protest.

Previously undisclosed details about the plan, obtained by The Intercept on Friday, show that Google compiled a censorship blacklist that included terms such as “human rights,” “student protest,” and “Nobel Prize” in Mandarin.

Leading human rights groups have criticized Dragonfly, saying that it could result in the company “directly contributing to, or [becoming] complicit in, human rights violations.” A central concern expressed by the groups is that, beyond the censorship, user data stored by Google on the Chinese mainland could be accessible to Chinese authorities, who routinely target political activists and journalists.

Sources familiar with the project said that prototypes of the search engine linked the search app on a user’s Android smartphone with their phone number. This means individual people’s searches could be easily tracked – and any user seeking out information banned by the government could potentially be at risk of interrogation or detention if security agencies were to obtain the search records from Google.",,,,,
Google Dragonfly,"GOOGLE BUILT A prototype of a censored search engine for China that links users’ searches to their personal phone numbers, thus making it easier for the Chinese government to monitor people’s queries, The Intercept can reveal.

The search engine, codenamed Dragonfly, was designed for Android devices, and would remove content deemed sensitive by China’s ruling Communist Party regime, such as information about political dissidents, free speech, democracy, human rights, and peaceful protest.

Previously undisclosed details about the plan, obtained by The Intercept on Friday, show that Google compiled a censorship blacklist that included terms such as “human rights,” “student protest,” and “Nobel Prize” in Mandarin.

Leading human rights groups have criticized Dragonfly, saying that it could result in the company “directly contributing to, or [becoming] complicit in, human rights violations.” A central concern expressed by the groups is that, beyond the censorship, user data stored by Google on the Chinese mainland could be accessible to Chinese authorities, who routinely target political activists and journalists.

Sources familiar with the project said that prototypes of the search engine linked the search app on a user’s Android smartphone with their phone number. This means individual people’s searches could be easily tracked – and any user seeking out information banned by the government could potentially be at risk of interrogation or detention if security agencies were to obtain the search records from Google.",,,,,
Are New York’s Free LinkNYC Internet Kiosks Tracking Your Movements?,"LINKNYC KIOSKS HAVE become a familiar eyesore to New Yorkers. Over 1,600 of these towering, nine-and-a-half-foot monoliths — their double-sided screens festooned with ads and fun facts — have been installed across the city since early 2016. Mayor Bill de Blasio has celebrated their ability to provide “the fastest and largest municipal Wi-Fi network in the world” as “a critical step toward a more equal, open, and connected city for every New Yorker, in every borough.” Anyone can use the kiosks’ Android tablets to search for directions and services; they are also equipped with charging stations, 911 buttons, and phones for free domestic calls.

But even as the kiosks have provided important services to connect New Yorkers, they may also represent a troubling expansion of the city’s surveillance network, potentially connecting every borough to a new level of invasive monitoring. Each kiosk has three cameras, 30 sensors, and heightened sight lines for viewing above crowds.

Since plans for LinkNYC were first unveiled, journalists, residents, and civil liberties experts have raised concerns that the internet kiosks might be storing sensitive data about its users and possibly tracking their movements. For the last two years, the American Civil Liberties Union, Electronic Frontier Foundation, and a small but vocal group of activists — including ReThink LinkNYC, a grassroots anti-surveillance group, and the anonymous Stop LinkNYC coalition — have highlighted the kiosk’s potential to track locations, collect personal information, and fuel mass surveillance.

Now an undergraduate researcher has discovered indications in LinkNYC code — accidentally made public on the internet — that LinkNYC may be actively planning to track users’ locations.",,,,,
IBM Used NYPD Surveillance Footage to Develop Technology That Lets Police Search by Skin Color,"LINKNYC KIOSKS HAVE become a familiar eyesore to New Yorkers. Over 1,600 of these towering, nine-and-a-half-foot monoliths — their double-sided screens festooned with ads and fun facts — have been installed across the city since early 2016. Mayor Bill de Blasio has celebrated their ability to provide “the fastest and largest municipal Wi-Fi network in the world” as “a critical step toward a more equal, open, and connected city for every New Yorker, in every borough.” Anyone can use the kiosks’ Android tablets to search for directions and services; they are also equipped with charging stations, 911 buttons, and phones for free domestic calls.

But even as the kiosks have provided important services to connect New Yorkers, they may also represent a troubling expansion of the city’s surveillance network, potentially connecting every borough to a new level of invasive monitoring. Each kiosk has three cameras, 30 sensors, and heightened sight lines for viewing above crowds.

Since plans for LinkNYC were first unveiled, journalists, residents, and civil liberties experts have raised concerns that the internet kiosks might be storing sensitive data about its users and possibly tracking their movements. For the last two years, the American Civil Liberties Union, Electronic Frontier Foundation, and a small but vocal group of activists — including ReThink LinkNYC, a grassroots anti-surveillance group, and the anonymous Stop LinkNYC coalition — have highlighted the kiosk’s potential to track locations, collect personal information, and fuel mass surveillance.

Now an undergraduate researcher has discovered indications in LinkNYC code — accidentally made public on the internet — that LinkNYC may be actively planning to track users’ locations.",,,,,
Sheryl Sandberg Misled Congress About Facebook’s Conscience,"FACEBOOK CHIEF OPERATING officer Sheryl Sandberg draped herself in the star-spangled banner of American principles before today’s Senate Select Intelligence Committee hearing on social media. Sandberg proclaimed that democratic values of free expression were integral to the company’s conscience. “We would only operate in a country where we could do so in keeping with our values,” she went on. Either this was a lie told under oath, or Facebook has some pretty lousy values.",,,,,
Google Dragonfly,"LEADING HUMAN RIGHTS groups are calling on Google to cancel its plan to launch a censored version of its search engine in China, which they said would violate the freedom of expression and privacy rights of millions of internet users in the country.

A coalition of 14 organizations — including Amnesty International, Human Rights Watch, Reporters Without Borders, Access Now, the Committee to Protect Journalists, the Electronic Frontier Foundation, the Center for Democracy and Technology, PEN International, and Human Rights in China — issued the demand Tuesday in an open letter addressed to the internet giant’s CEO, Sundar Pichai. The groups said the censored search engine represents “an alarming capitulation by Google on human rights” and could result in the company “directly contributing to, or [becoming] complicit in, human rights violations.”

The letter is the latest major development in an ongoing backlash over the censored search platform, code-named Dragonfly, which was first revealed by The Intercept earlier this month. The censored search engine would remove content that China’s ruling Communist Party regime views as sensitive, such as information about political dissidents, free speech, democracy, human rights, and peaceful protest. It would “blacklist sensitive queries” so that “no results will be shown” at all when people enter certain words or phrases, according to confidential Google documents.

Google launched a censored search engine in China in 2006, but ceased operating the service in the country in 2010, citing Chinese government efforts to limit free speech, block websites, and hack Google’s computer systems. The open letter released Tuesday asks Google to reaffirm the commitment it made in 2010 to no longer provide censored search in China.",,,,,
Facebook Suspended a Latin American News Network and Gave Three Different Reasons Why,"ON AUGUST 13, FACEBOOK shut down the English-language page of Telesur, blocking access for roughly half a million followers of the leftist media network until it was abruptly reinstated two days later. Facebook has provided three different explanations for the temporary disappearing, all contradicting one another, and not a single one making sense.

Telesur was created by Venezuela’s then-President Hugo Chávez in 2005 and co-funded by hemispheric neighbors Cuba, Bolivia, Nicaragua, and Uruguay — Argentina pulled support for the web and cable property in 2016. As a state-owned media property, it exists somewhere on the same continuum as RT and Al Jazeera, though like the former, Telesur has been criticized as a nakedly partisan governmental mouthpiece, and like the latter, it does engage in real news reporting. But putting aside questions of bias and agenda, Telesur does seem to exist on a separate plane than, say, Infowars, which exists primarily to peddle its particular, patently false genre of right-wing paranoia fan fiction packaged as news (and brain pills), as opposed to some garden-variety political agenda. Unlike RT, Telesur hasn’t been singled-out for a role in laundering disinformation for military intelligence purposes, nor is it a hoax factory, à la Alex Jones.

So it was unexpected when Telesur English blinked out of existence on the 13th, and even stranger when Facebook struggled to explain its own actions. At the time of its suspension, Telesur received this boilerplate message from Facebook:

Hello,

Your Page “teleSUR English” has been removed for violating our Terms of Use. A Facebook Page is a distinct presence used solely for business or promotional purposes. Among other things, Pages that are hateful, threatening or obscene are not allowed. We also take down Pages that attack an individual or group, or that are set up by an unauthorised individual. If your Page was removed for any of the above reasons, it will not be reinstated. Continued misuse of Facebook’s features could result in the permanent loss of your account.

The Facebook Team

Later that day, a Facebook customer support agent told the network that the suspension appeared to be due to a technical glitch — a go-to explanation for the company — rather than a violation of the company’s Terms of Use, adding that the issue was “under analysis by the engineering department.”",,,,,
Google Dragonfly,"GOOGLE BOSSES HAVE broken their silence on the company’s plan to launch a censored search engine in China amid mounting internal protests over the project.

On Thursday, CEO Sundar Pichai admitted to employees during an all-hands meeting that the censorship project – code-named Dragonfly – had been “in an exploration stage for quite a while now,” according to two sources who heard his remarks. Pichai emphasized his belief that Google should return to China, but claimed that the company was “not close to launching a search product in China.” Facing employee criticism for shrouding Dragonfly in secrecy, Pichai vowed that “we’ll definitely be transparent as we get closer to actually having a plan of record.”

Google co-founder Sergey Brin also spoke at Thursday’s meeting — and remarkably stated that he knew nothing about Dragonfly until The Intercept exposed it earlier this month. Back in 2006, Google launched a censored search engine in China. But four years later, in March 2010, it pulled the service out of the country, citing Chinese government efforts to limit free speech, block websites, and hack Google’s computer systems. At that time, Brin was a vocal opponent of the censorship. During Thursday’s meeting, Brin told Google employees that Dragonfly would have “certain trade-offs” but said the process was “slow-going and complicated.”

Both Pichai and Brin’s remarks to Google employees raise a number of questions. Pichai’s attempt to portray Dragonfly as an “exploratory” project contradicts internal Google documents and statements issued by senior Google officials on Dragonfly that The Intercept has seen.",,,,,
Google Dragonfly,"GOOGLE EMPLOYEES ARE demanding answers from the company’s leadership amid growing internal protests over plans to launch a censored search engine in China.

Staff inside the internet giant’s offices have agreed that the censorship project raises “urgent moral and ethical issues” and have circulated a letter saying so, calling on bosses to disclose more about the company’s work in China, which they say is shrouded in too much secrecy, according to three sources with knowledge of the matter.

The internal furor began after The Intercept earlier this month revealed details about the censored search engine, which would remove content that China’s authoritarian government views as sensitive, such as information about political dissidents, free speech, democracy, human rights, and peaceful protest. It would “blacklist sensitive queries” so that “no results will be shown” at all when people enter certain words or phrases, leaked Google documents disclosed. The search platform is to be launched via an Android app, pending approval from Chinese officials.

The censorship plan – code-named Dragonfly – was not widely known within Google. Prior to its public exposure, only a few hundred of Google’s 88,000 employees had been briefed about the project – around 0.35 percent of the total workforce. When the news spread through the company’s offices across the world, many employees expressed anger and confusion.

Now, a letter has been circulated among staff calling for Google’s leadership to recognize that there is a “code yellow” situation – a kind of internal alert that signifies a crisis is unfolding. The letter suggests that the Dragonfly initiative violates an internal Google artificial intelligence ethical code, which says that the company will not build or deploy technologies “whose purpose contravenes widely accepted principles of international law and human rights.”",,,,,
British and Canadian Governments Accidentally Exposed Passwords and Security Plans to the Entire Internet,"BY MISCONFIGURING PAGES on Trello, a popular project management website, the governments of the United Kingdom and Canada exposed to the entire internet details of software bugs and security plans, as well as passwords for servers, official internet domains, conference calls, and an event-planning system.

The U.K. government also exposed a small quantity of code for running a government website, as well as a limited number of emails. All told, between the two governments, a total of 50 Trello pages, known on the site as “boards,” were published on the open web and indexed by Google.

The computer researcher who found the sensitive material, Kushagra Pathak, had disclosed just this past April a wide swath of additional private data exposed to the public on Trello, which is widely used by software developers, among others. That earlier disclosure revealed how, on dozens of public Trello boards run by various organizations and individuals, the information available included email and social media credentials, as well as specific information on unfixed bugs and security vulnerabilities. Pathak even found an NGO sharing login details to a donor management software database, which in turn contained, he said, personally identifiable information and financial records on donors. In both the April and new security research, the sensitive data on Trello was tracked down starting with a simple Google query.

The data exposures underscore how easy it has become to improperly leak sensitive data in the era of cloud computing. More broadly, they show how the use and development of software has become a complex endeavor, involving a wide range of independent online systems, and how this complexity itself represents a security risk, encouraging users and developers to take shortcuts intended to cut through the morass. Tools like Trello can help master the tangle of development in a safe and constructive way, but can also be misused.",,,,,
Black Hat Hacker Conference Begins to Grapple With Gender Discrimination and Sexual Assault in Cybersecurity,"BLACK HAT HAS established its reputation as a world-famous hacker conference by drawing attention to the complex problems in cybersecurity that no one else has solved, or even noticed. For the last two decades, its packed discussions, known as briefings, have made headlines by featuring highly technical experts revealing previously unknown security vulnerabilities. In recent years, hackers have demonstrated their ingenuity in overcoming a smart gun’s protections, tampering with voting machines, and shutting down critical city infrastructure.

But last week, for the first time in Black Hat’s history, the conference invited speakers to address gender discrimination, sexual assault, mental health, and substance abuse. The conference’s inaugural Community Track briefings provided a window into problems in the cybersecurity world that have long been hidden in plain sight. At the Mandala Bay Convention Center in Las Vegas, certified rape crisis counselors spoke alongside engineers and emergency physicians about some of the challenges facing hackers as people.

Many leading cybersecurity conferences, such as Black Hat, Def Con, and RSA, have seemed reluctant to outgrow their beginnings as boys’ clubs, even as their attendees have become more professional and diverse. Over the last decade, journalists, hackers, and advocates have documented a range of abusive incidents at these events. Earlier this year, I spoke to two dozen women who worked in cybersecurity, many of whom had reported incidents of harassment only to be dismissed or ignored by organizers of these events. Some said that the systemic nature of sexism at these annual events felt like a feature, not a bug. In this landscape, Black Hat’s Community Track — along with an expanded range of initiatives to support working mothers, survivors of sexual assault, queer hackers, and recovering alcoholics, among others — represented a welcome step.

Countering Stigma and Silence

Cybersecurity is, by all accounts, an emotionally demanding field. In a briefing on burnout, depression, and suicide in the hacker community, Christian Dameff, a physician, and Jay Radcliffe, a security researcher, explained the unique stressors that often accompany jobs in the information security sector, such as social isolation and abnormal sleep schedules. They cited an Information Systems Security Association study from 2018, in which 68 percent of respondents described work-life balance as a major problem. Contributing to this, they said, was a talent shortage that increased demands on an already overworked staff. The field’s self-image of strength and toughness, Radcliffe said, could also serve to further isolate employees from seeking help.

In her talk on addiction in infosec, Jamie Tomasello, an engineer at Duo Security, detailed the relationship between stress and alcoholism. She described the particular ways in which the imperative to drink overlapped with career opportunities — and an occasionally toxic conference culture. “I built rapport, trust, and respect while drinking,” she said. “I was included in conversations and projects that I wouldn’t have been in without that glass in hand.” As a recovering alcoholic, she noted, it could be difficult to attend conferences like Black Hat that were fueled by networking and afterparties at bars. She offered alternatives for managers and companies hoping to organize more inclusive events for employees struggling with alcoholism, and praised the introduction of sobriety meetings. Employee wellness programs, she stressed, needed “to extend beyond health, food, gym memberships.”

In their respective talks on the importance of neurodiversity, Joe Slowik, a veteran with post-traumatic stress disorder who now works in network defense, and Rhett Greenhagen, a senior security researcher for McAfee’s Advanced Programs Group who has Asperger’s, each echoed this call for empathy. Slowik said that he had “rage-submitted” his talk, “Demystifying PTSD in Information Security,” to the conference after coming across an article that failed to distinguish between burnout, high stress, and an actual PTSD diagnosis. He pushed back against a “one-size-fits-all” approach to dealing with survivors of sexual and military trauma. Alienation, depression, and disengagement were common symptoms, he said, and he described his daily work as giving him his confidence back. “Don’t shun, ignore, or pity. Engage,” he advised those who might work with colleagues with PTSD.

Greenhagen described the ways in which being a person with Asperger’s gave him an interest in pattern recognition — “It is extremely hard for us to not solve a puzzle,” he noted — and a major leg up as a network security analyst. While the evidence is chiefly anecdotal, it is suspected that there is a prevalence of hackers on the autism spectrum. But for all the pleasures of the demanding work, Greenhagen also acknowledged some serious downsides to working on a team. Sensory distractions and small talk interfered with his ability to do his job — an experience that was echoed by hackers with an autism spectrum disorder diagnosis who took part in an informal survey conducted by Stacy Thayer, a psychologist who spoke alongside Greenhagen. “I don’t think I’ll ever have a normal social interaction with other co-workers,” Greenhagen said. “Either there were people who absolutely adored me, even if they found stupid crap I did hilarious. Or there were people who couldn’t stand me. What made it livable was that it wasn’t a huge percentage. I had more people stand up for me and realize I have shortcomings.”

The briefings focused on mental health were by turns moving and vexing. Some of the men emphasized soul-baring, engaging their captive audience in a personal story, at the expense of skill-building. Race was notably absent as a topic of discussion. So too were the ways in which diagnoses such as alcoholism, PTSD, burnout, and Asperger’s might differently affect people across genders and identities. Given the graphic nature of the discussions about suicide in the PTSD and burnout talks, trigger warnings would have been prudent. But it was precisely the elementary nature of some of these discussions that testified to their novelty in the community — and hence their necessity.",,,,,
"As Twitter Suspends Alex Jones, Should We Worry About Silicon Valley Regulating Speech?",,,,,,
Google Dragonfly,"GOOGLE’S FORMER HEAD of free expression issues in Asia has slammed the internet giant’s plan to launch a censored search engine in China, calling it a “stupid move” that would violate widely held human rights principles.

As The Intercept first reported last week, Google has been quietly developing a search platform for China that would remove content that China’s authoritarian government views as sensitive, such as information about political opponents, free speech, democracy, human rights, and peaceful protest. It would “blacklist sensitive queries” so that “no results will be shown” at all when people enter certain words or phrases, according to internal Google documents.

Lokman Tsui, Google’s head of free expression for Asia and the Pacific between 2011 and 2014, read the leaked censorship plans and said he was disturbed by the details. “This is just a really bad idea, a stupid, stupid move,” he told The Intercept in an interview. “I feel compelled to speak out and say that this is not right.”",,,,,
Google Dragonfly,"GOOGLE’S FORMER HEAD of free expression issues in Asia has slammed the internet giant’s plan to launch a censored search engine in China, calling it a “stupid move” that would violate widely held human rights principles.

As The Intercept first reported last week, Google has been quietly developing a search platform for China that would remove content that China’s authoritarian government views as sensitive, such as information about political opponents, free speech, democracy, human rights, and peaceful protest. It would “blacklist sensitive queries” so that “no results will be shown” at all when people enter certain words or phrases, according to internal Google documents.

Lokman Tsui, Google’s head of free expression for Asia and the Pacific between 2011 and 2014, read the leaked censorship plans and said he was disturbed by the details. “This is just a really bad idea, a stupid, stupid move,” he told The Intercept in an interview. “I feel compelled to speak out and say that this is not right.”",,,,,
Google Dragonfly,"A BIPARTISAN GROUP of six U.S. senators is demanding that Google CEO Sundar Pichai explain the company’s plan to launch a censored version of its search engine in China.

Since spring 2017, the internet giant has been developing a censored Android search app to launch in the country as part of a secretive project code-named Dragonfly, The Intercept revealed on Wednesday. The app would manipulate search results in accordance with strict censorship rules in China that are mandated by the ruling Communist Party regime, which restricts people’s access to information about political opponents, free speech, democracy, human rights, and peaceful protest. The censored Google search has been designed to “blacklist sensitive queries” so that “no results will be shown” at all when people enter certain words or phrases, according to internal Google documents.

In a letter sent to Pichai on Friday, the six lawmakers called the Google plan “deeply troubling” and said that it “risks making Google complicit in human rights abuses related to China’s rigorous censorship regime.” The letter was led by Sen. Marco Rubio, R-Fla., and also signed by Sens. Mark Warner, D-Va., Tom Cotton, R-Ark., Ron Wyden, D-Ore., Cory Gardner, R-Colo., and Robert Menendez, D-N.J.

The senators write: “It is a coup for the Chinese government and Communist Party to force Google—the biggest search engine in the world—to comply with their onerous censorship requirements, and sets a worrying precedent for other companies seeking to do business in China without compromising their core values.”",,,,,
Google Dragonfly,"GOOGLE BOSSES WERE scrambling to contain leaks and internal anger on Wednesday after the company’s confidential plan to launch a censored version of its search engine in China was revealed by The Intercept.

Just a few hundred of Google’s massive 88,000-strong workforce had been briefed on the project prior to the revelations, which triggered a wave of disquiet that spread through the internet giant’s offices across the world.

Company managers responded by swiftly trying to shut down employees’ access to any documents that contained information about the China censorship project, according to Google insiders who witnessed the backlash.

“Everyone’s access to documents got turned off, and is being turned on [on a] document-by-document basis,” said one source. “There’s been total radio silence from leadership, which is making a lot of people upset and scared. … Our internal meme site and Google Plus are full of talk, and people are a.n.g.r.y.”

On a message board forum for Google employees, one staff member posted a link to The Intercept’s story alongside a note saying that they and two other members of their team had been asked to work on the Chinese censorship project, code-named Dragonfly.",,,,,
Google Dragonfly,LEIA EM PORTUGUÊS ,,,,,
"Amazon Promises “Unwavering” Commitment to Police, Military Clients Using AI Technology",LEIA EM PORTUGUÊS ,,,,,
A New Broadband Network Is Pitching Surveillance Enhancements to Cops Across the Country,"THE LATEST TECHNOLOGIES promise cops the ability to whip out a smartphone, take a snapshot of a passerby, and instantly learn if that person is in an immigration or gang database.

A federal broadband program, designed after 9/11 to improve first responder communication during emergencies, will enhance this sort of capability and integrate it into an internet “super highway” built specifically for police and public safety. The program, called FirstNet, is already expanding the surveillance options available to law enforcement agencies across the country.

According to publicly available documents, as well as interviews with program participants, stakeholders, and government researchers, FirstNet will help agencies like U.S. Customs and Border Protection communicate with local police, deliver more information to officers’ hands, accelerate the nascent law enforcement app industry, and provide public safety agencies with new privileges and powers over AT&T’s commercial broadband network.

The program will also hasten these agencies’ migration from public radio frequencies to encrypted broadband networks, potentially eliminating one resource that local newsrooms and citizens have historically relied upon to monitor police and first responders.

FirstNet is a public-private partnership that creates a dedicated lane for public safety agencies within AT&T’s existing broadband network. As of January, all U.S. states had opted in to FirstNet, meaning that they agreed not to build their own competing broadband lanes for law enforcement and public safety. Then, in March, AT&T announced that FirstNet’s core — the infrastructure that isolates police traffic from the commercial network — had become operational at last.

“It’s like having a super highway that only public safety can use,” the company wrote in a press release.

Why FirstNet?

Part of FirstNet’s mission is to create a virtual space that allows any federal, state or local law enforcement or public safety agency to communicate seamlessly with any other. Therefore, convincing as many agencies as possible to sign up for the program is key to its success.

FirstNet recently pitched U.S. Customs and Border Protection to convince the agency to subscribe to the network. In a white paper, FirstNet claims its services will provide CBP access to “photographs, real-time audio/video feeds, and databases from other state, local, or Federal agencies … to aid in the identification and apprehension of terrorists, undocumented aliens, and smugglers.” These capabilities would be offered “in times of crisis or simply day-to-day operations.”

In the pitch, FirstNet also promises to help agents “connect to critical databases to identify whether detained persons have been previously apprehended for violating immigration law by quickly and efficiently collecting biographic (e.g., name, date of birth, place of birth) and biometric information (e.g., 10-print fingerprints, photo image), which are submitted remotely to said databases.” The document also promotes FirstNet’s support of other data-heavy technologies, such as live video streaming from drones.

AT&T and FirstNet did not respond to questions about whether CBP or any other federal agency has subscribed to the program. (A recent press release indicates that some federal agencies are currently using the system, but it does not name them.) CBP did not respond to requests for comment.

Local law enforcement officials are well-aware of the new capabilities that FirstNet is offering their departments. Domingo Herraiz, programs director at the International Association of Chiefs of Police, is excited about the heightened access to federal data FirstNet promises. Herraiz told The Intercept that FirstNet will place information from fusion centers, which enable criminal intelligence-sharing between government agencies, at the fingertips of local officers. “You could have gang databases,” he said. “It’s not there [on officers’ phones] today, but it will be.”

A “Private Tunnel” for Law Enforcement and First Responders

The concept behind FirstNet — a broadband network dedicated to public safety — was inspired by the National Commission on Terrorist Attacks Upon the United States (the so-called 9/11 Commission). Its 2004 report determined that streamlined communication between different agencies and jurisdictions could have saved lives in the aftermath of the attacks on the World Trade Center. The report blamed the use of separate radio frequencies by police and firefighters for the deaths of firefighters who didn’t get the message to evacuate before the north tower collapsed.",,,,,
Former Obama Officials Help Silicon Valley Pitch the Pentagon for Lucrative Defense Contracts,"SILICON VALLEY FIRMS seeking lucrative business opportunities with the Pentagon face a range of obstacles, not least the morally fraught choice of enabling a military led by President Donald Trump with the latest technological solutions. Enter a group of former high-level officials from the Obama administration, who are helping to bridge the divide between tech firms and the Defense Department through a new company called WestExec Advisors.

“Think Scowcroft Group, Kissinger, RiceHadleyGates, Albright, but my generation,” explained Michèle Flournoy, referencing the myriad of consulting firms founded by former top national security and foreign policy officials, during an interview on Capitol Hill. Flournoy herself is the former under secretary of defense for policy and one of the co-founders of WestExec Advisors.

The sort of initiatives WestExec is posturing itself to spearhead, however, have grown controversial. In recent months, Google has faced an internal rebellion over its work with the Defense Department to deploy cutting-edge artificial intelligence technology for drone warfare, part of a Pentagon initiative known as Project Maven. The internal uprising led to Google executives announcing last month that the firm would not renew the military contract when it expires next year. And WestExec has found itself at the center of the storm, with the consultancy’s officials deeply involved with the project and wading into the media firestorm that was set off by the Google employees’ objections.",,,,,
Election Insecurity,"ON FRIDAY, Special Counsel Robert Mueller, as part of his investigation into interference with the 2016 presidential election, charged 12 Russian military intelligence officers with conducting “large-scale cyber operations to interfere with the 2016 U.S. presidential election.” The indictment contains a surprising amount of technical information about alleged Russian cyberattacks against a range of U.S. political targets, including the Democratic Congressional Campaign Committee, the Democratic National Committee, members of Hillary Clinton’s presidential campaign, the Illinois (probably) State Board of Elections, and an American election vendor, apparently VR Systems, and its government customers.

While the indictment only describes the U.S. government’s charges in this case, the specific technical evidence presented is compelling and paints by far the most detailed and plausible picture yet of what exactly occurred in 2016.

It also sheds light on what the U.S. government is capable of doing when it investigates cyberattacks, as well as how Russia’s Main Intelligence Directorate of the General Staff, or GRU, allegedly conducted the attacks — which it denies — and what operational security mistakes they made. Here are what I find to be the most compelling takeaways from the indictment.",,,,,
An Extremely Consequential Supreme Court Decision Slipped Under the Radar,"AMID HIGH-PROFILE Supreme Court rulings like the lifeline given to the practice of gerrymandering, the endorsement of Trump’s Muslim travel ban, the gutting of public sector unions, and the defense of bakers who don’t want to serve gay people, the case of Ohio v. American Express may get overlooked.

But it could prove to be one of the most consequential rulings of the decade, serving as a broad immunity cloak for Silicon Valley giants — and perhaps others — in their quest to utterly dominate the global political economy.

Which is weird, because it was a case about credit card fees.

In a 5-4 ruling along party lines on Monday, the court, featuring Justice Neil Gorsuch rather than Judge Merrick Garland, ruled that American Express did not violate antitrust laws when it wrote into its contracts with retailers that they could not offer discounts or enticements to get customers to use other forms of payment.",,,,,
The War on Immigrants,"IN THE FACE of the Trump administration’s neglect and indifference toward the reunification of the thousands of immigrant families it has forcibly separated, some lawmakers, activists, and celebrities have called for the use of DNA testing, along with other biometrics, as a means to return some 3,700 children to their parents. So far, at least two direct-to-consumer genealogy companies have heeded those calls. MyHeritage and 23andMe have both offered to donate DNA sampling kits for the purposes of verifying kinship.

“In light of the humanitarian tragedy that has taken place, in which children have been separated from their parents, we have decided to rise to the challenge and take the lead in helping these families,” Gilad Japhet, founder and CEO of MyHeritage, said in a press statement. The company is offering 5,000 free DNA tests for separated parents and children, and it plans to distribute the kits through government agencies and NGOs. Both MyHeritage and 23andMe have said that its DNA results will be processed confidentially and not shared with any third parties.",,,,,
"Google and Facebook Are Quietly Fighting California’s Privacy Rights Initiative, Emails Reveal","LOBBYISTS FOR THE largest technology and telecommunications firms have only three days to prevent the California Consumer Privacy Act, or CCPA, a ballot initiative that would usher in the strongest consumer privacy standards in the country, from going before state voters this November.

The initiative allows consumers to opt out of the sale and collection of their personal data, and vastly expands the definition of personal information to include geolocation, biometrics, and browsing history. The initiative also allows consumers to pursue legal action for violations of the law.

The idea that Californians might gain sweeping new privacy rights has spooked Silicon Valley, internet service providers, and other industries that increasingly rely on data collection, leading to a lobbying push to defeat the initiative before it gains traction. Their best hope may be to convince the sponsors of the initiative, including San Francisco real estate developer Alastair Mactaggart, to pull the proposal in exchange for compromise privacy legislation, AB 375, which would achieve some of the same goals of the initiative. Lawmakers behind the legislation, led by state Assembly Member Ed Chau, D-Monterey Park, and state Sen. Robert Hertzberg, D-Van Nuys, have promised to swiftly pass their bill this week if sponsors withdraw the CCPA.

Emails obtained by The Intercept reveal that tech giants are fighting behind the scenes to water down the privacy legislation, hoping to prevent an expensive and potentially losing ballot fight this year.

Andrea Deveau, a lobbyist for TechNet, a trade group for Google, Facebook, and other tech companies, has continually updated an ad-hoc business lobbying coalition formed to defeat the CCPA. In an update sent on Sunday evening, Deveau provided a “compilation of feedback re: the most problematic aspects of AB 375.”

In her update, she listed a vast array of changes lobbyists are still seeking, including a rewrite of the privacy law’s description of what counts as personal information, changes to the conditions under which a consumer can seek legal action, the preservation of arbitration clauses in consumer contracts, and the removal of the mandate that firms display a button on their homepage giving consumers a clear way of opting out of data collection, among other changes.",,,,,
Interpol Rolls Out International Voice Identification Database Using Samples From 192 Law Enforcement Agencies,"LAST WEEK, INTERPOL held a final project review of its speaker identification system, a four-year, 10 million euro project that has recently come to completion. The Speaker Identification Integrated Project, what they call SiiP, marks a major development in the international expansion of voice biometrics for law enforcement uses — and raises red flags when it comes to privacy.

Speaker identification works by taking samples of a known voice, capturing its unique and behavioral features, and then turning these features into an algorithmic template that’s known as a voice print or voice model. With enough voice prints and samples collected in its global audio database, Interpol’s speaker identification system will be able to upload an unknown voice and, regardless of the language it is speaking, match it to a list of likely candidates. SiiP’s database allow uploads and downloads of samples from 192 law enforcement agencies across the world.

SiiP will join Interpol’s existing fingerprint and face databases, and its key advantage will be to facilitate a quick identification process — say, of a kidnapper making a phone call — even in the absence of other identifiers. The platform also boasts the ability to filter voice samples by gender, age, language, and accent. When the audio recordings are taken from similar acoustical environments, accuracy rates can be extremely high.",,,,,
Supreme Court Rules That the U.S. Government Must Get a Warrant Before Accessing Cellphone Location Data,"IN A LANDMARK privacy decision, the Supreme Court ruled 5-4 on Friday that police must get a warrant in order to obtain your cellphone’s location data over an extended period of time.

The decision is a major victory for privacy advocates, who have long argued that the law has failed to keep pace with the amount of intrusive data we voluntarily hand over to private companies.

Chief Justice John Roberts joined the liberal justices on the court, declaring that even though the data is held by a third party, the government still needs a warrant to obtain it.

“We decline to grant the state unrestricted access to a wireless carrier’s database of physical location information,” said Roberts, writing for the majority. “In light of the deeply revealing nature of [cell-site location information], its depth, breadth, and comprehensive reach, and the inescapable and automatic nature of its collection, the fact that such information is gathered by a third party does not make it any less deserving of Fourth Amendment protection.”

The court made the ruling in the case of Timothy Carpenter, who was convicted in 2013 of robbing Radio Shack and T-Mobile stores in Michigan and Ohio. In order to build their case, the FBI obtained 127 days’ worth of location information for Carpenter’s cellphone – almost 12,900 location points – which they used to place him at the scene of the robberies.",,,,,
The American Right Wing Had Another Great Week Online,"IN A LANDMARK privacy decision, the Supreme Court ruled 5-4 on Friday that police must get a warrant in order to obtain your cellphone’s location data over an extended period of time.

The decision is a major victory for privacy advocates, who have long argued that the law has failed to keep pace with the amount of intrusive data we voluntarily hand over to private companies.

Chief Justice John Roberts joined the liberal justices on the court, declaring that even though the data is held by a third party, the government still needs a warrant to obtain it.

“We decline to grant the state unrestricted access to a wireless carrier’s database of physical location information,” said Roberts, writing for the majority. “In light of the deeply revealing nature of [cell-site location information], its depth, breadth, and comprehensive reach, and the inescapable and automatic nature of its collection, the fact that such information is gathered by a third party does not make it any less deserving of Fourth Amendment protection.”

The court made the ruling in the case of Timothy Carpenter, who was convicted in 2013 of robbing Radio Shack and T-Mobile stores in Michigan and Ohio. In order to build their case, the FBI obtained 127 days’ worth of location information for Carpenter’s cellphone – almost 12,900 location points – which they used to place him at the scene of the robberies.",,,,,
Making a Killing,"EARLIER THIS YEAR, it was reported that Elliott Broidy, previously known for his conviction in a state bribery case and his role as a top Donald Trump fundraiser, proffered meetings with the president to foreign regimes who were also potential clients of his defense firm Circinus. Little is known about Circinus, but purported company documents obtained by The Intercept contain plans to peddle social media surveillance software to repressive regimes.

The Circinus website paints the contractor as a red-blooded defender of U.S. national security: “Are you a patriot determined to keep our country — both government and private industry — safe?” its careers page reads. Circinus’s executive roster boasts experience in U.S. special forces, Homeland Security, and military intelligence. But the documents, a series of pitch decks, indicate that the company was prepared to sell what’s described as a suite of sophisticated internet-mining tools to the governments of Cyprus, Romania, Tunisia, and the United Arab Emirates, touting the ability to detect and identify online “detractors.” The recent histories of Tunisia and the UAE are rife with human rights abuses, including crackdowns against political dissent.",,,,,
The Intercept Welcomes Tech Whistleblowers as Part of a Global Partnership,"THE INTERCEPT AND European media partners are joining with The Signals Network, a whistleblower support organization, to solicit information from those who want to speak out against data-related malpractice in the technology sector.

Through this collaboration, The Intercept will work with German newspaper Die Zeit, French news website Mediapart, British newspaper The Daily Telegraph, and the global news platform WikiTribune to obtain and investigate information regarding the abuse of personal data — whether by a social network, health care company, government, marketing firm, or any other of the myriad entities that collect and process such data on an enormous scale. The Signals Network, a nonprofit founded by French media executive Gilles Raymond, said on its website that it can, in “selected … appropriate cases,” offer support to whistleblowers, including legal aid, psychological counseling, and safe shelter in case of physical threats.

As part of the effort, the news partners will share a contact number on the secure messaging platform Signal and share tips submitted to a set of email addresses.

Sources that come forward will have access to not just the newsrooms of the above news organizations, but the chance to reach their combined audiences of over 46 million readers in three languages. Those interested in contacting the consortium can find more details here, and should read these guidelines for submitting information.",,,,,
Election Insecurity,"THE INTERCEPT AND European media partners are joining with The Signals Network, a whistleblower support organization, to solicit information from those who want to speak out against data-related malpractice in the technology sector.

Through this collaboration, The Intercept will work with German newspaper Die Zeit, French news website Mediapart, British newspaper The Daily Telegraph, and the global news platform WikiTribune to obtain and investigate information regarding the abuse of personal data — whether by a social network, health care company, government, marketing firm, or any other of the myriad entities that collect and process such data on an enormous scale. The Signals Network, a nonprofit founded by French media executive Gilles Raymond, said on its website that it can, in “selected … appropriate cases,” offer support to whistleblowers, including legal aid, psychological counseling, and safe shelter in case of physical threats.

As part of the effort, the news partners will share a contact number on the secure messaging platform Signal and share tips submitted to a set of email addresses.

Sources that come forward will have access to not just the newsrooms of the above news organizations, but the chance to reach their combined audiences of over 46 million readers in three languages. Those interested in contacting the consortium can find more details here, and should read these guidelines for submitting information.",,,,,
Can #MeToo Change the Toxic Culture of Sexism and Harassment at Cybersecurity Conferences?,"CAMILLE TUUTTI CAN’T remember all the times she’s been harassed. A prominent information technology journalist and editor, Tuutti feels that her friendly and outgoing personality — a necessity in her line of work — has often been misinterpreted by men in her field as an invitation for inappropriate behavior, especially at top cybersecurity conferences, where binge drinking is encouraged. Drunk men have often put their arms around her and her colleagues. She has been asked out “a million times.” Someone tried to kiss her the first time she met him.

This April, at RSA, a leading cybersecurity conference held in San Francisco, she was walking the showroom with a male colleague when a male stranger asked her what she was wearing to bed. She noticed, too, that vendors at the show assumed that she didn’t know what she was talking about and that her colleague did. And despite organizers’ previous attempts to implement a dress code, many of the booths featured “booth babes” — scantily clad models hired to attract men to vendors’ wares. “It was so tone-deaf, especially in 2018 and especially in the wake of #MeToo,” Tuutti said.

The casual sexism Tuutti encountered at RSA is not atypical of big-league hacker and cybersecurity conferences. While there are no precise statistics available about harassment at these events, anecdotal reports like Tuutti’s have been widespread and documented for years.

The Intercept spoke to nearly two dozen women across the industry who recounted experiences ranging from uncomfortable to traumatic at conferences such as Def Con and Black Hat, held each year in Las Vegas, and RSA, held worldwide. The women who spoke to The Intercept had encountered a variety of offenses, from suggestive commentary and drunken come-ons to groping and assault. Some of the women, among whom are renowned journalists, CEOs, diversity advocates, and hackers, said that even if their own status had shielded them from some of the worst behavior, they had all heard troubling stories from younger colleagues, peers, and friends.",,,,,
Drone Wars,"GOOGLE EXECUTIVES ANNOUNCED to company staff this morning that the tech giant won’t renew its contract to work on Project Maven, the controversial Pentagon program designed to provide the military with artificial intelligence technology used to help drone operators identify images on the battlefield. Google will continue work on the project through March 2019, according to multiple people with knowledge of the announcement, but once the 18-month contract concludes, it will not be renewed.

The company, however, has not committed to forego signing other military contracts dealing with artificial intelligence, according to multiple people with knowledge of the decision. Google declined to comment for this story.",,,,,
Election Insecurity,"JUST DAYS BEFORE the 2016 presidential election, hackers identified by the National Security Agency as working for Russia attempted to breach American voting systems. Among their specific targets were the computers of state voting officials, which they had hoped to compromise with malware-laden emails, according to an intelligence report published previously by The Intercept.

Now we know what those emails looked like.

An image of the malicious email, provided to The Intercept in response to a public records request in North Carolina, reveals precisely how hackers, who the NSA believed were working for Russian military intelligence, impersonated a Florida-based e-voting vendor and attempted to trick its customers into opening malware-packed Microsoft Word files.",,,,,
Drone Wars,"JUST DAYS BEFORE the 2016 presidential election, hackers identified by the National Security Agency as working for Russia attempted to breach American voting systems. Among their specific targets were the computers of state voting officials, which they had hoped to compromise with malware-laden emails, according to an intelligence report published previously by The Intercept.

Now we know what those emails looked like.

An image of the malicious email, provided to The Intercept in response to a public records request in North Carolina, reveals precisely how hackers, who the NSA believed were working for Russian military intelligence, impersonated a Florida-based e-voting vendor and attempted to trick its customers into opening malware-packed Microsoft Word files.",,,,,
An Advocacy Group for Startups Is Funded by Google and Run by Ex-Googlers,"A WASHINGTON-BASED ADVOCACY organization that purports to be a voice for startup tech companies is actually a sock puppet for Google, according to a report released Wednesday that details numerous links between the two.

According to the report, startup advocacy group Engine has at least seven former Google employees and consultants on its board of directors and advisory board. Its three founders all previously worked at Google; they founded a startup incubator that Google eventually bought. Google has given Engine an undisclosed amount of funding over the past five years. The two share a lobbying firm called S-3 Group that has worked for both Engine and Google. The initial launch party for Engine in 2011 had attendees RSVP to a Google email address, which is reserved primarily for employees, unlike the Gmail address that is offered to the public.

On numerous issues, from patent reform, anti-piracy efforts, and high-skilled immigration, to the recent changes to Section 230 of the Communications Decency Act, Engine’s advocacy and Google’s stated policy preferences are in alignment, the report explains. Google even funded a research paper that Engine later released.

“Public officials need to be aware that this so-called startup advocacy group is really in bed with Silicon Valley’s foremost D.C. influence machine, whose interests are often in conflict with those of disruptive entrepreneurs,” said Daniel Stevens of the Campaign for Accountability, which released the report. There are no clean hands here: The Campaign for Accountability gets major funding from Oracle, a chief antagonist to Google.

A Google spokesperson said the company is “happy to support Engine’s work” to represent the views of startups in Washington policy debates. “While we often agree on policy matters, Engine is an independent organization just like the other groups we support,” the spokesperson said.

Google publicly discloses its funding support for Engine on its website, “in contrast to the Campaign for Accountability, which declines to list its corporate funders and has been instrumental in Oracle’s long-running legal grudge against Google,” the spokesperson said.

Ken Gleuck, a senior vice president in Oracle’s Washington office, said after publication that Google’s charge was off-base and that Oracle had nothing to do with the report. “Before reading your story, Oracle had no idea Engine even existed, nor did we have any knowledge or involvement with this report,” he said. “While we are flattered, Google should not assume we are behind every bad story about Google. We’d run out of 20 percent time if all we did was out Google front groups. Are we also responsible for the Red Wedding and plastic straws?”",,,,,
"Face Recognition Is Now Being Used in Schools, but It Won’t Stop Mass Shootings","OFFICIALS AT THE Lockport, New York, school district have purchased face recognition technology as part of a purported effort to prevent school shootings. Starting in September, all 10 of Lockport District’s school buildings, just north of Buffalo, will be outfitted with a surveillance system that can identify faces and objects. The software, known as Aegis, was developed by SN Technologies Corp., a Canadian biometrics firm that specifically advertises to schools. It can be used to alert officials to whenever sex offenders, suspended students, fired employees, suspected gang members, or anyone else placed on a school’s “blacklist” enters the premises. Aegis also sends alerts any time one of the “top 10” most popular guns used in school shootings appears in view of a camera.

The district is spending most of its recent $4 million state “Smart School” grant on these and other enhancements to its security systems, including bullet-proof greeter windows and a mass notification system, according to the Niagra Gazette. “We always have to be on our guard. We can’t let our guard down,” Lockport Superintendent Michelle T. Bradley told the Buffalo News. “For the Board of Education and the Lockport City School District, this is the No. 1 priority: school security.”",,,,,
"In Apple Mail, There’s No Protecting PGP-Encrypted Messages","Update: Since this article was published, GPGTools released version 2018.2 which appears to successfully mitigate the OpenPGP EFAIL attack for macOS High Sierra users. If you use macOS High Sierra, Apple Mail, and GPGTools, it should be safe to use PGP again if you update to the latest version of everything. If you use an older version of macOS, GPGTools is still vulnerable.


IT’S BEEN NEARLY two weeks since a group of European researchers published a paper describing “EFAIL,” a set of critical software vulnerabilities that allow encrypted email messages to be stolen from within the inbox. And developers of email clients and encryption plug-ins are still scrambling to come up with a permanent fix.

Apple Mail is the email client that comes free with every Mac computer, and an open source project called GPGTools allows Apple Mail to smoothly encrypt and decrypt messages using the 23-year-old PGP standard. The day the EFAIL paper was published, GPGTools instructed users to workaround EFAIL by changing a setting in Apple Mail to disable loading remote content:",,,,,
Snowden Archive,In partnership with,,,,,
Experts Say Keep Amazon’s Alexa Away From Your Kids,"WHAT’S THE BEST way to keep adults from questioning the use of a deeply problematic product? Get them started when they’re too young to question anything. Amazon has a new addition to its line of voice-commanded artificial intelligence Alexa assistants, marketed for use by children as young as 5 years old, who can barely grasp a box of juice, let alone digital privacy. Now, a coalition of children’s privacy and psychology advocates are warning parents away from Amazon’s latest, cutest device, saying it could normalize surveillance and harm children’s mental development.

The Echo Dot for kids is functionally identical to the Echo Dot for adults, except that it’s brightly colored and inexplicably costs $30 more than the grown-up version. Cosmetics aside, Echo Dot is still an AI-powered microphone that listens constantly for an activation keyword, relays a user’s voice to remote servers where it is analyzed and processed opaquely, and then responds to an increasingly long list of commands; on its packaging, Amazon highlights commands like “tell me a story” and “start SpongeBob.” Dot for kids will not only perpetually listen to and entertain your children, but attempt to teach them manners in your stead: “Alexa even provides positive feedback when kids ask questions and remember to say ‘please,'” says Amazon.",,,,,
"You Can’t Handle the Truth About Facebook Ads, New Harvard Study Shows",LEIA EM PORTUGUÊS ,,,,,
It’s Impossible to Prove Your Laptop Hasn’t Been Hacked. I Spent Two Years Finding Out.,"DIGITAL SECURITY SPECIALISTS like me get some version of this question all the time: “I think my laptop may have been infected with malware. Can you check?”

We dread this sort of query because modern computer exploits are as complex, clever, and hard to reason about as modern computers — particularly if someone has the ability to physically access your device, as is routinely the case with laptops, especially when traveling. So while it’s definitely possible to detect certain types of tampering, it isn’t always trivial. And even in controlled environments, it’s impossible to give a laptop a clean bill of health with full confidence – it’s always possible that it was tampered with in a way you did not think to check.

The issue of tampering is particularly relevant for human rights workers, activists, journalists, and software developers, all of whom hold sensitive data sought by powerful potential attackers. People in these vocations are often keenly aware of the security of their laptops while traveling – after all, laptops store critical secrets like communication with sources, lists of contacts, password databases, and encryption keys used to vouch for source code you write, or to give you access to remote servers.",,,,,
"Facebook Uses Artificial Intelligence to Predict Your Future Actions for Advertisers, Says Confidential Document",LEIA EM PORTUGUÊS ,,,,,
Mark Zuckerberg Is Either Ignorant or Deliberately Misleading Congress,"AFTER WATCHING the Facebook founder and CEO’s 48-hour trip to Capitol Hill, there are two possible conclusions: either Mark Zuckerberg deliberately misled Congress, or Mark Zuckerberg knows very little about his own company. Both are bad.

Again and again, before both Senate and House committees, Zuckerberg pleaded ignorance about the company he created and has controlled for 14 years. Zuckerberg wasn’t dodging questions about obscure corners of the company or corporate minutiae, but the most plainly fundamental aspects of Facebook’s business and privacy policies. Rather than the congressional beatdown many had expected, the most striking aspect of Zuckerberg’s testimony wasn’t his painful apologias or excuse-spinning, but his ability to spend nearly 10 hours saying almost nothing. The hearings may prove to be a sea change moment for Facebook and the greater data-mining industrial complex, but it would be hard to say the public learned much of anything.

When Sen. Kamala Harris asked Zuckerberg, on the subject of Cambridge Analytica, whether the company had any conversations about whether to inform the 87 million users affected, the CEO replied, “I don’t know if there were any conversations at Facebook overall because I wasn’t in a lot of them,” and finally “I don’t remember a conversation like that.”

When asked by Sen. Maria Cantwell whether Facebook employees had helped with Cambridge Analytica’s work: “Senator, I don’t know.”

When asked about the role of Palantir, a data-mining defense contractor co-founded by Facebook board member and early Zuckerberg ally Peter Thiel: “I’m not really that familiar with what Palantir does.”

Zuckerberg acted similarly confused when asked whether Facebook does things it openly says it does on its own website. When Sen. Roger Wicker asked Zuckerberg if he could confirm whether “Facebook can track a user’s internet browsing activity, even after that user has logged off of the Facebook platform,” the CEO replied, “Senator — I — I want to make sure I get this accurate, so it would probably be better to have my team follow up afterwards.”

The answer is categorically, unequivocally yes, according to Facebook.com: “If you’re logged out or don’t have a Facebook account and visit a website with the Like button or another social plugin, your browser sends us a more limited set of info.”

When Sen. Roy Blunt asked Zuckerberg whether Facebook tracks users across devices (say, from their iPhone to their iPad), he replied that he was “not sure of the answer to that question.”

Meanwhile, on Facebook.com:",,,,,
Cambridge Analytica Might Have to Return Ad Award — but Industry Still Embraces Company’s Goals,"FOUNDED IN 1936, the Advertising Research Foundation “has been the standard-bearer for unbiased quality in research on advertising, media and marketing,” according to its website, and works to spread “unifying standards and best practices” throughout the ad industry. Last year, the ARF presented Cambridge Analytica with its highest honor.

The current scandal engulfing both Facebook and Cambridge Analytica, the shadowy British political consultancy that exfiltrated and exploited 50 million profiles from the social network, centers mostly around how the data was acquired, not how it was used. This is due in part to the fact that before the pilfered profile revelations, Cambridge Analytica enjoyed the praise of its peers in the marketing world, which viewed it as a band of innovators.",,,,,
The War on Immigrants,"Because of errors inserted during editing, the original version of this article contained the mistaken assertion that ICE used private Facebook data to track unauthorized immigrants. The story has been corrected. See below for full correction.

CAMBRIDGE ANALYTICA MAY have had access to the personal information of tens of millions of unwitting Americans, but a genuine debate has emerged about whether the company had the sophistication to put that data effectively to use on behalf of Donald Trump’s presidential campaign.

But one other organization that has ready access to Facebook’s trove of personal data has a much better track record of using such information effectively: U.S. Immigration and Customs Enforcement.

ICE, the federal agency tasked with Trump’s program of mass deportation, uses backend Facebook data to locate and track suspects, according to a string of emails and documents obtained by The Intercept through a public records request. The hunt for one particular suspect provides a rare window into how ICE agents use social media and powerful data analytics tools to find targets.",,,,,
Snowden Archive,LEIA EM PORTUGUÊS ,,,,,
Democrats Want to Subpoena Apple to Find Out When Key Administration Officials Downloaded Encrypted Messaging Apps,"ON WEDNESDAY, HOUSE Democrats on the Intelligence Committee released a memo laying out the steps they would have taken had they been in charge of the Trump-Russia investigation — and steps they may take if and when they gain subpoena power by taking over the House of Representatives in November.

The possibility became much more likely on Tuesday night, as Democrats pulled off an upset victory in a Pennsylvania special election for a congressional seat that President Donald Trump had carried by nearly 20 points, and that Democrats hadn’t even bothered to contest in the last two cycles. If the pattern holds, Democrats have a strong chance of picking up the nearly two-dozen seats they need to win the House — and the subpoena power that comes with it.

Down on Page 20 of the memo is a pair of ideas that could put Congress on a collision course with privacy advocates in Silicon Valley. “Apple: The Committee should seek records reflecting downloaded encrypted messaging apps for certain key individuals,” the memo suggests. “The Committee should likewise issue a subpoena to WhatsApp for messages exchanged between key witnesses of interest.”

The committee said that it would also seek to find out “all messaging applications that Mr. [Jared] Kushner used during the campaign as well as the presidential transition, including but not limited to SMS, iMessage, Whatsapp, Facebook Messenger, Signal, Slack, Instagram, and Snapchat.”

The committee may also consider adding ProtonMail, the encrypted email service, to that list. One White House staffer, Ryan P. McAvoy, jotted his ProtonMail passwords and his address on a piece of White House stationery and left it at a bus stop near the White House. A source found it there and provided it to The Intercept, which confirmed its authenticity. (McAvoy did not respond to requests for comment.)

Following publication of this story, Irina Marcopol, a spokesperson for ProtonMail, forwarded a statement from the company’s CEO, Andy Yen. “Don’t be a password idiot,” Yen suggested. “In other words, don’t be this guy.”
Yen went on to note that whether a White House staffer is using encrypted or unencrypted email isn’t the important question, at least from the perspective of retention of records. The use of any personal email account for official business would run afoul of that.",,,,,
Facebook Quietly Hid Webpages Bragging of Ability to Influence Elections,LEIA EM PORTUGUÊS ,,,,,
Amazon Partnership with British Police Alarms Privacy Advocates,LEIA EM PORTUGUÊS ,,,,,
Drone Wars,"GOOGLE HAS QUIETLY secured a contract to work on the Defense Department’s new algorithmic warfare initiative, providing assistance with a pilot project to apply its artificial intelligence solutions to drone targeting.

The military contract with Google is routed through a Northern Virginia technology staffing company called ECS Federal, obscuring the relationship from the public.

The contract, first reported Tuesday by Gizmodo, is part of a rapid push by the Pentagon to deploy state-of-the-art artificial intelligence technology to improve combat performance.

Google, which has made strides in applying its proprietary deep learning tools to improve language translation, and vision recognition, has a cross-team collaboration within the company to work on the AI drone project.

The team, The Intercept has learned, is working to develop deep learning technology to help drone analysts interpret the vast image data vacuumed up from the military’s fleet of 1,100 drones to better target bombing strikes against the Islamic State.

The race to adopt cutting-edge AI technology was announced in April 2017 by then-Deputy Defense Secretary Robert Work, who unveiled an ambitious plan called the Algorithmic Warfare Cross-Functional Team, code-named Project Maven. The initiative, Work wrote in an agency-wide memo, is designed to “accelerate DoD’s integration of big data and machine learning” and “turn the enormous volume of data available to DoD into actionable intelligence and insights at speed.”

The first phase of Project Maven, which incorporates multiple teams from across the Defense Department, is an effort to automate the identification and classification of images taken by drones — cars, buildings, people — providing analysts with increased ability to make informed decisions on the battlefield.",,,,,
Snowden Archive,"FOR A MOMENT, it seemed the hackers had slipped up and exposed their identities. It was the summer of 2013, and European investigators were looking into an unprecedented breach of Belgium’s telecommunications infrastructure. They believed they were on the trail of the people responsible. But it would soon become clear that they were chasing ghosts – fake names that had been invented by British spies.

The hack had targeted Belgacom, Belgium’s largest telecommunications provider, which serves millions of people across Europe. The company’s employees had noticed their email accounts were not receiving messages. On closer inspection, they made a startling discovery: Belgacom’s internal computer systems had been infected with one of the most advanced pieces of malware security experts had ever seen.

As The Intercept reported in 2014, the hack turned out to have been perpetrated by U.K. surveillance agency Government Communications Headquarters, better known as GCHQ. The British spies hacked into Belgacom employees’ computers and then penetrated the company’s internal systems. In an eavesdropping mission called “Operation Socialist,” GCHQ planted bugs inside the most sensitive parts of Belgacom’s networks and tapped into communications processed by the company.",,,,,
"In Leaked Chats, WikiLeaks Discusses Preference for GOP Over Clinton, Russia, Trolling, and Feminists They Don’t Like","ON A THURSDAY afternoon in November 2015, a light snow was falling outside the windows of the Ecuadorian embassy in London, despite the relatively warm weather, and Julian Assange was inside, sitting at his computer and pondering the upcoming 2016 presidential election in the United States.

In little more than a year, WikiLeaks would be engulfed in a scandal over how it came to publish internal emails that damaged Hillary Clinton’s presidential campaign, and the extent to which it worked with Russian hackers or Donald Trump’s campaign to do so. But in the fall of 2015, Trump was polling at less than 30 percent among Republican voters, neck-and-neck with neurosurgeon Ben Carson, and Assange spoke freely about why WikiLeaks wanted Clinton and the Democrats to lose the election.

“We believe it would be much better for GOP to win,” he typed into a private Twitter direct message group to an assortment of WikiLeaks’ most loyal supporters on Twitter. “Dems+Media+liberals woudl then form a block to reign in their worst qualities,” he wrote. “With Hillary in charge, GOP will be pushing for her worst qualities., dems+media+neoliberals will be mute.” He paused for two minutes before adding, “She’s a bright, well connected, sadistic sociopath.”",,,,,
U.K. Court Finds Government’s Surveillance Powers Unlawful,"THE U.K. GOVERNMENT’S mass surveillance powers were deemed unlawful on Tuesday in a court ruling that could force changes to the country’s spy laws.

Three judges at London’s Court of Appeal found that a sweeping data retention law, which allowed authorities to access people’s phone and email records, was not subject to adequate safeguards. The court ruled that access to the private data “should be restricted to the objective of fighting serious crime.” The court also said that such data should not be turned over to authorities until after a “prior review by a court or an independent administrative body.”

The case was originally brought by the Labour Member of Parliament Tom Watson following the introduction of the 2014 Data Retention and Investigatory Powers Act. That law expired in 2016 and has since been replaced by the Investigatory Powers Act, which expanded the government’s surveillance authority further, retroactively legalizing controversial spy tactics exposed in documents leaked by Edward Snowden. Human rights group Liberty, which represented Watson in the case, said Tuesday’s ruling meant parts of the Investigatory Powers Act – dubbed the “Snoopers’ Charter” by critics – would now need to be reformed.

“Yet again a U.K. court has ruled the government’s extreme mass surveillance regime unlawful,” said Martha Spurrier, Liberty’s director, in a statement. “This judgment tells ministers in crystal clear terms that they are breaching the public’s human rights. … When will the government stop bartering with judges and start drawing up a surveillance law that upholds our democratic freedoms?”

Watson said he was “proud to have played my part in safeguarding citizens’ fundamental rights.” He called on the government to “ensure that hundreds of thousands of people, many of whom are innocent victims or witnesses to crime, are protected by a system of independent approval for access to communications data.”

The Data Retention and Investigatory Powers Act forced telecommunications companies to store records on their customers’ emails and phone calls for 12 months. The Investigatory Powers Act broadened the data retention system by allowing the government to compel phone and internet companies to store not just email and phone records, but also logs showing the websites customers visited and the apps they used. Law enforcement agencies can then access this information without a court order or warrant for a broad range of reasons, not necessarily related to suspected criminal activity. They can obtain the data, for instance, if they judge it to be for the “purpose of protecting public health,” “in the interests of the economic well-being” of the U.K., or “for the purpose of assessing or collecting any tax, duty, levy or other imposition, contribution or charge payable to a government department.”

The Court of Appeal ruling is the latest in a series of blows for the U.K. government on surveillance. It partly reaffirms a December 2016 judgment in the European Union’s top court, which found that the British government’s data retention powers were “highly invasive” and exceeded “the limits of what is strictly necessary and cannot be considered to be justified, within a democratic society.” At least three other major legal cases challenging the country’s spy powers remain ongoing.

Ben Wallace, the U.K. government’s security minister, was dismissive of Tuesday’s decision. “This judgment relates to legislation which is no longer in force and … does not change the way in which law enforcement agencies can detect and disrupt crimes,” he said in a statement. Wallace claimed that the ruling would “not undermine the [data retention] regime” because the government had already acted preemptively in November by introducing safeguards that rein in police officers’ ability to self-authorize access to people’s private data. However, the significance of the ruling is that it will ensure the changes restricting police access to the data are bound into law and cannot be rolled back in future.

Critics believe more reforms are still required. They point out that the government has as of yet failed to address legal breaches identified in the earlier December 2016 European Union court ruling. That ruling stated that to be compliant with human rights law, the government must notify people – after investigations have been completed – if their data has been accessed and must also commit to keeping people’s private data within the EU. Spurrier described the government’s existing safeguards as “window-dressing for indiscriminate surveillance of the public.”

Top photo: A man chats on the phone during the auction at Tattersalls October Yearling Sale Book 1 on Oct. 4, 2016 in Newmarket, England.",,,,,
Facebook Will Trust Its Untrustworthy Users to Rank the Trustworthiness of News,"FACEBOOK USERS, BY and large, are not very good at differentiating between what’s fact and what’s false. Many users will eagerly share both reliable news and the fake stuff without any hesitation. It happens because users either want the falsehoods to be received as true or simply can’t tell the difference. Rampant media illiteracy is the root cause of the fake news handwringing we’ve been dealing with since before the election and will be fretting over until the end of time (or the end of Facebook, whichever comes first). Today, Facebook honcho Mark Zuckerberg said he is setting out to fix this fundamental problem of digital media illiteracy — by putting more power in the hands of the illiterate.

In a new Facebook post today, Zuckerberg said he “asked our product teams to make sure we prioritize news that is trustworthy, informative, and local.” Why this has only become a priority in the company’s 14th year of existence is left unsaid. Zuckerberg admitted that “there’s too much sensationalism, misinformation and polarization in the world today,” and that his website “enables people to spread information faster than ever before.” As with the rest of Silicon Valley, Facebook is obsessed with the appearance of machine-like objectivity, and so Zuckerberg said figuring out which outlets deliberately package viral-ready falsehoods and which do not is a head-scratcher (spoiler: It isn’t):

The hard question we’ve struggled with is how to decide what news sources are broadly trusted in a world with so much division. We could try to make that decision ourselves, but that’s not something we’re comfortable with. We considered asking outside experts, which would take the decision out of our hands but would likely not solve the objectivity problem. Or we could ask you — the community — and have your feedback determine the ranking.

So, rather than relying on the subjectivity and biases of a team of outside experts, Facebook will rely on the subjectivity and biases of 2 billion people around the world. Specifically, Facebook said it will decide which media outlets are prioritized at least in part by just asking people which outlets they like:

As part of our ongoing quality surveys, we will now ask people whether they’re familiar with a news source and, if so, whether they trust that source. The idea is that some news organizations are only trusted by their readers or watchers, and others are broadly trusted across society even by those who don’t follow them directly. (We eliminate from the sample those who aren’t familiar with a source, so the output is a ratio of those who trust the source to those who are familiar with it.)

Facebook is either unaware of — or, more likely — unwilling to deal with the fact that people have rabid, tribalistic loyalties to certain outlets. Someone who enjoys sharing, say, the Daily Caller or InfoWars articles is going to, of course, say that these are trustworthy outlets. Otherwise, they’re admitting that they voluntarily consume and spread information that isn’t trustworthy, and we all think too highly of ourselves for that. According to a Facebook spokesperson, the surveys are meant to make sure “people can have more from their favorite sources and more from trusted sources.” Isn’t part of the Facebook information disaster that so many people count things like RedStateEagleMilitiaZoneDeepStateNews (or what have you) among their “favorite sources?” Should we be asking these people what’s trustworthy and what isn’t? Should they be deciding what will appear on your feed — or even their own — as reliable news?",,,,,
Snowden Archive,,,,,,
Edward Snowden’s New App Uses Your Smartphone to Physically Guard Your Laptop,"LIKE MANY OTHER journalists, activists, and software developers I know, I carry my laptop everywhere while I’m traveling. It contains sensitive information; messaging app conversations, email, password databases, encryption keys, unreleased work, web browsers  logged into various accounts, and so on. My disk is encrypted, but all it takes to bypass this protection is for an attacker — a malicious hotel housekeeper, or “evil maid,” for example — to spend a few minutes physically tampering with it without my knowledge. If I come back and continue to use my compromised computer, the attacker could gain access to everything.

Edward Snowden and his friends have a solution. The NSA whistleblower and a team of collaborators have been working on a new open source Android app called Haven that you install on a spare smartphone, turning the device into a sort of sentry to watch over your laptop. Haven uses the smartphone’s many sensors — microphone, motion detector, light detector, and cameras — to monitor the room for changes, and it logs everything it notices. The first public beta version of Haven has officially been released; it’s available in the Play Store and on F-Droid, an open source app store for Android.

Snowden is helping to develop the software through a project he leads at the Freedom of the Press Foundation, which receives funding from The Intercept’s parent company. I sit on the FPF board with Snowden, am an FPF founder, and lent some help developing the app, including through nine months of testing. With that noted, I’ll be forthright about the product’s flaws below, and have solicited input for this article from people not involved in the project.

Also collaborating on Haven is the Guardian Project, a global collective of mobile security app developers.

Haven is an external solution to a problem computer makers traditionally attempted to handle from within their devices. Some laptops, for example, offer “secure boot” through a special tamper-resistant chip called a Trusted Platform Module, which tries to ensure that the computer’s bootloader code hasn’t been modified to be malicious. But there are various ways this could go wrong: there can be bugs in the code that does the verification, attackers could connive to get their code marked as trustworthy, or malicious code could be inserted after the bootloader. Some computer users have tried the low-tech solution of painting glitter nail polish on their laptop screws, creating a sort of seal that would be broken during a tampering attempt.

“Due to how current laptops, and probably most other computing devices, are made today, it is virtually impossible to systematically check later if the laptop has been compromised or not,” said Joanna Rutkowska, founder of the secure Qubes operating system, who invented the term “evil maid” in 2009 as part of her work as a security researcher.",,,,,
Jill Stein Will Hand Over Russia-Related Communications to Senate Committee,"In her first comments to the press, former Green Party presidential candidate Jill Stein said she will cooperate fully with the Senate Intelligence Committee’s investigation into “collusion with the Russians” during the 2016 campaign, and is currently searching for relevant documents. Stein denies holding any substantive communications with the Russian government or RT, its state-owned media property.
Stein says her involvement in the inquiry, first reported by BuzzFeed News, came as a surprise when her campaign was first contacted last month. After a subsequent dialogue between attorneys representing Stein and lawyers from the Senate Intelligence Committee, the former candidate received a formal request for cooperation. Although she says the possibility of testifying before Congress has not yet been broached, Stein says she would be “happy to do so” if asked.
Still, Stein clearly resents the Senate’s attention vis-à-vis  electoral interference and foreign meddling: “This smacks of the dangerous underbelly of these investigations. The extent to which they exercise overreach, politicizing, and sensationalism is a danger to democracy, especially in the current climate of all-out war on our First Amendment rights. This is not a time to be attacking the rights of political speech and political association.”
In the meantime, Stein’s defunct 2016 campaign is working to “produce all docs related to the inquiry into Russian interference” in accordance with the Intelligence Committee’s formal request, though Stein doesn’t “believe they’ve given us search terms,” as their respective attorneys are still “in the process of working that out.” Stein added that she’s unaware of a deadline for this document handover, but “we are trying to comply as quickly as we possibly can. … There are a number of people we have to contact that we’re not in touch with, and they have to search as well.”
It’s safe to assume the Intelligence Committee is interested in anything pertaining to Stein’s now-infamous attendance of an RT gala in Moscow, at which she was seated and photographed with Russian President Vladimir Putin and President Donald Trump’s former national security adviser Michael Flynn. Stein told The Intercept that as she has routinely appeared on RT and expects to hand over communications related to booking those TV segments and other “administrative” messages between her campaign and the Russian network, as well as “logistical” messages about the Moscow event. Stein also noted that before her Moscow visit, she had “requested to speak with either Putin or [Russian Foreign Minister Sergey] Lavrov, or someone in the Russian government, to be able to discuss our policies, because I was there to advance our agenda for peace and climate action and diplomacy and nuclear weapon abolition.”
Stein says this request was not granted. Stein also maintains that she declined to let RT pay for any portion of her trip to Moscow and further denies requesting or receiving any other assistance, monetary or otherwise, from RT, the Russian government, WikiLeaks, or the Trump campaign, adding that any dialogue or cooperation with Trump “would have been quite contrary to our values.”
When asked why she had attended the gala and sought an audience with Putin, she told The Intercept that “we sought contact with every powerful world leader we had access to,” and that the Russian government was of particular interest because of its involvement in the Syrian civil war. “We don’t have any reason to suspect that there was any backdoor communication,” Stein said. “We were very much focused on the substantive issues of the elections, and we avoid like the plague manipulations and machinations in order to make things happen behind the scenes.”
A spokesperson for Stein provided the following statement:








Responding to a Senate Select Committee on Intelligence request for documents pertaining to interference in the 2016 election, former Green Party Presidential candidate Jill Stein said she is cooperating by sharing all communications relevant to the committee’s mission. “We take seriously the issue of potential interference in our elections, as demonstrated by our continuing efforts to investigate the integrity of the 2016 election and examine our voting machines that are widely known to be vulnerable, but which still have not been examined for evidence of interference. To restore trust in our elections and democracy itself, we must safeguard our elections from all potential sources of interference, whether by foreign state actors or domestic political partisans, criminal networks, lone wolves, or private corporations – including those who control voting software.
Our campaign has observed the highest standards of transparency and integrity in our interactions with foreign nationals as well as Americans. Our communications with Russian individuals regarding an invitation to speak on international relations at the RT 10th anniversary media conference will confirm what we stated publicly at that time and since: that we did not accept any payment or even reimbursement for the trip, and that we made the trip with the goal of reaching an international audience and Russian officials with a message of Middle East peace, diplomacy, and cooperation against the urgent threat of climate change, consistent with long-standing Green principles and policies.
We strongly support legitimate inquiry into any illegal activity in our elections – including quid pro quo deals, money laundering, corruption and violation of campaign finance laws. At the same time, we caution against the politicization, sensationalism and collapse of journalistic standards that has plagued media coverage of the investigation. In the current climate of attacks on our civil liberties, with the emergence of censorship in social media and the press, criminalization of protest, militarization of police and massive expansion of the surveillance state, we must guard against the potential for these investigations to be used to intimidate and silence principled opposition to the political establishment.
















Stein said that she would release a more comprehensive statement about the investigation in the near future.








Top photo: Green Party presidential candidate Jill Stein speaks at a news conference on Fifth Avenue across the street from Trump Tower December 5, 2016 in New York City.",,,,,
Drone Wars,"THE U.K. GOVERNMENT is facing fresh calls to clarify its role in U.S. drone strikes after acknowledging that there are potentially hundreds of British spy agency personnel working inside a U.S.-controlled surveillance base that has played a key role in so-called targeted killings.

Earlier this month, British Minister of State for the Armed Forces Mark Lancaster disclosed to the U.K. Parliament that employees of eavesdropping agency Government Communications Headquarters, or GCHQ, are stationed at a remote base in the north of England called Menwith Hill. An unknown number of GCHQ employees are among 578 British civilians, military, and contractors at the site, Lancaster confirmed in a previously unreported written statement, alongside 627 Americans.

Questioned in 2013 about GCHQ’s presence at the base, the British government had insisted that it “would not comment on whether there are personnel working in intelligence” there – a position that appears to have changed with Lancaster’s admission, possibly unintentionally. His statement came in response to a Parliament member’s question about how many people are working at Menwith Hill. A spokesperson for the U.K. government’s Ministry of Defence declined to answer questions about whether the statement represented a policy shift.

Menwith Hill is the National Security Agency’s largest overseas surveillance facility, located near the small town of Harrogate in North Yorkshire. As The Intercept revealed in 2015, the base has been used to aid “a significant number of capture-kill operations” across the Middle East and North Africa, according to top-secret documents. The facility operates spy satellites used to pinpoint the locations of people on the ground below, and it is equipped with eavesdropping technology that can harvest data from more than 300 million emails and phone calls a day.",,,,,
How to Protect Yourself Against Spearphishing: A Comic Explanation,"THE U.K. GOVERNMENT is facing fresh calls to clarify its role in U.S. drone strikes after acknowledging that there are potentially hundreds of British spy agency personnel working inside a U.S.-controlled surveillance base that has played a key role in so-called targeted killings.

Earlier this month, British Minister of State for the Armed Forces Mark Lancaster disclosed to the U.K. Parliament that employees of eavesdropping agency Government Communications Headquarters, or GCHQ, are stationed at a remote base in the north of England called Menwith Hill. An unknown number of GCHQ employees are among 578 British civilians, military, and contractors at the site, Lancaster confirmed in a previously unreported written statement, alongside 627 Americans.

Questioned in 2013 about GCHQ’s presence at the base, the British government had insisted that it “would not comment on whether there are personnel working in intelligence” there – a position that appears to have changed with Lancaster’s admission, possibly unintentionally. His statement came in response to a Parliament member’s question about how many people are working at Menwith Hill. A spokesperson for the U.K. government’s Ministry of Defence declined to answer questions about whether the statement represented a policy shift.

Menwith Hill is the National Security Agency’s largest overseas surveillance facility, located near the small town of Harrogate in North Yorkshire. As The Intercept revealed in 2015, the base has been used to aid “a significant number of capture-kill operations” across the Middle East and North Africa, according to top-secret documents. The facility operates spy satellites used to pinpoint the locations of people on the ground below, and it is equipped with eavesdropping technology that can harvest data from more than 300 million emails and phone calls a day.",,,,,
European Court to Decide Whether U.K. Mass Surveillance Revealed by Snowden Violates Human Rights,"BRITISH SPY AGENCIES are under scrutiny in a landmark court case challenging the legality of top-secret mass surveillance programs revealed in documents leaked by whistleblower Edward Snowden.

A panel of 10 judges at the European Court of Human Rights in Strasbourg, France, held a hearing Tuesday to examine the U.K. government’s large-scale electronic spying operations, following three separate challenges brought by a dozen human rights groups, including Amnesty International, Privacy International, the American Civil Liberties Union, Big Brother Watch, the Open Rights Group, and the Irish Council for Civil Liberties.

The case is the first of its kind to be heard by the court, which handles complaints related to violations of the European Convention on Human Rights, an international treaty by which the U.K. is still bound despite its vote last year to leave the European Union. The court’s judgments could have ramifications for future U.K. surveillance operations.

The human rights groups are arguing that British spy programs violate four key rights protected under the convention: the right to privacy; the right to a fair trial; the right to freedom of expression; and the right not to be discriminated against. They cite a 2015 ruling by a U.K. tribunal, which found that British eavesdropping agency Government Communications Headquarters, or GCHQ, had unlawfully spied on the communications of Amnesty International and the South Africa-based Legal Resources Centre.

Dinah Rose, a lawyer representing the human rights groups, acknowledged in court Tuesday that some serious security threats require the use of covert government surveillance. But, she added, “excessive and unaccountable state surveillance puts at risk the very core values of the free and democratic societies that terrorism seeks to undermine.”

The British government has insisted that it does not carry out “mass surveillance,” preferring instead to use the term “bulk surveillance,” which it says is necessary to discover previously unknown threats. Documents leaked by Snowden describe how GCHQ planned to carry out “population scale” surveillance; boasted that it had “massive access” to internet communications; and monitored more than 50 billion “events” about communications each day.

Government lawyer James Eadie told the court that using surveillance systems to collect and store communications is not itself a violation of privacy. Instead, he said, privacy is only violated when there is “sentient examination” of communications – in other words, when a human analyst reads or listens to individual messages or calls. This will be a key point of contention for the Strasbourg judges to consider.

Last year, a complaint filed in the case by 10 of the human rights groups named more than a dozen surveillance programs that allegedly violate rights and do not have adequate safeguards against abuse. Among them are GCHQ programs, such as KARMA POLICE, which was first exposed by The Intercept. KARMA POLICE was designed to allow the GCHQ to build “a web-browsing profile for every visible user on the internet.” The complaint also focuses on NSA-operated programs that have been shared with British spies, such as XKEYSCORE, a tool that can be used to sift through masses of emails, online chats, and virtually every other kind of internet data.

Nick Williams, Amnesty International’s senior legal counsel, said in an email that the case represented a “watershed moment for people’s privacy and freedom of expression” across the world. “The case concerns the U.K., but its significance is global. By bringing together human rights defenders and journalists from four different continents, it serves to highlight the dangers mass surveillance poses to the vital work of countless organisations and to individuals who expose human rights abuses and defend those at risk.”

Scarlet Kim, a legal officer with Privacy International, said in a statement: “For years, the U.K. Government has been intercepting the private communications and data of millions of people around the world. At the same time, it can access similarly enormous troves of information intercepted by the U.S. Government. These practices are unlawful and violate the fundamental rights of individuals across the world, assailing privacy and chilling thought and speech.”

A spokesperson for the U.K. government’s Home Office declined to comment on the specifics of the case, but said in a statement that British intelligence agencies “conduct their vital work within a strict legal and policy framework that applies rigorous safeguards and oversight mechanisms to ensure respect for human rights. We will vigorously defend the powers our agencies need to keep us all safe and secure.”

Top photo: City workers use smartphones inside in London on Oct. 30, 2017.",,,,,
Why We Reinstalled SecureDrop,LEIA EM PORTUGUÊS ,,,,,
How to Use Signal Without Giving Out Your Phone Number,LEIA EM PORTUGUÊS ,,,,,
Taser Wants to Build an Army of Smartphone Informants,"AXON, THE WORLD’S largest vendor of police-worn body cameras, is moving into the business of capturing video taken by the public. In a survey emailed to law enforcement officials last month, the company formerly known as Taser International solicited naming ideas for its provisionally titled Public Evidence Product. According to the survey, the product will allow citizens to submit photos or video evidence of “a crime, suspicious activity, or event” to Evidence.com, the company’s cloud-based storage platform, to help agencies “in solving a crime or gathering a fuller point of view from the public.” Civil rights advocates interviewed by The Intercept were surprised to learn about the corporation’s latest initiative, seeing it as yet another untested effort to co-opt community oversight and privatize criminal justice.

“When police body cameras were initially established, it was because citizens were clamoring for police accountability,” explained Shahid Buttar, director of grassroots advocacy with the Electronic Frontier Foundation. “But we’ve seen how cameras have been more useful for police investigations than for accountability. This product realizes those dangers and takes them to a new dystopian level by crowdsourcing the collection of evidence and turning it over to law enforcement.”",,,,,
"How Right-Wing Extremists Stalk, Dox, and Harass Their Enemies","CHAT LOGS OBTAINED from message boards used by neo-Nazis and other far-right groups show a concerted effort to compile private information on leftist enemies and circulate the data to encourage harassment or violence.

The messages were obtained by an anonymous source, who infiltrated and gained the trust of white nationalists and other right-wingers, and has been leaking the material to Unicorn Riot, a “decentralized media collective” that emerged from leftist protest movements.

The chat logs originate from various web discussion communities hosted by the provider Discord and closed to the public. The communities, which have names like “Vibrant Diversity,” “Ethnoserver,” “Safe Space 3,” “4th Reich,” and “Charlottesville 2.0,” range from having 36 users to 1,269 users. The most active, with nearly a quarter million messages over seven months, is “Vibrant Diversity,” a neo-Nazi community forum that includes a channel called “#oven,” where users share racist memes. The 4th Reich server, the second most active, has 130,000 messages over the course of four months and includes a channel called “#rare_hitlers,” where users share propaganda posters and other glorified media from Nazi Germany. The “Charlottesville 2.0” server, which contains 35,000 messages, is where the “Unite the Right” hate rally in Charlottesville was organized.

This article is based solely on chat logs from a community called “Pony Power” (Unicorn Riot published the logs yesterday). The Pony Power server has 50 users, and the chat logs contain just over 1,000 messages, posted over the course of 10 days and ranging in topic from far-right politics to advice about digital and operational security to debates about the legal limits of online behavior. The primary activity on the Pony Power server is posting private information, like names, photos, home addresses, and phone numbers of dozens of anti-fascist activists.

Victims of the outings, also known as “doxing,” described reactions ranging from terror to anger to annoyance, and have variously turned to friends and family for support and locked down their accounts. They said the Pony Power doxing campaign is just the latest in a series of online efforts by neo-Nazis and their allies to marginalize their opponents. The information compiled on Pony Power hasn’t yet been distributed to the larger right-wing extremist community. However, doxing efforts associated with prior online hate campaigns have forced targets to leave their homes in the face of death threats, rape threats, and other forms of harassment. And those attacks were mounted even before President Donald Trump came to power on the back of racist attacks against his predecessor, Mexicans, and Muslims, and before he embraced white nationalists and encouraged violence against protesters at campaign rallies.

People chatting on the Pony Power server spoke openly, as though behind closed doors, often using offensive slurs. So be warned, some of the following conversations are hard to stomach.

Scope of the harassment campaign

DURING THE 10-DAY span that the Pony Power chat logs cover, from August 17 to 27, so-called alt-right members collected private information from over 50 anti-fascist activists from the states of California, Florida, Illinois, Iowa, Maryland, Massachusetts, Minnesota, Missouri, Nebraska, North Carolina, South Dakota, Texas, Virginia, and Washington.

The information collected often included photographs, social media profiles, home address, phone numbers, email addresses, date of birth, driver license numbers, vehicle information, place of employment, and in one instance, a social security number. The justification for doxing normally put forward in Pony Power was that the targets were part of loosely structured far-left groups known as antifa, or anti-fascists, which has put up some of the most militant opposition to the far right; or they’re judged sympathetic to antifa; or they’ve been seen at protests deemed “communist” by the the far right.

The members of Pony Power often brainstorm methods to increase the effectiveness of their harassment campaigns. One user called “oxycolton” wrote, “We’ve had a lot of people dox antifags but it doesn’t hold,” apparently meaning that the information is lost, in part because they don’t yet have a database to keep track of everything.",,,,,
"NYPD Refuses to Disclose Information About Its Face Recognition Program, So Privacy Researchers Are Suing","CHAT LOGS OBTAINED from message boards used by neo-Nazis and other far-right groups show a concerted effort to compile private information on leftist enemies and circulate the data to encourage harassment or violence.

The messages were obtained by an anonymous source, who infiltrated and gained the trust of white nationalists and other right-wingers, and has been leaking the material to Unicorn Riot, a “decentralized media collective” that emerged from leftist protest movements.

The chat logs originate from various web discussion communities hosted by the provider Discord and closed to the public. The communities, which have names like “Vibrant Diversity,” “Ethnoserver,” “Safe Space 3,” “4th Reich,” and “Charlottesville 2.0,” range from having 36 users to 1,269 users. The most active, with nearly a quarter million messages over seven months, is “Vibrant Diversity,” a neo-Nazi community forum that includes a channel called “#oven,” where users share racist memes. The 4th Reich server, the second most active, has 130,000 messages over the course of four months and includes a channel called “#rare_hitlers,” where users share propaganda posters and other glorified media from Nazi Germany. The “Charlottesville 2.0” server, which contains 35,000 messages, is where the “Unite the Right” hate rally in Charlottesville was organized.

This article is based solely on chat logs from a community called “Pony Power” (Unicorn Riot published the logs yesterday). The Pony Power server has 50 users, and the chat logs contain just over 1,000 messages, posted over the course of 10 days and ranging in topic from far-right politics to advice about digital and operational security to debates about the legal limits of online behavior. The primary activity on the Pony Power server is posting private information, like names, photos, home addresses, and phone numbers of dozens of anti-fascist activists.

Victims of the outings, also known as “doxing,” described reactions ranging from terror to anger to annoyance, and have variously turned to friends and family for support and locked down their accounts. They said the Pony Power doxing campaign is just the latest in a series of online efforts by neo-Nazis and their allies to marginalize their opponents. The information compiled on Pony Power hasn’t yet been distributed to the larger right-wing extremist community. However, doxing efforts associated with prior online hate campaigns have forced targets to leave their homes in the face of death threats, rape threats, and other forms of harassment. And those attacks were mounted even before President Donald Trump came to power on the back of racist attacks against his predecessor, Mexicans, and Muslims, and before he embraced white nationalists and encouraged violence against protesters at campaign rallies.

People chatting on the Pony Power server spoke openly, as though behind closed doors, often using offensive slurs. So be warned, some of the following conversations are hard to stomach.

Scope of the harassment campaign

DURING THE 10-DAY span that the Pony Power chat logs cover, from August 17 to 27, so-called alt-right members collected private information from over 50 anti-fascist activists from the states of California, Florida, Illinois, Iowa, Maryland, Massachusetts, Minnesota, Missouri, Nebraska, North Carolina, South Dakota, Texas, Virginia, and Washington.

The information collected often included photographs, social media profiles, home address, phone numbers, email addresses, date of birth, driver license numbers, vehicle information, place of employment, and in one instance, a social security number. The justification for doxing normally put forward in Pony Power was that the targets were part of loosely structured far-left groups known as antifa, or anti-fascists, which has put up some of the most militant opposition to the far right; or they’re judged sympathetic to antifa; or they’ve been seen at protests deemed “communist” by the the far right.

The members of Pony Power often brainstorm methods to increase the effectiveness of their harassment campaigns. One user called “oxycolton” wrote, “We’ve had a lot of people dox antifags but it doesn’t hold,” apparently meaning that the information is lost, in part because they don’t yet have a database to keep track of everything.",,,,,
Taser Will Use Police Body Camera Videos “to Anticipate Criminal Activity”,"WHEN CIVIL LIBERTIES advocates discuss the dangers of new policing technologies, they often point to sci-fi films like “RoboCop” and “Minority Report” as cautionary tales. In “RoboCop,” a massive corporation purchases Detroit’s entire police department. After one of its officers gets fatally shot on duty, the company sees an opportunity to save on labor costs by reanimating the officer’s body with sleek weapons, predictive analytics, facial recognition, and the ability to record and transmit live video.

Although intended as a grim allegory of the pitfalls of relying on untested, proprietary algorithms to make lethal force decisions, “RoboCop” has long been taken by corporations as a roadmap. And no company has been better poised than Taser International, the world’s largest police body camera vendor, to turn the film’s ironic vision into an earnest reality.

In 2010, Taser’s longtime vice president Steve Tuttle “proudly predicted” to GQ that once police can search a crowd for outstanding warrants using real-time face recognition, “every cop will be RoboCop.” Now Taser has announced that it will provide any police department in the nation with free body cameras, along with a year of free “data storage, training, and support.” The company’s goal is not just to corner the camera market, but to dramatically increase the video streaming into its servers.

With an estimated one-third of departments using body cameras, police officers have been generating millions of hours of video footage. Taser stores terabytes of such video on Evidence.com, in private servers, operated by Microsoft, to which police agencies must continuously subscribe for a monthly fee. Data from these recordings is rarely analyzed for investigative purposes, though, and Taser — which recently rebranded itself as a technology company and renamed itself “Axon” — is hoping to change that.

Taser has started to get into the business of making sense of its enormous archive of video footage by building an in-house “AI team.” In February, the company acquired a computer vision startup called Dextro and a computer vision team from Fossil Group Inc. Taser says the companies will allow agencies to automatically redact faces to protect privacy, extract important information, and detect emotions and objects — all without human intervention. This will free officers from the grunt work of manually writing reports and tagging videos, a Taser spokesperson wrote in an email. “Our prediction for the next few years is that the process of doing paperwork by hand will begin to disappear from the world of law enforcement, along with many other tedious manual tasks.” Analytics will also allow departments to observe historical patterns in behavior for officer training, the spokesperson added. “Police departments are now sitting on a vast trove of body-worn footage that gives them insight for the first time into which interactions with the public have been positive versus negative, and how individuals’ actions led to it.”

But looking to the past is just the beginning: Taser is betting that its artificial intelligence tools might be useful not just to determine what happened, but to anticipate what might happen in the future.

“We’ve got all of this law enforcement information with these videos, which is one of the richest treasure troves you could imagine for machine learning,” Taser CEO Rick Smith told PoliceOne in an interview about the company’s AI acquisitions. “Imagine having one person in your agency who would watch every single one of your videos — and remember everything they saw — and then be able to process that and give you the insight into what crimes you could solve, what problems you could deal with. Now, that’s obviously a little further out, but based on what we’re seeing in the artificial intelligence space, that could be within five to seven years.”

As video analytics and machine vision have made rapid gains in recent years, the future long dreaded by privacy experts and celebrated by technology companies is quickly approaching. No longer is the question whether artificial intelligence will transform the legal and lethal limits of policing, but how and for whose profits.

“Everyone refers to ‘Minority Report’ … about how they use facial recognition and iris recognition,” said Ron Kirk, director of the West Virginia Intelligence Fusion Center, which uses both technologies, in an interview with Vocativ. “I actually think that that is the way of the future.”",,,,,
Real-Time Face Recognition Threatens to Turn Cops’ Body Cameras Into Surveillance Machines,"LAST YEAR, A RUSSIAN startup announced that it could scan the faces of people passing by Moscow’s thousands of CCTV cameras and pick out wanted criminals or missing persons. Unlike much face recognition technology — which runs stills from videos or photographs after the fact — NTechLab’s FindFace algorithm has achieved a feat that once only seemed possible in the science fictional universe of “Minority Report”: It can determine not just who someone is, but where they’ve been, where they’re going, and whether they have an outstanding warrant, immigration detainer, or unpaid traffic ticket.

For years, the development of real-time face recognition has been hampered by poor video resolution, the angles of bodies in motion, and limited computing power. But as systems begin to transcend these technical barriers, they are also outpacing the development of policies to constrain them. Civil liberties advocates fear that the rise of real-time face recognition alongside the growing number of police body cameras creates the conditions for a perfect storm of mass surveillance.

“The main concern is that we’re already pretty far along in terms of having this real-time technology, and we already have the cameras,” said Jake Laperruque, a fellow at the Constitution Project. “These cameras are small, hard to notice, and all over the place. That’s a pretty lethal combination for privacy unless we have reasonable rules on how they can be used together.”

This imminent reality has led several civil liberties groups to call on police departments and legislators to implement clear policies on camera footage retention, biometrics, and privacy. On Wednesday morning, the House Oversight Committee held a hearing on law enforcement’s use of facial recognition technology, where advocates emphasized the dangers of allowing advancements in real-time recognition to broaden surveillance powers. As Alvaro Bedoya, executive director of the Center on Privacy and Technology at Georgetown Law, told Congress, pairing the technology with body cameras, in particular, “will redefine the nature of public spaces.”

The integration of real-time face recognition with body-worn cameras is further along than lawmakers and citizens realize. A recent Justice Department-funded survey conducted by Johns Hopkins University found that at least nine out of 38 manufacturers of body cameras currently have facial recognition capacities or have built in an option for such technology to be used later.

Taser, which leads the market for body cameras, recently acquired two startups that will allow it to run video analytics on the footage the cameras collect, and Taser’s CEO has repeatedly emphasized the development of real-time applications, such as scanning videos for faces, objects, and suspicious activity. A spokesperson for NTechLab, which has pilot projects in 20 countries including the United States, China, the United Kingdom, and Turkey, told The Intercept that its high-performing algorithm is already compatible with body cameras.

Police see the appeal. The captain of the Las Vegas Police Department told Bloomberg in July that he envisions his officers someday patrolling the Strip with “real-time analysis” on their body cameras and an earpiece to tell them, “‘Hey, that guy you just passed 20 feet ago has an outstanding warrant.’”

At least five U.S. police departments, including those in Los Angeles and New York, have already purchased or looked into purchasing real-time face recognition for their CCTV cameras, according to a study of face recognition technology published by Bedoya and other researchers at Georgetown. Bedoya emphasized that it’s only a matter of time until the nation’s body-worn cameras will be hooked up to real-time systems. With 6,000 of the country’s 18,000 police agencies estimated to be using body cameras, the pairing would translate into hundreds of thousands of new, mobile surveillance cameras.

“For many of these systems, the inclusion of real-time face recognition is just a software update away,” said Harlan Yu, co-author of a report on body camera policies for Upturn, a technology think tank.

Civil liberties experts warn that just walking down the street in a major urban center could turn into an automatic law enforcement interaction. With the ability to glean information at a distance, officers would not need to justify a particular interaction or find probable cause for a search, stop, or frisk. Instead, everybody walking past a given officer on his patrol could be subject to a “perpetual line-up,” as the Georgetown study put it. In Ferguson, Missouri, where a Justice Department investigation showed that more than three-quarters of the population had outstanding warrants, real-time face searches could give police immense power to essentially arrest individuals at will. And in a city like New York, which has over 100 officers per square mile and plans to equip each one of them with body cameras by 2019, the privacy implications of turning every beat cop into a surveillance camera are enormous.

“The inclusion of face recognition really changes the nature and purpose of body cameras, and it changes what communities expect when they call for and pay for cameras with taxpayer dollars,” Yu said. “I think there’s a real fear in communities of color, where officers are already concentrated, that these body-worn cameras will become another tool for surveillance rather than a tool for accountability.”",,,,,
The FBI Is Building a National Watchlist That Gives Companies Real-Time Updates on Employees,"THE FBI’S RAP BACK program is quietly transforming the way employers conduct background checks. While routine background checks provide employers with a one-time “snapshot” of their employee’s past criminal history, employers enrolled in federal and state Rap Back programs receive ongoing, real-time notifications and updates about their employees’ run-ins with law enforcement, including arrests at protests and charges that do not end up in convictions. (“Rap” is an acronym for Record of Arrest and Prosecution; “Back” is short for background.) Testifying before Congress about the program in 2015, FBI Director James Comey explained some limits of regular background checks: “People are clean when they first go in, then they get in trouble five years down the road [and] never tell the daycare about this.”

A majority of states already have their own databases that they use for background checks and have accessed in-state Rap Back programs since at least 2007; states and agencies now partnering with the federal government will be entering their data into the FBI’s Next Generation Identification database. The NGI database, widely considered to be the world’s largest biometric database, allows federal and state agencies to search more than 70 million civil fingerprints submitted for background checks alongside over 50 million prints submitted for criminal purposes. In July 2015, Utah became the first state to join the federal Rap Back program. Last April, aviation workers at Dallas-Ft. Worth Airport and Boston Logan International Airport began participating in a federal Rap Back pilot program for aviation employees. Two weeks ago, Texas submitted its first request to the federal criminal Rap Back system.

Rap Back has been advertised by the FBI as an effort to target individuals in “positions of trust,” such as those who work with children, the elderly, and the disabled. According to a Rap Back spokesperson, however, there are no formal limits as to “which populations of individuals can be enrolled in the Rap Back Service.” Civil liberties advocates fear that under Trump’s administration the program will grow with serious consequences for employee privacy, accuracy of records, and fair employment practices.",,,,,
Study: Face Recognition Systems Threaten the Privacy of Millions,"A BROAD COALITION of over 50 civil liberties groups delivered a letter to the Justice Department’s civil rights division Tuesday calling for an investigation into the expanding use of face recognition technology by police. “Safeguards to ensure this technology is being used fairly and responsibly appear to be virtually nonexistent,” the letter stated. The routine unsupervised use of face recognition systems, according to the dozens of signatories, threatens the privacy and civil liberties of millions — especially those of immigrants and people of color.

These civil rights groups were provided with advance copies of a watershed 150-page report detailing — in many cases for the first time — how local police departments across the country have been using facial recognition technology. Titled “The Perpetual Lineup,” the report, published Tuesday morning by the Georgetown Center on Privacy & Technology, reveals that police deploy face recognition technology in ways that are more widespread, advanced, and unregulated than anyone has previously reported.

“Face recognition is a powerful technology that requires strict oversight. But those controls by and large don’t exist today,” said Clare Garvie, one of the report’s co-authors. “With only a few exceptions, there are no laws governing police use of the technology, no standards ensuring its accuracy, and no systems checking for bias. It’s a wild west.”

Of the 52 agencies that acknowledged using face recognition in response to 106 records requests, the authors found that only one had obtained legislative approval before doing so. Government reports have long confirmed that millions of images of citizens are collected and stored in federal face recognition databases. Since at least 2002, civil liberties advocates have raised concerns that millions of drivers license photos of Americans who have never been arrested are being subject to facial searches — a practice that amounts to a perpetual digital lineup. This report augments such fears, demonstrating that at least one in four state or local law enforcement agencies have access to face recognition systems.

Among its findings, the report provides the most fine-grained detail to date on how exactly these face recognition systems might disproportionately impact African-Americans. “Face recognition systems are powerful — but they can also be biased,” the coalition’s letter explains. While one in two American adults have face images stored in at least one database, African-Americans are more likely than others to have their images captured and searched by face recognition systems.

In Virginia, for instance, the report shows how state police can search a mug shot database disproportionately populated with African-Americans, who are twice as likely to be arrested in the state. Not only are African-Americans more likely to be subject to searches, according to the report, but this overrepresentation puts them at greatest risk for a false match.

These errors could be compounded by the fact that some face recognition algorithms have been shown to misidentify African-Americans, women, and young people at unusually high rates. In a 2012 study co-authored by FBI experts, three algorithms that were tested performed between 5 and 10 percent worse on black faces than on white faces. And the overall accuracy of systems has been shown to decrease as a dataset expands. The Georgetown report interviewed two major facial recognition vendors which said that they did not test for racial basis, despite the fact that systems have been shown to be far from “race-blind.”

A slideshow on San Diego’s privacy policy obtained by the researchers reveals that people of color in the county are between 1.5 and 2.5 more likely to be targeted by its surveillance systems. San Diego County uses a mugshot-only system, and repeated studies have shown that African-Americans are twice as likely as white people to be arrested and searched by police.",,,,,
"U.K.’s Mass Surveillance Databases Were Unlawful for 17 Years, Court Rules","A BROAD COALITION of over 50 civil liberties groups delivered a letter to the Justice Department’s civil rights division Tuesday calling for an investigation into the expanding use of face recognition technology by police. “Safeguards to ensure this technology is being used fairly and responsibly appear to be virtually nonexistent,” the letter stated. The routine unsupervised use of face recognition systems, according to the dozens of signatories, threatens the privacy and civil liberties of millions — especially those of immigrants and people of color.

These civil rights groups were provided with advance copies of a watershed 150-page report detailing — in many cases for the first time — how local police departments across the country have been using facial recognition technology. Titled “The Perpetual Lineup,” the report, published Tuesday morning by the Georgetown Center on Privacy & Technology, reveals that police deploy face recognition technology in ways that are more widespread, advanced, and unregulated than anyone has previously reported.

“Face recognition is a powerful technology that requires strict oversight. But those controls by and large don’t exist today,” said Clare Garvie, one of the report’s co-authors. “With only a few exceptions, there are no laws governing police use of the technology, no standards ensuring its accuracy, and no systems checking for bias. It’s a wild west.”

Of the 52 agencies that acknowledged using face recognition in response to 106 records requests, the authors found that only one had obtained legislative approval before doing so. Government reports have long confirmed that millions of images of citizens are collected and stored in federal face recognition databases. Since at least 2002, civil liberties advocates have raised concerns that millions of drivers license photos of Americans who have never been arrested are being subject to facial searches — a practice that amounts to a perpetual digital lineup. This report augments such fears, demonstrating that at least one in four state or local law enforcement agencies have access to face recognition systems.

Among its findings, the report provides the most fine-grained detail to date on how exactly these face recognition systems might disproportionately impact African-Americans. “Face recognition systems are powerful — but they can also be biased,” the coalition’s letter explains. While one in two American adults have face images stored in at least one database, African-Americans are more likely than others to have their images captured and searched by face recognition systems.

In Virginia, for instance, the report shows how state police can search a mug shot database disproportionately populated with African-Americans, who are twice as likely to be arrested in the state. Not only are African-Americans more likely to be subject to searches, according to the report, but this overrepresentation puts them at greatest risk for a false match.

These errors could be compounded by the fact that some face recognition algorithms have been shown to misidentify African-Americans, women, and young people at unusually high rates. In a 2012 study co-authored by FBI experts, three algorithms that were tested performed between 5 and 10 percent worse on black faces than on white faces. And the overall accuracy of systems has been shown to decrease as a dataset expands. The Georgetown report interviewed two major facial recognition vendors which said that they did not test for racial basis, despite the fact that systems have been shown to be far from “race-blind.”

A slideshow on San Diego’s privacy policy obtained by the researchers reveals that people of color in the county are between 1.5 and 2.5 more likely to be targeted by its surveillance systems. San Diego County uses a mugshot-only system, and repeated studies have shown that African-Americans are twice as likely as white people to be arrested and searched by police.",,,,,
How a Facial Recognition Mismatch Can Ruin Your Life,,,,,,
Protests for Black Lives,"FEDERAL AGENTS from the Department of Homeland Security and the Justice Department used “a sophisticated cell phone cloning attack—the details of which remain classified—to intercept protesters’ phone communications” in Portland this summer, Ken Klippenstein reported this week in The Nation. Put aside for the moment that, if the report is true, federal agents conducted sophisticated electronic surveillance against American protesters, an alarming breach of constitutional rights. Do ordinary people have any hope of defending their privacy and freedom of assembly against threats like this?

Yes, they do. Here are two simple things you can do to help mitigate this type of threat:

As much as possible, and especially in the context of activism, use an encrypted messaging app like Signal — and get everyone you work with to use it too — to protect your SMS text messages, texting groups, and voice and video calls.
Prevent other people from using your SIM card by setting a SIM PIN on your phone. There are instructions on how to do this below.
How SIM Cloning Works

Without more details, it’s hard to be entirely sure what type of surveillance was used, but The Nation’s mention of “cell phone cloning” makes me think it was a SIM cloning attack. This involves duplicating a small chip used by virtually every cellphone to link itself to its owner’s phone number and account; this small chip is the subscriber identity module, more commonly known as SIM.

Here’s how SIM cloning would work:

First, the feds would need physical access to their target’s phone; for example, they could arrest their target at a protest, temporarily confiscating their phone.
Then they would pop out the SIM card from the phone, a process designed to be easy, since end users often have reasons to replace the card (such as traveling abroad and needing a local SIM card to access the local cellular network, or when switching cellular providers).
The feds would then copy their target’s SIM card data onto a blank SIM card (this presents some challenges, as I explain below), and then put the original SIM card back without their target knowing.

SIM cards contain a secret encryption key that is used to encrypt data between the phone and cellphone towers. They’re designed so that this key can be used (like when you receive a text or call someone) but so the key itself can’t be extracted.

But it’s still possible to extract the key from the SIM card, by cracking it. Older SIM cards used a weaker encryption algorithm and could be cracked quickly and easily, but newer SIM cards use stronger encryption and might take days or significantly longer to crack. It’s possible that this is why the details of the type of surveillance used in Portland “remain classified.” Do federal agencies know of a way to quickly extract encryption keys from SIM cards? (On the other hand, it’s also possible that “cell phone cloning” doesn’t describe SIM cloning at all but something else instead, like extracting files from the phone itself instead of data from the SIM card.)",,,,,
BlueLeaks,"Since May, as protesters around the country have marched against police brutality and in support of the Black Lives Matter movement, activists have spotted a recurring presence in the skies: mysterious planes and helicopters hovering overhead, apparently conducting surveillance on protesters. A press release from the Justice Department at the end of May revealed that the Drug Enforcement Agency and U.S. Marshals Service were asked by the Justice Department to provide unspecified support to law enforcement during protests. A few days later, a memo obtained by BuzzFeed News offered a little more insight on the matter; it revealed that shortly after protests began in various cities, the DEA had sought special authority from the Justice Department to covertly spy on Black Lives Matter protesters on behalf of law enforcement. 
Although the press release and memo didn’t say what form the support and surveillance would take, it’s likely that the two agencies were being asked to assist police for a particular reason. Both the DEA and the Marshals possess airplanes outfitted with so-called stingrays or dirtboxes: powerful technologies capable of tracking mobile phones or, depending on how they’re configured, collecting data and communications from mobile phones in bulk.
",,,,,
Protests for Black Lives,,,,,,